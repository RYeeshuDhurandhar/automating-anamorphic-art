{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "# from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a 3D image, converting to black and white!\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def load_image_and_convert_to_tensor(image_path, target_size=(30, 30)):\n",
    "    # Load the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "    # Display the image in a window\n",
    "    # cv2_imshow(image)\n",
    "    # cv2.imshow(\"Image\", image)\n",
    "\n",
    "    # Wait for a key press and then close the window\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "    if image is None:\n",
    "        # If no image is loaded, return a tensor with 0\n",
    "        print('Images is None!')\n",
    "        return np.zeros(target_size, dtype=np.uint8)\n",
    "\n",
    "    # Resize the image to the target size\n",
    "    image = cv2.resize(image, target_size)\n",
    "    # print('image: ', image)\n",
    "    # Convert the image to grayscale if it's not already\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "        print('It is a 3D image, converting to black and white!')\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Convert the grayscale image to a binary tensor\n",
    "    # binary_tensor = (image > 0).astype(np.uint8)\n",
    "    binary_tensor = (image < 1).astype(np.uint8)\n",
    "\n",
    "    return binary_tensor\n",
    "\n",
    "# Example usage:\n",
    "image_path = \"apple2.jpg\"\n",
    "result = load_image_and_convert_to_tensor(image_path)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 6, 3, 8, 5, 2, 7, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define the input 2D tensor\n",
    "input_tensor = torch.tensor([[1, 2, 3],\n",
    "                             [4, 5, 6],\n",
    "                             [7, 8, 9]])\n",
    "\n",
    "# Get the number of rows and columns in the tensor\n",
    "num_rows, num_cols = input_tensor.shape\n",
    "\n",
    "# Create an empty list to store the elements in the desired order\n",
    "result_list = []\n",
    "\n",
    "# Iterate through the columns in reverse order\n",
    "for j in range(num_cols - 1, -1, -1):\n",
    "    # Iterate through the rows in reverse order\n",
    "    for i in range(num_rows - 1, -1, -1):\n",
    "        # Append the element to the result list\n",
    "        result_list.append(input_tensor[i, j])\n",
    "\n",
    "# Iterate through the columns in reverse order\n",
    "for j in range(num_cols - 1, -1, -1):\n",
    "    # Iterate through the rows in reverse order\n",
    "    for i in range(num_rows - 1, -1, -1):\n",
    "        # Append the element to the result list\n",
    "        result_list.append(input_tensor[i, j])\n",
    "\n",
    "# Convert the result list to a 1D tensor\n",
    "result_tensor = torch.tensor(result_list)\n",
    "\n",
    "# Print the result\n",
    "print(result_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0: tensor([7, 8, 9, 4, 5, 6, 1, 2, 3])\n",
    "1: tensor([3, 2, 1, 6, 5, 4, 9, 8, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7, 8, 9],\n",
      "        [4, 5, 6],\n",
      "        [1, 2, 3]])\n",
      "tensor([[7, 4, 1],\n",
      "        [8, 5, 2],\n",
      "        [9, 6, 3]])\n",
      "tensor([7, 4, 1, 8, 5, 2, 9, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define the input 2D tensor\n",
    "input_tensor = torch.tensor([[1, 2, 3],\n",
    "                             [4, 5, 6],\n",
    "                             [7, 8, 9]])\n",
    "\n",
    "# Reverse the rows\n",
    "reversed_tensor = torch.flip(input_tensor, [0])\n",
    "print(reversed_tensor)\n",
    "\n",
    "reversed_tensor = torch.transpose(reversed_tensor, 0, 1)\n",
    "print(reversed_tensor)\n",
    "# Flatten the reversed tensor\n",
    "result_tensor = reversed_tensor.reshape(-1)\n",
    "\n",
    "# Print the result\n",
    "print(result_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Define the input 2D tensor\n",
    "input_tensor = torch.tensor([[1, 2, 3],\n",
    "                             [4, 5, 6],\n",
    "                             [7, 8, 9]])\n",
    "\n",
    "# Reverse the rows\n",
    "reversed_tensor = torch.flip(input_tensor, [0])\n",
    "print(reversed_tensor)\n",
    "transposed_tensor = reversed_tensor.t()\n",
    "print(transposed_tensor)\n",
    "# Flatten the reversed tensor\n",
    "result_tensor = transposed_tensor.view(-1)\n",
    "\n",
    "# Print the result\n",
    "print(result_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Load the black and white image\u001b[39;00m\n\u001b[1;32m      2\u001b[0m image_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./duck.jpg\u001b[39m\u001b[39m'\u001b[39m  \u001b[39m# Replace with your image path\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(image_path, cv2\u001b[39m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[1;32m      5\u001b[0m \u001b[39m# Resize the image to 400x500\u001b[39;00m\n\u001b[1;32m      6\u001b[0m desired_size \u001b[39m=\u001b[39m (\u001b[39m500\u001b[39m, \u001b[39m400\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the black and white image\n",
    "image_path = './duck.jpg'  # Replace with your image path\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Resize the image to 400x500\n",
    "desired_size = (64, 64)\n",
    "resized_image = cv2.resize(image, desired_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# Apply thresholding to create a binary image\n",
    "_, binary_image = cv2.threshold(resized_image, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Convert binary image to binary tensor\n",
    "binary_tensor = torch.tensor(binary_image, dtype=torch.float32) / 255.0\n",
    "\n",
    "# Display the original and resized images\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Resized and Binary Image', binary_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_xyz(p, angles):\n",
    "    '''\n",
    "    Reference: http://www.songho.ca/opengl/gl_anglestoaxes.html\n",
    "    '''\n",
    "    θx, θy, θz = angles\n",
    "    θx = torch.FloatTensor([θx * 3.14159 / 180.0])\n",
    "    θy = torch.FloatTensor([θy * 3.14159 / 180.0])\n",
    "    θz = torch.FloatTensor([θz * 3.14159 / 180.0])\n",
    "    R_zyx = torch.tensor([ \n",
    "        [torch.cos(θz)*torch.cos(θy), -torch.sin(θz)*torch.cos(θx) + torch.cos(θz)*torch.sin(θy)*torch.sin(θx), torch.sin(θz)*torch.sin(θx)+torch.cos(θz)*torch.sin(θy)*torch.cos(θx)],\n",
    "        [torch.sin(θz)*torch.cos(θy), torch.cos(θz)*torch.cos(θx)+torch.sin(θz)*torch.sin(θy)*torch.sin(θx), -torch.cos(θz)*torch.sin(θx)+torch.sin(θz)*torch.sin(θy)*torch.cos(θx)],\n",
    "        [-torch.sin(θy), torch.cos(θy)*torch.sin(θx), torch.cos(θy)*torch.cos(θx)]\n",
    "    ])\n",
    "    p = p.float()\n",
    "    R_zyx = R_zyx.float()\n",
    "    return torch.matmul(p, R_zyx.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdf_sphere(p, r, center, angles):\n",
    "    p_rotated = rotate_xyz(p, angles)\n",
    "    return torch.sqrt(torch.sum((p_rotated - center)**2, dim=1)) - r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdBox(p, b, center, angles):\n",
    "    '''\n",
    "    p = point to be tested, nx3 tensor\n",
    "    b = half the length of box, i.e. coordinates of the corner from the center\n",
    "    center = center of the box\n",
    "    angles = rotation angles in degrees\n",
    "    '''\n",
    "    p_rotated = rotate_xyz(p, angles)\n",
    "    q = torch.abs(p_rotated-center) - b\n",
    "    return torch.norm(torch.max(q, torch.tensor([0.,0.,0.])), dim=1) + torch.min(torch.max(q, dim=1)[0], torch.tensor([0.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid of points in 3D space\n",
    "x = np.linspace(-5, 5, 50)\n",
    "y = np.linspace(-5, 5, 50)\n",
    "z = np.linspace(-5, 5, 50)\n",
    "X, Y, Z = np.meshgrid(x, y, z)\n",
    "points = np.stack((X, Y, Z), axis=-1).reshape(-1, 3)\n",
    "\n",
    "# Calculate the signed distance function for a sphere and a box\n",
    "sphere_sdf = sdf_sphere(torch.tensor(points), r=2.0, center=torch.tensor([0.0, 0.0, 0.0]), angles=torch.tensor([0.0, 0.0, 0.0]))\n",
    "box_sdf = sdBox(torch.tensor(points), b=torch.tensor([1.0, 1.0, 1.0]), center=torch.tensor([0.0, 0.0, 0.0]), angles=torch.tensor([0.0, 0.0, 0.0]))\n",
    "\n",
    "# Reshape the signed distance values to match the grid shape\n",
    "sphere_sdf = sphere_sdf.reshape(50, 50, 50)\n",
    "box_sdf = box_sdf.reshape(50, 50, 50)\n",
    "\n",
    "# Create a 3D plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the surfaces using contour plots\n",
    "ax.contourf(X, Y, Z, sphere_sdf, cmap='viridis', alpha=0.5)\n",
    "ax.contourf(X, Y, Z, box_sdf, cmap='plasma', alpha=0.5)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.set_title('Signed Distance Function Visualization')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the parameters to visualize\n",
    "param1_values = np.linspace(-5, 5, 100)\n",
    "param2_values = np.linspace(-5, 5, 100)\n",
    "\n",
    "# Create a grid of parameter values\n",
    "param1_grid, param2_grid = np.meshgrid(param1_values, param2_values)\n",
    "\n",
    "# Calculate the loss for each parameter combination (simplified example)\n",
    "def loss_function(param1, param2):\n",
    "    return param1 ** 2 + param2 ** 2\n",
    "\n",
    "loss_grid = loss_function(param1_grid, param2_grid)\n",
    "\n",
    "# Create a contour plot of the loss landscape\n",
    "plt.contourf(param1_grid, param2_grid, loss_grid, levels=20, cmap=\"viridis\")\n",
    "plt.colorbar()\n",
    "\n",
    "# Simulate optimization trajectory (simplified example)\n",
    "trajectory_param1 = np.array([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
    "trajectory_param2 = np.array([3, 2, 1, 0, -1, -2, -3, -4, -5])\n",
    "\n",
    "plt.plot(trajectory_param1, trajectory_param2, marker=\"o\", color=\"red\")\n",
    "\n",
    "plt.xlabel(\"Parameter 1\")\n",
    "plt.ylabel(\"Parameter 2\")\n",
    "plt.title(\"Loss Landscape and Optimization Trajectory\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anamorph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
