parameters.grad:  None
Iteration:  0
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(4.3749, grad_fn=<DivBackward0>)
Projection Loss:  tensor(2500.0625, grad_fn=<AddBackward0>)
Total Loss:  tensor(2504.4375, grad_fn=<AddBackward0>)
Gradients:
10792.3203125
Gradient before update: tensor(19489.)
Gradient after update: tensor(19489.)
Total Loss:  tensor(2504.4375, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[-0.5368,  0.7649,  1.2547,  0.0000,  0.0000,  0.0000],
        [-0.9424,  0.7026,  1.8237,  0.0000,  0.0000,  0.0000],
        [-0.4586, -0.3414, -2.0503,  0.0000,  0.0000,  0.0000],
        [-0.6812,  0.3044,  2.3899,  0.0000,  0.0000,  0.0000],
        [ 0.0379, -0.1354,  2.0204,  0.0000,  0.0000,  0.0000],
        [ 0.7877,  0.3101, -1.6354,  0.0000,  0.0000,  0.0000],
        [-0.9203,  0.1550, -1.3418,  0.0000,  0.0000,  0.0000],
        [-0.0325, -0.9144,  2.0936,  0.0000,  0.0000,  0.0000],
        [-0.1663,  0.0272,  0.9568,  0.0000,  0.0000,  0.0000],
        [-0.0861, -0.6313,  2.2075,  0.0000,  0.0000,  0.0000],
        [-0.9769,  0.4621,  0.8733,  0.0000,  0.0000,  0.0000],
        [ 0.1440, -0.0403, -0.3836,  0.0000,  0.0000,  0.0000],
        [ 0.1630, -0.6362,  1.4840,  0.0000,  0.0000,  0.0000],
        [-0.3019,  0.9752,  2.9657,  0.0000,  0.0000,  0.0000],
        [ 0.6361,  1.0116, -2.9998,  0.0000,  0.0000,  0.0000],
        [ 0.7736,  1.0445, -1.8820,  0.0000,  0.0000,  0.0000],
        [-0.6241,  0.5052,  0.8413,  0.0000,  0.0000,  0.0000],
        [ 0.4934,  0.4282, -3.0652,  0.0000,  0.0000,  0.0000],
        [-0.9026,  0.4472, -2.4406,  0.0000,  0.0000,  0.0000],
        [ 1.0343,  0.9702,  0.3682,  0.0000,  0.0000,  0.0000],
        [ 0.1928,  0.0838, -2.8198,  0.0000,  0.0000,  0.0000],
        [-0.5174, -0.6234, -1.5150,  0.0000,  0.0000,  0.0000],
        [ 0.4036, -0.3710, -2.2794,  0.0000,  0.0000,  0.0000],
        [-0.4616, -0.6608,  1.7335,  0.0000,  0.0000,  0.0000],
        [-0.2679, -0.6820, -0.1051,  0.0000,  0.0000,  0.0000],
        [ 0.6240,  0.8994,  1.3890,  0.0000,  0.0000,  0.0000],
        [-1.0820, -0.1077,  1.7482,  0.0000,  0.0000,  0.0000],
        [-1.0583,  0.1515,  1.1162,  0.0000,  0.0000,  0.0000],
        [-0.8117, -0.1042,  0.9099,  0.0000,  0.0000,  0.0000],
        [-0.4057, -1.0159, -1.9969,  0.0000,  0.0000,  0.0000],
        [-0.7668, -1.0035,  2.1437,  0.0000,  0.0000,  0.0000],
        [-0.2096,  1.0533, -1.9513,  0.0000,  0.0000,  0.0000],
        [ 0.5106,  0.9592, -0.3499,  0.0000,  0.0000,  0.0000],
        [-0.5131, -0.9947,  1.4328,  0.0000,  0.0000,  0.0000],
        [ 0.7967, -0.7802,  0.5085,  0.0000,  0.0000,  0.0000],
        [-0.5496, -0.0379,  0.1802,  0.0000,  0.0000,  0.0000],
        [-0.2923, -0.5123, -2.2563,  0.0000,  0.0000,  0.0000],
        [ 0.2893, -0.7438, -2.6845,  0.0000,  0.0000,  0.0000],
        [-0.0487,  0.5157,  1.5486,  0.0000,  0.0000,  0.0000],
        [ 0.8849, -0.0473, -2.3489,  0.0000,  0.0000,  0.0000],
        [-0.8010, -1.0298, -1.3455,  0.0000,  0.0000,  0.0000],
        [-0.9609, -0.4343, -1.4536,  0.0000,  0.0000,  0.0000],
        [-0.0268,  0.5319, -2.4048,  0.0000,  0.0000,  0.0000],
        [ 1.0052,  0.8896, -1.1901,  0.0000,  0.0000,  0.0000],
        [-0.1603, -0.8437, -2.6153,  0.0000,  0.0000,  0.0000],
        [ 0.1644, -0.7195, -0.9544,  0.0000,  0.0000,  0.0000],
        [ 0.9682,  0.5165,  0.9222,  0.0000,  0.0000,  0.0000],
        [-0.1424,  0.4865,  2.3747,  0.0000,  0.0000,  0.0000],
        [ 0.2949,  0.7670,  0.6274,  0.0000,  0.0000,  0.0000],
        [-0.5211,  0.5402, -0.7269,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
Iteration:  1
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.7928, grad_fn=<DivBackward0>)
Projection Loss:  tensor(2390.0708, grad_fn=<AddBackward0>)
Total Loss:  tensor(2390.8635, grad_fn=<AddBackward0>)
Gradients:
323.2103271484375
Gradient before update: tensor(55.1188)
Gradient after update: tensor(55.1188)
Iteration:  2
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.1661, grad_fn=<DivBackward0>)
Projection Loss:  tensor(2302.0303, grad_fn=<AddBackward0>)
Total Loss:  tensor(2302.1965, grad_fn=<AddBackward0>)
Gradients:
55.6494026184082
Gradient before update: tensor(39.7031)
Gradient after update: tensor(39.7031)
Total Loss:  tensor(2302.1965, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[-4.2405e-01,  9.0655e-01,  1.4157e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0612e+00,  5.8376e-01,  1.7049e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.0003e-01, -1.5079e-01, -2.0181e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-8.2593e-01,  1.2992e-01,  2.5165e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 2.1876e-01, -1.5321e-01,  1.8351e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.6896e-01,  1.9130e-01, -1.7542e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-8.1786e-01,  3.1000e-01, -1.1558e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0039e-01, -1.0470e+00,  1.9615e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.7852e-01, -4.4366e-02,  1.0966e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1826e-01, -4.5039e-01,  2.3614e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1675e+00,  6.3279e-01,  6.8815e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 2.6285e-01,  7.8515e-02, -5.0238e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 2.8183e-01, -5.1744e-01,  1.3652e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.6737e-01,  1.1251e+00,  3.0335e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.4419e-01,  1.1984e+00, -2.9130e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.6293e-01,  1.1643e+00, -2.0008e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.5989e-01,  6.1940e-01,  6.9073e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.3262e-01,  5.5563e-01, -3.2092e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0867e+00,  6.1434e-01, -2.3979e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1535e+00,  1.0893e+00,  2.4957e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.2964e-02, -5.5652e-02, -2.6437e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.4587e-01, -4.8808e-01, -1.4107e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.1928e-01, -2.5250e-01, -2.1410e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.8245e-01, -4.9150e-01,  1.6518e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.8669e-01, -8.0078e-01,  1.3733e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.0520e-01,  1.0182e+00,  1.5078e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2452e+00, -2.7560e-01,  1.8545e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2419e+00,  2.2114e-01,  1.2924e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.0226e-01, -2.5054e-01,  7.5550e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-2.7328e-01, -1.1574e+00, -2.1033e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-8.8982e-01, -1.1367e+00,  2.2742e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.2194e-01,  1.1788e+00, -1.9868e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.7254e-01,  1.0986e+00, -2.3197e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.4589e-01, -1.1764e+00,  1.2797e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.7826e-01, -6.6098e-01,  3.8562e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.2379e-01,  9.2560e-02,  2.5555e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.4178e-01, -4.8721e-01, -2.2401e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.4537e-01, -9.0747e-01, -2.8375e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1390e-01,  4.3089e-01,  1.6994e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0553e+00,  7.4650e-03, -2.5146e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-9.1984e-01, -1.1487e+00, -1.2267e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1030e+00, -3.2224e-01, -1.3204e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.4557e-01,  6.4750e-01, -2.2842e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1259e+00,  1.0083e+00, -1.0713e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.2654e-01, -9.8882e-01, -2.7639e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.4691e-01, -8.7973e-01, -1.0051e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0971e+00,  3.9463e-01,  8.0397e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0424e-03,  6.1878e-01,  2.4884e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.0941e-01,  8.8701e-01,  5.0897e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.3604e-01,  3.8388e-01, -7.4906e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00]], requires_grad=True)
Iteration:  3
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0493, grad_fn=<DivBackward0>)
Projection Loss:  tensor(2227.8843, grad_fn=<AddBackward0>)
Total Loss:  tensor(2227.9336, grad_fn=<AddBackward0>)
Gradients:
333.8244323730469
Gradient before update: tensor(192.3167)
Gradient after update: tensor(192.3167)
Iteration:  4
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0724, grad_fn=<DivBackward0>)
Projection Loss:  tensor(2142.1045, grad_fn=<AddBackward0>)
Total Loss:  tensor(2142.1770, grad_fn=<AddBackward0>)
Gradients:
731.8786010742188
Gradient before update: tensor(852.4614)
Gradient after update: tensor(852.4614)
Total Loss:  tensor(2142.1770, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[-0.5232,  0.9318,  1.5211,  0.0000,  0.0000,  0.0000],
        [-1.1395,  0.5055,  1.6267,  0.0000,  0.0000,  0.0000],
        [-0.7529,  0.0155, -1.9532,  0.0000,  0.0000,  0.0000],
        [-0.9213,  0.0149,  2.5999,  0.0000,  0.0000,  0.0000],
        [ 0.3604, -0.1418,  1.8078,  0.0000,  0.0000,  0.0000],
        [ 0.7064,  0.1551, -1.7537,  0.0000,  0.0000,  0.0000],
        [-0.8898,  0.4062, -1.1721,  0.0000,  0.0000,  0.0000],
        [ 0.1881, -1.1346,  1.8741,  0.0000,  0.0000,  0.0000],
        [-0.0999, -0.0445,  1.2061,  0.0000,  0.0000,  0.0000],
        [-0.1618, -0.3267,  2.4683,  0.0000,  0.0000,  0.0000],
        [-1.3184,  0.7489,  0.5564,  0.0000,  0.0000,  0.0000],
        [ 0.3411,  0.1568, -0.5807,  0.0000,  0.0000,  0.0000],
        [ 0.3594, -0.4985,  1.2682,  0.0000,  0.0000,  0.0000],
        [-0.6131,  1.1486,  3.0841,  0.0000,  0.0000,  0.0000],
        [ 0.6514,  1.0913, -3.0194,  0.0000,  0.0000,  0.0000],
        [ 0.6724,  1.2863, -2.0881,  0.0000,  0.0000,  0.0000],
        [-0.3475,  0.6961,  0.5916,  0.0000,  0.0000,  0.0000],
        [ 0.7253,  0.6357, -3.3084,  0.0000,  0.0000,  0.0000],
        [-1.0806,  0.7276, -2.3917,  0.0000,  0.0000,  0.0000],
        [ 1.2329,  1.1690,  0.1714,  0.0000,  0.0000,  0.0000],
        [-0.0497, -0.1445, -2.5503,  0.0000,  0.0000,  0.0000],
        [-0.2303, -0.4009, -1.3371,  0.0000,  0.0000,  0.0000],
        [ 0.5940, -0.1792, -2.0718,  0.0000,  0.0000,  0.0000],
        [-0.6630, -0.3783,  1.6005,  0.0000,  0.0000,  0.0000],
        [-0.4895, -0.8502,  0.0635,  0.0000,  0.0000,  0.0000],
        [ 0.4284,  1.0985,  1.5859,  0.0000,  0.0000,  0.0000],
        [-1.4169, -0.3954,  1.9473,  0.0000,  0.0000,  0.0000],
        [-1.3907,  0.2523,  1.3813,  0.0000,  0.0000,  0.0000],
        [-0.6601, -0.3492,  0.6410,  0.0000,  0.0000,  0.0000],
        [-0.1625, -1.2621, -2.1640,  0.0000,  0.0000,  0.0000],
        [-0.9642, -1.1603,  2.3567,  0.0000,  0.0000,  0.0000],
        [-0.4521,  1.1095, -1.9710,  0.0000,  0.0000,  0.0000],
        [ 0.2468,  1.1109, -0.2551,  0.0000,  0.0000,  0.0000],
        [-0.7337, -1.3092,  1.1770,  0.0000,  0.0000,  0.0000],
        [ 0.7477, -0.6907,  0.2727,  0.0000,  0.0000,  0.0000],
        [-0.3214,  0.0872,  0.2284,  0.0000,  0.0000,  0.0000],
        [-0.3403, -0.5461, -2.2725,  0.0000,  0.0000,  0.0000],
        [ 0.5697, -1.0521, -2.9299,  0.0000,  0.0000,  0.0000],
        [ 0.2007,  0.5292,  1.7328,  0.0000,  0.0000,  0.0000],
        [ 1.1629, -0.0997, -2.6224,  0.0000,  0.0000,  0.0000],
        [-0.9992, -1.2278, -1.1491,  0.0000,  0.0000,  0.0000],
        [-1.1463, -0.3381, -1.2089,  0.0000,  0.0000,  0.0000],
        [-0.1909,  0.6446, -2.2306,  0.0000,  0.0000,  0.0000],
        [ 1.2292,  1.0635, -0.9912,  0.0000,  0.0000,  0.0000],
        [-0.4367, -1.0852, -2.8640,  0.0000,  0.0000,  0.0000],
        [ 0.2774, -1.0033, -0.9232,  0.0000,  0.0000,  0.0000],
        [ 1.2152,  0.4043,  0.7419,  0.0000,  0.0000,  0.0000],
        [ 0.0921,  0.7060,  2.5632,  0.0000,  0.0000,  0.0000],
        [ 0.4817,  0.9666,  0.4310,  0.0000,  0.0000,  0.0000],
        [-0.2288,  0.4911, -0.6418,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
Iteration:  5
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.1136, grad_fn=<DivBackward0>)
Projection Loss:  tensor(2063.1504, grad_fn=<AddBackward0>)
Total Loss:  tensor(2063.2639, grad_fn=<AddBackward0>)
Gradients:
363.6242980957031
Gradient before update: tensor(-202.5593)
Gradient after update: tensor(-202.5593)
Iteration:  6
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.1593, grad_fn=<DivBackward0>)
Projection Loss:  tensor(1992.9617, grad_fn=<AddBackward0>)
Total Loss:  tensor(1993.1210, grad_fn=<AddBackward0>)
Gradients:
14634.7978515625
Gradient before update: tensor(17398.7363)
Gradient after update: tensor(17398.7363)
Total Loss:  tensor(1993.1210, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[-0.5965,  0.9504,  1.5990,  0.0000,  0.0000,  0.0000],
        [-1.1973,  0.4476,  1.5690,  0.0000,  0.0000,  0.0000],
        [-0.8677,  0.1402, -1.9042,  0.0000,  0.0000,  0.0000],
        [-0.9919, -0.0702,  2.6616,  0.0000,  0.0000,  0.0000],
        [ 0.4626, -0.1246,  1.8177,  0.0000,  0.0000,  0.0000],
        [ 0.8488,  0.2068, -1.6427,  0.0000,  0.0000,  0.0000],
        [-0.9420,  0.4775, -1.1843,  0.0000,  0.0000,  0.0000],
        [ 0.2530, -1.1996,  1.8095,  0.0000,  0.0000,  0.0000],
        [-0.0680, -0.0075,  1.2709,  0.0000,  0.0000,  0.0000],
        [-0.1940, -0.2352,  2.5474,  0.0000,  0.0000,  0.0000],
        [-1.2228,  0.8470,  0.4566,  0.0000,  0.0000,  0.0000],
        [ 0.3990,  0.2147, -0.6386,  0.0000,  0.0000,  0.0000],
        [ 0.4190, -0.5218,  1.1860,  0.0000,  0.0000,  0.0000],
        [-0.7007,  1.1181,  3.1893,  0.0000,  0.0000,  0.0000],
        [ 0.7307,  1.0122, -3.0918,  0.0000,  0.0000,  0.0000],
        [ 0.6521,  1.3769, -2.1820,  0.0000,  0.0000,  0.0000],
        [-0.2644,  0.7537,  0.5189,  0.0000,  0.0000,  0.0000],
        [ 0.8002,  0.6687, -3.4119,  0.0000,  0.0000,  0.0000],
        [-1.1572,  0.8194, -2.4654,  0.0000,  0.0000,  0.0000],
        [ 1.2928,  1.2301,  0.1135,  0.0000,  0.0000,  0.0000],
        [-0.0911, -0.1905, -2.5670,  0.0000,  0.0000,  0.0000],
        [-0.1447, -0.3366, -1.2828,  0.0000,  0.0000,  0.0000],
        [ 0.6453, -0.1358, -2.0790,  0.0000,  0.0000,  0.0000],
        [-0.7229, -0.2951,  1.5625,  0.0000,  0.0000,  0.0000],
        [-0.5869, -0.8617,  0.0751,  0.0000,  0.0000,  0.0000],
        [ 0.3776,  1.1744,  1.6418,  0.0000,  0.0000,  0.0000],
        [-1.5436, -0.4017,  2.0272,  0.0000,  0.0000,  0.0000],
        [-1.4987,  0.2548,  1.3852,  0.0000,  0.0000,  0.0000],
        [-0.6309, -0.4227,  0.5605,  0.0000,  0.0000,  0.0000],
        [-0.0805, -1.3394, -2.2090,  0.0000,  0.0000,  0.0000],
        [-1.0177, -1.1171,  2.4145,  0.0000,  0.0000,  0.0000],
        [-0.3664,  1.2060, -1.9744,  0.0000,  0.0000,  0.0000],
        [ 0.1586,  1.0229, -0.3429,  0.0000,  0.0000,  0.0000],
        [-0.7440, -1.4236,  1.0686,  0.0000,  0.0000,  0.0000],
        [ 0.8055, -0.7219,  0.1888,  0.0000,  0.0000,  0.0000],
        [-0.3308,  0.0774,  0.1265,  0.0000,  0.0000,  0.0000],
        [-0.3471, -0.6090, -2.2846,  0.0000,  0.0000,  0.0000],
        [ 0.6836, -1.1726, -2.9886,  0.0000,  0.0000,  0.0000],
        [ 0.2273,  0.5275,  1.7785,  0.0000,  0.0000,  0.0000],
        [ 1.2444, -0.1800, -2.7023,  0.0000,  0.0000,  0.0000],
        [-1.0579, -1.2865, -1.0918,  0.0000,  0.0000,  0.0000],
        [-1.1287, -0.4210, -1.1029,  0.0000,  0.0000,  0.0000],
        [-0.1700,  0.5546, -2.2270,  0.0000,  0.0000,  0.0000],
        [ 1.3280,  0.9659, -1.0771,  0.0000,  0.0000,  0.0000],
        [-0.5179, -1.1564, -2.9380,  0.0000,  0.0000,  0.0000],
        [ 0.1745, -0.9003, -1.0258,  0.0000,  0.0000,  0.0000],
        [ 1.3396,  0.4950,  0.6983,  0.0000,  0.0000,  0.0000],
        [ 0.1611,  0.7704,  2.6186,  0.0000,  0.0000,  0.0000],
        [ 0.5351,  1.0254,  0.3734,  0.0000,  0.0000,  0.0000],
        [-0.2222,  0.6147, -0.5611,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
Iteration:  7
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.1216, grad_fn=<DivBackward0>)
Projection Loss:  tensor(1929.0599, grad_fn=<AddBackward0>)
Total Loss:  tensor(1929.1815, grad_fn=<AddBackward0>)
Gradients:
148.57659912109375
Gradient before update: tensor(222.6694)
Gradient after update: tensor(222.6694)
Iteration:  8
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0896, grad_fn=<DivBackward0>)
Projection Loss:  tensor(1887.3461, grad_fn=<AddBackward0>)
Total Loss:  tensor(1887.4357, grad_fn=<AddBackward0>)
Gradients:
1396.732666015625
Gradient before update: tensor(1843.2037)
Gradient after update: tensor(1843.2037)
Total Loss:  tensor(1887.4357, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[-0.6535,  0.9507,  1.6608,  0.0000,  0.0000,  0.0000],
        [-1.2422,  0.4028,  1.5243,  0.0000,  0.0000,  0.0000],
        [-0.9468,  0.2414, -1.8661,  0.0000,  0.0000,  0.0000],
        [-1.0795, -0.1742,  2.7176,  0.0000,  0.0000,  0.0000],
        [ 0.5440, -0.1132,  1.8255,  0.0000,  0.0000,  0.0000],
        [ 0.9996,  0.2672, -1.5259,  0.0000,  0.0000,  0.0000],
        [-0.9214,  0.5339, -1.1992,  0.0000,  0.0000,  0.0000],
        [ 0.3034, -1.2500,  1.7593,  0.0000,  0.0000,  0.0000],
        [-0.0433,  0.0211,  1.3212,  0.0000,  0.0000,  0.0000],
        [-0.2189, -0.1642,  2.6088,  0.0000,  0.0000,  0.0000],
        [-1.1486,  0.9232,  0.3793,  0.0000,  0.0000,  0.0000],
        [ 0.4440,  0.2596, -0.6835,  0.0000,  0.0000,  0.0000],
        [ 0.4652, -0.5398,  1.1222,  0.0000,  0.0000,  0.0000],
        [-0.7691,  1.0948,  3.2712,  0.0000,  0.0000,  0.0000],
        [ 0.7921,  0.9511, -3.1340,  0.0000,  0.0000,  0.0000],
        [ 0.5989,  1.3604, -2.1845,  0.0000,  0.0000,  0.0000],
        [-0.1999,  0.7983,  0.4625,  0.0000,  0.0000,  0.0000],
        [ 0.8694,  0.6515, -3.5475,  0.0000,  0.0000,  0.0000],
        [-1.2177,  0.8933, -2.5178,  0.0000,  0.0000,  0.0000],
        [ 1.3406,  1.3348,  0.0980,  0.0000,  0.0000,  0.0000],
        [-0.0979, -0.2083, -2.6436,  0.0000,  0.0000,  0.0000],
        [-0.0794, -0.2803, -1.2452,  0.0000,  0.0000,  0.0000],
        [ 0.6833, -0.1050, -2.1026,  0.0000,  0.0000,  0.0000],
        [-0.7694, -0.2306,  1.5331,  0.0000,  0.0000,  0.0000],
        [-0.6614, -0.8800,  0.0398,  0.0000,  0.0000,  0.0000],
        [ 0.3911,  1.1249,  1.6792,  0.0000,  0.0000,  0.0000],
        [-1.6281, -0.3176,  2.1116,  0.0000,  0.0000,  0.0000],
        [-1.5881,  0.1706,  1.3020,  0.0000,  0.0000,  0.0000],
        [-0.6115, -0.4781,  0.5152,  0.0000,  0.0000,  0.0000],
        [-0.0170, -1.3995, -2.2438,  0.0000,  0.0000,  0.0000],
        [-1.0635, -1.0800,  2.4592,  0.0000,  0.0000,  0.0000],
        [-0.3693,  1.2087, -1.9690,  0.0000,  0.0000,  0.0000],
        [ 0.0903,  0.9548, -0.4089,  0.0000,  0.0000,  0.0000],
        [-0.6635, -1.5256,  0.9747,  0.0000,  0.0000,  0.0000],
        [ 0.8523, -0.7433,  0.1251,  0.0000,  0.0000,  0.0000],
        [-0.4523,  0.1864,  0.0288,  0.0000,  0.0000,  0.0000],
        [-0.3607, -0.6797, -2.2817,  0.0000,  0.0000,  0.0000],
        [ 0.7754, -1.2716, -3.0341,  0.0000,  0.0000,  0.0000],
        [ 0.2378,  0.4908,  1.8317,  0.0000,  0.0000,  0.0000],
        [ 1.3089, -0.2426, -2.7646,  0.0000,  0.0000,  0.0000],
        [-1.1036, -1.3323, -1.0474,  0.0000,  0.0000,  0.0000],
        [-1.2178, -0.5166, -1.0027,  0.0000,  0.0000,  0.0000],
        [-0.1522,  0.4779, -2.2250,  0.0000,  0.0000,  0.0000],
        [ 1.4634,  0.8759, -1.1253,  0.0000,  0.0000,  0.0000],
        [-0.4420, -1.1267, -3.0094,  0.0000,  0.0000,  0.0000],
        [ 0.0903, -0.8209, -1.1093,  0.0000,  0.0000,  0.0000],
        [ 1.4427,  0.5636,  0.6649,  0.0000,  0.0000,  0.0000],
        [ 0.2145,  0.8205,  2.6615,  0.0000,  0.0000,  0.0000],
        [ 0.5766,  1.0710,  0.3287,  0.0000,  0.0000,  0.0000],
        [-0.3158,  0.5211, -0.4674,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
Iteration:  9
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0671, grad_fn=<DivBackward0>)
Projection Loss:  tensor(1836.4308, grad_fn=<AddBackward0>)
Total Loss:  tensor(1836.4979, grad_fn=<AddBackward0>)
Gradients:
6346.4677734375
Gradient before update: tensor(-9488.6924)
Gradient after update: tensor(-9488.6924)
Iteration:  10
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0538, grad_fn=<DivBackward0>)
Projection Loss:  tensor(1786.0746, grad_fn=<AddBackward0>)
Total Loss:  tensor(1786.1283, grad_fn=<AddBackward0>)
Gradients:
467.2804260253906
Gradient before update: tensor(-457.4500)
Gradient after update: tensor(-457.4500)
Total Loss:  tensor(1786.1283, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[-0.6989,  0.9509,  1.7099,  0.0000,  0.0000,  0.0000],
        [-1.2780,  0.3671,  1.4888,  0.0000,  0.0000,  0.0000],
        [-1.0097,  0.3219, -1.8358,  0.0000,  0.0000,  0.0000],
        [-1.1492, -0.2571,  2.7623,  0.0000,  0.0000,  0.0000],
        [ 0.6129, -0.1078,  1.8308,  0.0000,  0.0000,  0.0000],
        [ 1.1288,  0.3157, -1.4317,  0.0000,  0.0000,  0.0000],
        [-0.9006,  0.5788, -1.2109,  0.0000,  0.0000,  0.0000],
        [ 0.3435, -1.2901,  1.7194,  0.0000,  0.0000,  0.0000],
        [-0.0237,  0.0440,  1.3612,  0.0000,  0.0000,  0.0000],
        [-0.2388, -0.1078,  2.6576,  0.0000,  0.0000,  0.0000],
        [-1.0897,  0.9839,  0.3176,  0.0000,  0.0000,  0.0000],
        [ 0.4797,  0.2954, -0.7192,  0.0000,  0.0000,  0.0000],
        [ 0.5020, -0.5542,  1.0715,  0.0000,  0.0000,  0.0000],
        [-0.7972,  1.1257,  3.2634,  0.0000,  0.0000,  0.0000],
        [ 0.8409,  0.9026, -3.1559,  0.0000,  0.0000,  0.0000],
        [ 0.5172,  1.2781, -2.1234,  0.0000,  0.0000,  0.0000],
        [-0.1486,  0.8339,  0.4176,  0.0000,  0.0000,  0.0000],
        [ 0.9484,  0.6245, -3.6976,  0.0000,  0.0000,  0.0000],
        [-1.3157,  0.7990, -2.4191,  0.0000,  0.0000,  0.0000],
        [ 1.3003,  1.4370,  0.1535,  0.0000,  0.0000,  0.0000],
        [-0.0976, -0.2172, -2.7199,  0.0000,  0.0000,  0.0000],
        [-0.0342, -0.1850, -1.2454,  0.0000,  0.0000,  0.0000],
        [ 0.7135, -0.0806, -2.1213,  0.0000,  0.0000,  0.0000],
        [-0.8064, -0.1792,  1.5097,  0.0000,  0.0000,  0.0000],
        [-0.7220, -0.9060, -0.0465,  0.0000,  0.0000,  0.0000],
        [ 0.3591,  1.1189,  1.7055,  0.0000,  0.0000,  0.0000],
        [-1.6954, -0.2508,  2.1784,  0.0000,  0.0000,  0.0000],
        [-1.6592,  0.1035,  1.2358,  0.0000,  0.0000,  0.0000],
        [-0.5934, -0.5203,  0.5075,  0.0000,  0.0000,  0.0000],
        [ 0.0337, -1.4475, -2.2717,  0.0000,  0.0000,  0.0000],
        [-1.1010, -1.0507,  2.4947,  0.0000,  0.0000,  0.0000],
        [-0.4278,  1.1460, -1.9807,  0.0000,  0.0000,  0.0000],
        [ 0.0359,  0.9006, -0.4605,  0.0000,  0.0000,  0.0000],
        [-0.6014, -1.6092,  0.8994,  0.0000,  0.0000,  0.0000],
        [ 0.8967, -0.7618,  0.0785,  0.0000,  0.0000,  0.0000],
        [-0.5641,  0.2475,  0.0666,  0.0000,  0.0000,  0.0000],
        [-0.3728, -0.7400, -2.2766,  0.0000,  0.0000,  0.0000],
        [ 0.8242, -1.4016, -3.0667,  0.0000,  0.0000,  0.0000],
        [ 0.2404,  0.4618,  1.8782,  0.0000,  0.0000,  0.0000],
        [ 1.3608, -0.2925, -2.8140,  0.0000,  0.0000,  0.0000],
        [-1.1399, -1.3687, -1.0121,  0.0000,  0.0000,  0.0000],
        [-1.2927, -0.5928, -0.9232,  0.0000,  0.0000,  0.0000],
        [-0.1380,  0.4170, -2.2234,  0.0000,  0.0000,  0.0000],
        [ 1.5566,  0.9669, -1.0335,  0.0000,  0.0000,  0.0000],
        [-0.3816, -1.1030, -3.0663,  0.0000,  0.0000,  0.0000],
        [ 0.0239, -0.7882, -1.1694,  0.0000,  0.0000,  0.0000],
        [ 1.5299,  0.6169,  0.6390,  0.0000,  0.0000,  0.0000],
        [ 0.2574,  0.8599,  2.6958,  0.0000,  0.0000,  0.0000],
        [ 0.6096,  1.1073,  0.2931,  0.0000,  0.0000,  0.0000],
        [-0.3905,  0.4464, -0.3946,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
Iteration:  11
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0334, grad_fn=<DivBackward0>)
Projection Loss:  tensor(1768.1528, grad_fn=<AddBackward0>)
Total Loss:  tensor(1768.1862, grad_fn=<AddBackward0>)
Gradients:
406.07781982421875
Gradient before update: tensor(-441.5893)
Gradient after update: tensor(-441.5893)
Iteration:  12
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0210, grad_fn=<DivBackward0>)
Projection Loss:  tensor(1736.4381, grad_fn=<AddBackward0>)
Total Loss:  tensor(1736.4591, grad_fn=<AddBackward0>)
Gradients:
8837.8486328125
Gradient before update: tensor(11069.2139)
Gradient after update: tensor(11069.2139)
Total Loss:  tensor(1736.4591, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[-7.3555e-01,  9.5109e-01,  1.7496e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.3068e+00,  3.3828e-01,  1.4602e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0606e+00,  3.8675e-01, -1.8123e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2054e+00, -3.2473e-01,  2.7985e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.7026e-01, -1.0518e-01,  1.8344e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2650e+00,  3.3497e-01, -1.3530e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-8.8377e-01,  6.1502e-01, -1.2204e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.7586e-01, -1.3226e+00,  1.6871e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.6942e-03,  6.2414e-02,  1.3936e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-2.5485e-01, -6.2129e-02,  2.6970e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0421e+00,  1.0329e+00,  2.6784e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.0894e-01,  3.2463e-01, -7.4816e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.3138e-01, -5.6563e-01,  1.0305e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.9588e-01,  1.1947e+00,  3.1910e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.3875e-01,  8.9037e-01, -3.2487e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.5129e-01,  1.2113e+00, -2.0725e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0718e-01,  8.6262e-01,  3.8136e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0394e+00,  6.6436e-01, -3.7206e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.4006e+00,  7.1432e-01, -2.3329e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2003e+00,  1.5025e+00,  2.2984e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-9.7252e-02, -2.2443e-01, -2.7815e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.9539e-04, -8.2824e-02, -1.2556e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.3794e-01, -6.0786e-02, -2.1365e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-8.3629e-01, -1.3766e-01,  1.4907e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-8.1541e-01, -9.9758e-01,  4.1719e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 2.6052e-01,  1.1505e+00,  1.7263e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.7499e+00, -1.9675e-01,  2.2324e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.7167e+00,  4.9360e-02,  1.1822e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.6562e-01, -5.6067e-01,  5.1489e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.4577e-02, -1.4863e+00, -2.2943e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1324e+00, -1.0271e+00,  2.5233e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.7260e-01,  1.1727e+00, -1.9506e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-8.0429e-03,  8.5693e-01, -5.0243e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.5121e-01, -1.6768e+00,  8.3855e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.1063e-01, -8.1928e-01,  1.1744e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.9286e-01,  2.5358e-01,  1.9781e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.8268e-01, -7.8873e-01, -2.2726e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.1597e-01, -1.5091e+00, -2.9768e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 2.3738e-01,  4.4405e-01,  1.9173e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4032e+00, -3.3308e-01, -2.8536e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1693e+00, -1.3981e+00, -9.8350e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.3746e+00, -6.7387e-01, -9.3766e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2647e-01,  3.6769e-01, -2.2222e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.6319e+00,  1.0405e+00, -9.5932e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.3299e-01, -1.0841e+00, -3.1123e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-2.9501e-02, -7.8198e-01, -1.2157e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.6017e+00,  6.6000e-01,  6.1796e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 2.9213e-01,  8.9169e-01,  2.7235e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.3822e-01,  1.1372e+00,  2.6436e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.5074e-01,  3.8626e-01, -3.3970e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00]], requires_grad=True)
Iteration:  13
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0239, grad_fn=<DivBackward0>)
Projection Loss:  tensor(1698.2905, grad_fn=<AddBackward0>)
Total Loss:  tensor(1698.3145, grad_fn=<AddBackward0>)
Gradients:
9626.1826171875
Gradient before update: tensor(-3961.8657)
Gradient after update: tensor(-3961.8657)
Iteration:  14
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0600, grad_fn=<DivBackward0>)
Projection Loss:  tensor(1672.2057, grad_fn=<AddBackward0>)
Total Loss:  tensor(1672.2657, grad_fn=<AddBackward0>)
Gradients:
1357.5054931640625
Gradient before update: tensor(-1677.5562)
Gradient after update: tensor(-1677.5562)
Total Loss:  tensor(1672.2657, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[-7.6384e-01,  9.4797e-01,  1.7816e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.3304e+00,  3.1477e-01,  1.4369e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1037e+00,  4.3865e-01, -1.7974e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2497e+00, -3.8796e-01,  2.8340e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.6944e-01, -1.1029e-01,  1.8345e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.3722e+00,  2.9349e-01, -1.3058e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-8.4239e-01,  6.5900e-01, -1.1577e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.0340e-01, -1.3487e+00,  1.6608e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.6408e-03,  7.2319e-02,  1.4117e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-2.6797e-01, -2.4900e-02,  2.7292e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0033e+00,  1.0729e+00,  2.2722e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.0779e-01,  2.9668e-01, -7.8390e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.4437e-01, -5.6337e-01,  9.9699e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.9959e-01,  1.2548e+00,  3.1307e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0186e+00,  8.8046e-01, -3.3226e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.9783e-01,  1.1565e+00, -2.0348e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.3387e-02,  8.8602e-01,  3.5177e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1224e+00,  7.4727e-01, -3.6409e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.4704e+00,  6.4676e-01, -2.2649e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0882e+00,  1.5382e+00,  2.8678e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0391e-01, -2.3339e-01, -2.8333e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.4338e-02, -4.7175e-02, -1.2623e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.9763e-01, -9.5717e-02, -2.1359e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-8.5937e-01, -1.0537e-01,  1.4754e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-8.9166e-01, -1.0724e+00,  1.1261e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.5176e-01,  1.0585e+00,  1.6350e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.7946e+00, -1.5256e-01,  2.2758e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.7636e+00,  5.1670e-03,  1.1385e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.2338e-01, -5.9202e-01,  5.2568e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0792e-01, -1.5179e+00, -2.3128e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1580e+00, -1.0079e+00,  2.5467e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.6494e-01,  1.2651e+00, -2.0427e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.3893e-02,  8.2130e-01, -5.3696e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.0274e-01, -1.7338e+00,  7.9115e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.0248e-01, -8.9959e-01, -7.4094e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-8.1665e-01,  2.4649e-01,  3.4341e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.9070e-01, -8.2848e-01, -2.2692e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.5599e-01, -1.5002e+00, -2.9243e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 2.3489e-01,  4.2957e-01,  1.9492e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4482e+00, -3.6184e-01, -2.8851e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1932e+00, -1.4228e+00, -9.6043e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.4577e+00, -7.5760e-01, -1.0204e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1710e-01,  3.2748e-01, -2.2211e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.6960e+00,  1.1144e+00, -8.9926e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-2.9336e-01, -1.0692e+00, -3.1498e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.9136e-02, -8.1189e-01, -1.2528e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.6748e+00,  6.9529e-01,  6.0002e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.2120e-01,  9.1691e-01,  2.7464e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.2742e-01,  1.2286e+00,  3.6010e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.9982e-01,  3.3725e-01, -2.9660e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00]], requires_grad=True)
Iteration:  15
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.1401, grad_fn=<DivBackward0>)
Projection Loss:  tensor(1674.8810, grad_fn=<AddBackward0>)
Total Loss:  tensor(1675.0211, grad_fn=<AddBackward0>)
Gradients:
307.7339782714844
Gradient before update: tensor(-27.3535)
Gradient after update: tensor(-27.3535)
Iteration:  16
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.2100, grad_fn=<DivBackward0>)
Projection Loss:  tensor(1674.6970, grad_fn=<AddBackward0>)
Total Loss:  tensor(1674.9071, grad_fn=<AddBackward0>)
Gradients:
10627.6123046875
Gradient before update: tensor(2891.0273)
Gradient after update: tensor(2891.0273)
Total Loss:  tensor(1674.9071, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[-0.7828,  0.9414,  1.8096,  0.0000,  0.0000,  0.0000],
        [-1.3497,  0.2955,  1.4178,  0.0000,  0.0000,  0.0000],
        [-1.1318,  0.4791, -1.7790,  0.0000,  0.0000,  0.0000],
        [-1.3162, -0.2948,  2.9277,  0.0000,  0.0000,  0.0000],
        [ 0.6257, -0.1210,  1.8322,  0.0000,  0.0000,  0.0000],
        [ 1.4662,  0.2125, -1.2820,  0.0000,  0.0000,  0.0000],
        [-0.7988,  0.6985, -1.0869,  0.0000,  0.0000,  0.0000],
        [ 0.4064, -1.3588,  1.6425,  0.0000,  0.0000,  0.0000],
        [ 0.0114,  0.0758,  1.4192,  0.0000,  0.0000,  0.0000],
        [-0.2788,  0.0057,  2.7557,  0.0000,  0.0000,  0.0000],
        [-0.9721,  1.1058,  0.1939,  0.0000,  0.0000,  0.0000],
        [ 0.5811,  0.2934, -0.7438,  0.0000,  0.0000,  0.0000],
        [ 0.5269, -0.5511,  0.9700,  0.0000,  0.0000,  0.0000],
        [-0.8122,  1.3155,  3.0747,  0.0000,  0.0000,  0.0000],
        [ 1.0839,  0.8725, -3.3781,  0.0000,  0.0000,  0.0000],
        [ 0.3542,  1.1111, -2.0085,  0.0000,  0.0000,  0.0000],
        [-0.0457,  0.9052,  0.3275,  0.0000,  0.0000,  0.0000],
        [ 1.1906,  0.8153, -3.5791,  0.0000,  0.0000,  0.0000],
        [-1.5343,  0.6124, -2.1916,  0.0000,  0.0000,  0.0000],
        [ 1.0332,  1.5453,  0.3600,  0.0000,  0.0000,  0.0000],
        [-0.1155, -0.2438, -2.8770,  0.0000,  0.0000,  0.0000],
        [ 0.0991, -0.0184, -1.2678,  0.0000,  0.0000,  0.0000],
        [ 0.8881, -0.1901, -2.1352,  0.0000,  0.0000,  0.0000],
        [-0.8678, -0.0901,  1.4637,  0.0000,  0.0000,  0.0000],
        [-0.9527, -1.1342,  0.1684,  0.0000,  0.0000,  0.0000],
        [ 0.4267,  0.9829,  1.5600,  0.0000,  0.0000,  0.0000],
        [-1.7707, -0.1812,  2.2614,  0.0000,  0.0000,  0.0000],
        [-1.8021, -0.0311,  1.1026,  0.0000,  0.0000,  0.0000],
        [-0.7653, -0.6155,  0.5407,  0.0000,  0.0000,  0.0000],
        [ 0.1366, -1.5458, -2.3229,  0.0000,  0.0000,  0.0000],
        [-1.1791, -0.9920,  2.5658,  0.0000,  0.0000,  0.0000],
        [-0.6406,  1.3408, -2.1183,  0.0000,  0.0000,  0.0000],
        [-0.0734,  0.7919, -0.5644,  0.0000,  0.0000,  0.0000],
        [-0.4245, -1.7155,  0.7153,  0.0000,  0.0000,  0.0000],
        [ 0.8967, -0.9649, -0.1449,  0.0000,  0.0000,  0.0000],
        [-0.9183,  0.2407,  0.4630,  0.0000,  0.0000,  0.0000],
        [-0.3973, -0.8610, -2.2665,  0.0000,  0.0000,  0.0000],
        [ 0.9575, -1.4186, -2.8994,  0.0000,  0.0000,  0.0000],
        [ 0.2390,  0.4240,  1.9984,  0.0000,  0.0000,  0.0000],
        [ 1.5418, -0.4561, -2.8403,  0.0000,  0.0000,  0.0000],
        [-1.2128, -1.4429, -0.9415,  0.0000,  0.0000,  0.0000],
        [-1.5259, -0.8264, -1.0883,  0.0000,  0.0000,  0.0000],
        [-0.1094,  0.2945, -2.2203,  0.0000,  0.0000,  0.0000],
        [ 1.7464,  1.2070, -0.8385,  0.0000,  0.0000,  0.0000],
        [-0.2606, -1.0743, -3.1806,  0.0000,  0.0000,  0.0000],
        [-0.0994, -0.8387, -1.2826,  0.0000,  0.0000,  0.0000],
        [ 1.5827,  0.7905,  0.5055,  0.0000,  0.0000,  0.0000],
        [ 0.3452,  0.9375,  2.7653,  0.0000,  0.0000,  0.0000],
        [ 0.6448,  1.3230,  0.4686,  0.0000,  0.0000,  0.0000],
        [-0.5401,  0.2970, -0.2613,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
Iteration:  17
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.2799, grad_fn=<DivBackward0>)
Projection Loss:  tensor(1674.0090, grad_fn=<AddBackward0>)
Total Loss:  tensor(1674.2889, grad_fn=<AddBackward0>)
Gradients:
93.79866027832031
Gradient before update: tensor(84.0738)
Gradient after update: tensor(84.0738)
Iteration:  18
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.3368, grad_fn=<DivBackward0>)
Projection Loss:  tensor(1675.0477, grad_fn=<AddBackward0>)
Total Loss:  tensor(1675.3845, grad_fn=<AddBackward0>)
Gradients:
383.5707702636719
Gradient before update: tensor(-134.4460)
Gradient after update: tensor(-134.4460)
Total Loss:  tensor(1675.3845, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[-0.7904,  0.9348,  1.8346,  0.0000,  0.0000,  0.0000],
        [-1.3656,  0.2796,  1.4020,  0.0000,  0.0000,  0.0000],
        [-1.1353,  0.5087, -1.7497,  0.0000,  0.0000,  0.0000],
        [-1.3677, -0.2181,  3.0049,  0.0000,  0.0000,  0.0000],
        [ 0.5896, -0.1299,  1.8303,  0.0000,  0.0000,  0.0000],
        [ 1.5388,  0.1422, -1.2608,  0.0000,  0.0000,  0.0000],
        [-0.7477,  0.7317, -1.0282,  0.0000,  0.0000,  0.0000],
        [ 0.3867, -1.3262,  1.6477,  0.0000,  0.0000,  0.0000],
        [ 0.0178,  0.0787,  1.4253,  0.0000,  0.0000,  0.0000],
        [-0.2880,  0.0308,  2.7775,  0.0000,  0.0000,  0.0000],
        [-0.9470,  1.1328,  0.1663,  0.0000,  0.0000,  0.0000],
        [ 0.6863,  0.3035, -0.8238,  0.0000,  0.0000,  0.0000],
        [ 0.4963, -0.5649,  0.9482,  0.0000,  0.0000,  0.0000],
        [-0.8261,  1.3511,  3.0305,  0.0000,  0.0000,  0.0000],
        [ 1.1374,  0.8662, -3.4161,  0.0000,  0.0000,  0.0000],
        [ 0.3138,  1.0777, -1.9577,  0.0000,  0.0000,  0.0000],
        [-0.0111,  1.0010,  0.4071,  0.0000,  0.0000,  0.0000],
        [ 1.2470,  0.8713, -3.5333,  0.0000,  0.0000,  0.0000],
        [-1.6197,  0.6573, -2.0991,  0.0000,  0.0000,  0.0000],
        [ 1.0123,  1.5321,  0.4435,  0.0000,  0.0000,  0.0000],
        [-0.1421, -0.2575, -2.9162,  0.0000,  0.0000,  0.0000],
        [ 0.1360,  0.0052, -1.2723,  0.0000,  0.0000,  0.0000],
        [ 0.9668, -0.2822, -2.1432,  0.0000,  0.0000,  0.0000],
        [-0.8634, -0.0854,  1.4556,  0.0000,  0.0000,  0.0000],
        [-1.0017, -1.1855,  0.2124,  0.0000,  0.0000,  0.0000],
        [ 0.5174,  0.9052,  1.4698,  0.0000,  0.0000,  0.0000],
        [-1.6911, -0.2650,  2.1791,  0.0000,  0.0000,  0.0000],
        [-1.8341, -0.0610,  1.0730,  0.0000,  0.0000,  0.0000],
        [-0.6882, -0.5658,  0.5152,  0.0000,  0.0000,  0.0000],
        [ 0.1606, -1.5694, -2.3261,  0.0000,  0.0000,  0.0000],
        [-1.1964, -0.9789,  2.5817,  0.0000,  0.0000,  0.0000],
        [-0.7028,  1.4033, -2.1805,  0.0000,  0.0000,  0.0000],
        [-0.0978,  0.7676, -0.5871,  0.0000,  0.0000,  0.0000],
        [-0.4317, -1.6946,  0.6248,  0.0000,  0.0000,  0.0000],
        [ 0.8920, -1.0182, -0.2033,  0.0000,  0.0000,  0.0000],
        [-1.0021,  0.2359,  0.5616,  0.0000,  0.0000,  0.0000],
        [-0.4027, -0.8874, -2.2642,  0.0000,  0.0000,  0.0000],
        [ 0.9589, -1.3516, -2.8788,  0.0000,  0.0000,  0.0000],
        [ 0.2456,  0.4212,  2.0390,  0.0000,  0.0000,  0.0000],
        [ 1.6071, -0.5360, -2.7971,  0.0000,  0.0000,  0.0000],
        [-1.2290, -1.4596, -0.9258,  0.0000,  0.0000,  0.0000],
        [-1.5823, -0.8832, -1.1443,  0.0000,  0.0000,  0.0000],
        [-0.1031,  0.2673, -2.2196,  0.0000,  0.0000,  0.0000],
        [ 1.7836,  1.3006, -0.7776,  0.0000,  0.0000,  0.0000],
        [-0.2327, -1.0886, -3.2063,  0.0000,  0.0000,  0.0000],
        [-0.1008, -0.9384, -1.2847,  0.0000,  0.0000,  0.0000],
        [ 1.5067,  0.8692,  0.4272,  0.0000,  0.0000,  0.0000],
        [ 0.3649,  0.9545,  2.7808,  0.0000,  0.0000,  0.0000],
        [ 0.5787,  1.3977,  0.5747,  0.0000,  0.0000,  0.0000],
        [-0.5732,  0.2644, -0.2321,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
Iteration:  19
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.3727, grad_fn=<DivBackward0>)
Projection Loss:  tensor(1674.9076, grad_fn=<AddBackward0>)
Total Loss:  tensor(1675.2803, grad_fn=<AddBackward0>)
Gradients:
390.0967712402344
Gradient before update: tensor(315.9201)
Gradient after update: tensor(315.9201)
Final Learning Rate:  0.1
