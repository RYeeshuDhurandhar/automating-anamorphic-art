lr=0.1
if i%15 == 0:
    optimizer.param_groups[0]['lr'] = optimizer.param_groups[0]['lr'] / 2  # Set the learning rate to 0.01 after 10 epochs



parameters.grad:  None
Iteration:  1
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(4.3369, grad_fn=<DivBackward0>)
Projection Loss:  tensor(1487.0358, grad_fn=<AddBackward0>)
Total Loss:  tensor(1491.3727, grad_fn=<AddBackward0>)
Gradients:
181.97854614257812
Gradient before update: tensor(-257.4526)
Gradient after update: tensor(-257.4526)
current Learning Rate:  0.1
------------------------------------------------------------------------------------------------------------------
Iteration:  2
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.9712, grad_fn=<DivBackward0>)
Projection Loss:  tensor(1369.0015, grad_fn=<AddBackward0>)
Total Loss:  tensor(1369.9727, grad_fn=<AddBackward0>)
Gradients:
11.513127326965332
Gradient before update: tensor(-4.2650)
Gradient after update: tensor(-4.2650)
current Learning Rate:  0.1
Total Loss:  tensor(1369.9727, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[-0.0158,  0.7767, -3.0646,  0.0000,  0.0000,  0.0000],
        [-0.1302,  0.7696,  1.8243,  0.0000,  0.0000,  0.0000],
        [-1.1234, -0.2430,  2.3667,  0.0000,  0.0000,  0.0000],
        [ 1.0465, -0.1822,  2.0489,  0.0000,  0.0000,  0.0000],
        [ 0.7150, -0.1357,  1.0387,  0.0000,  0.0000,  0.0000],
        [ 0.7575, -0.0927, -0.6567,  0.0000,  0.0000,  0.0000],
        [-0.0084,  0.3533, -0.8496,  0.0000,  0.0000,  0.0000],
        [ 0.8029,  0.4047,  0.2664,  0.0000,  0.0000,  0.0000],
        [-0.6099, -0.9790, -1.3779,  0.0000,  0.0000,  0.0000],
        [ 1.0122, -0.0934,  1.5620,  0.0000,  0.0000,  0.0000],
        [-0.9635, -0.7839, -3.0758,  0.0000,  0.0000,  0.0000],
        [-0.7036, -0.1248,  1.5095,  0.0000,  0.0000,  0.0000],
        [-0.0039,  0.0354, -2.2953,  0.0000,  0.0000,  0.0000],
        [ 1.0948,  0.1185,  2.5886,  0.0000,  0.0000,  0.0000],
        [-0.7446, -0.2600, -2.5847,  0.0000,  0.0000,  0.0000],
        [-0.8030,  0.9933, -2.9980,  0.0000,  0.0000,  0.0000],
        [ 0.9489,  1.0715,  2.5922,  0.0000,  0.0000,  0.0000],
        [ 0.0573, -0.5982,  2.3943,  0.0000,  0.0000,  0.0000],
        [-0.4744,  0.5856, -2.2338,  0.0000,  0.0000,  0.0000],
        [-0.0844, -0.9698,  0.7063,  0.0000,  0.0000,  0.0000],
        [ 0.8301,  0.4750, -0.4040,  0.0000,  0.0000,  0.0000],
        [-0.7552,  0.6115,  1.4956,  0.0000,  0.0000,  0.0000],
        [ 0.4720,  1.0333, -1.0910,  0.0000,  0.0000,  0.0000],
        [ 0.0043,  0.8835, -1.7954,  0.0000,  0.0000,  0.0000],
        [-0.7760, -0.1574, -1.5087,  0.0000,  0.0000,  0.0000],
        [ 0.2939, -0.1476, -2.7439,  0.0000,  0.0000,  0.0000],
        [-0.8694, -0.7170, -0.6448,  0.0000,  0.0000,  0.0000],
        [-0.0365,  0.3075, -1.4207,  0.0000,  0.0000,  0.0000],
        [ 1.1676, -0.6096,  0.5625,  0.0000,  0.0000,  0.0000],
        [ 0.2381, -0.5546,  1.8235,  0.0000,  0.0000,  0.0000],
        [-0.3813, -0.5011,  1.8947,  0.0000,  0.0000,  0.0000],
        [ 0.2632,  1.0093, -2.2376,  0.0000,  0.0000,  0.0000],
        [ 0.4077, -0.8832, -1.1315,  0.0000,  0.0000,  0.0000],
        [ 1.0282,  0.5066, -2.4917,  0.0000,  0.0000,  0.0000],
        [-1.0782, -1.1586, -0.1407,  0.0000,  0.0000,  0.0000],
        [-1.0469,  0.4081, -2.3780,  0.0000,  0.0000,  0.0000],
        [ 0.6151,  0.3985,  1.3960,  0.0000,  0.0000,  0.0000],
        [ 1.0844, -0.8813,  1.5788,  0.0000,  0.0000,  0.0000],
        [-0.4462, -0.5685, -2.0341,  0.0000,  0.0000,  0.0000],
        [-0.7240, -0.8631,  2.9875,  0.0000,  0.0000,  0.0000],
        [ 0.7084,  0.3224, -1.4650,  0.0000,  0.0000,  0.0000],
        [ 0.4507, -0.9842, -0.0064,  0.0000,  0.0000,  0.0000],
        [-0.7517,  1.0677, -0.6666,  0.0000,  0.0000,  0.0000],
        [ 0.5292, -0.8648,  1.2417,  0.0000,  0.0000,  0.0000],
        [ 1.1005, -1.1617, -2.0305,  0.0000,  0.0000,  0.0000],
        [-1.0481, -1.0880,  1.3232,  0.0000,  0.0000,  0.0000],
        [-0.1585,  0.8716,  0.8594,  0.0000,  0.0000,  0.0000],
        [-0.6772,  0.3979,  2.1645,  0.0000,  0.0000,  0.0000],
        [ 0.2500, -1.1476, -2.4760,  0.0000,  0.0000,  0.0000],
        [-0.0464,  0.0608, -0.1234,  0.0000,  0.0000,  0.0000],
        [-1.1568, -1.0504,  0.5590,  0.0000,  0.0000,  0.0000],
        [ 0.8815,  0.2319, -1.9299,  0.0000,  0.0000,  0.0000],
        [-0.1370, -0.5811, -0.6089,  0.0000,  0.0000,  0.0000],
        [ 0.1700, -1.1575, -1.7062,  0.0000,  0.0000,  0.0000],
        [-0.6047,  0.1904,  0.3917,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  3
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.4769, grad_fn=<DivBackward0>)
Projection Loss:  tensor(1260.0546, grad_fn=<AddBackward0>)
Total Loss:  tensor(1260.5315, grad_fn=<AddBackward0>)
Gradients:
129.27354431152344
Gradient before update: tensor(-112.6779)
Gradient after update: tensor(-112.6779)
current Learning Rate:  0.1
------------------------------------------------------------------------------------------------------------------
Iteration:  4
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.2388, grad_fn=<DivBackward0>)
Projection Loss:  tensor(1190.8308, grad_fn=<AddBackward0>)
Total Loss:  tensor(1191.0696, grad_fn=<AddBackward0>)
Gradients:
1923.6314697265625
Gradient before update: tensor(2691.2178)
Gradient after update: tensor(2691.2178)
current Learning Rate:  0.1
Total Loss:  tensor(1191.0696, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.1053,  0.6813, -3.1789,  0.0000,  0.0000,  0.0000],
        [-0.2022,  0.9367,  1.9245,  0.0000,  0.0000,  0.0000],
        [-1.2285, -0.3498,  2.4739,  0.0000,  0.0000,  0.0000],
        [ 1.1383, -0.1394,  2.2165,  0.0000,  0.0000,  0.0000],
        [ 0.5729, -0.0612,  0.9040,  0.0000,  0.0000,  0.0000],
        [ 0.8029, -0.0768, -0.6568,  0.0000,  0.0000,  0.0000],
        [ 0.0948,  0.2606, -0.6822,  0.0000,  0.0000,  0.0000],
        [ 0.8411,  0.2626,  0.3965,  0.0000,  0.0000,  0.0000],
        [-0.5238, -1.1363, -1.4454,  0.0000,  0.0000,  0.0000],
        [ 1.2045,  0.0237,  1.5348,  0.0000,  0.0000,  0.0000],
        [-1.1448, -0.9393, -3.2397,  0.0000,  0.0000,  0.0000],
        [-0.7436, -0.2451,  1.3833,  0.0000,  0.0000,  0.0000],
        [ 0.0832, -0.0675, -2.2685,  0.0000,  0.0000,  0.0000],
        [ 1.2065,  0.3150,  2.7784,  0.0000,  0.0000,  0.0000],
        [-0.8507, -0.3783, -2.7370,  0.0000,  0.0000,  0.0000],
        [-0.9709,  0.9317, -3.0923,  0.0000,  0.0000,  0.0000],
        [ 1.0551,  1.1815,  2.4831,  0.0000,  0.0000,  0.0000],
        [ 0.1706, -0.7249,  2.5168,  0.0000,  0.0000,  0.0000],
        [-0.5589,  0.7235, -2.2931,  0.0000,  0.0000,  0.0000],
        [-0.1902, -1.0763,  0.5997,  0.0000,  0.0000,  0.0000],
        [ 0.9703,  0.5462, -0.2998,  0.0000,  0.0000,  0.0000],
        [-0.8727,  0.7035,  1.5340,  0.0000,  0.0000,  0.0000],
        [ 0.6079,  1.0502, -1.0795,  0.0000,  0.0000,  0.0000],
        [ 0.0151,  0.9335, -1.7015,  0.0000,  0.0000,  0.0000],
        [-0.9241, -0.0377, -1.5810,  0.0000,  0.0000,  0.0000],
        [ 0.4475, -0.3339, -2.9298,  0.0000,  0.0000,  0.0000],
        [-1.0588, -0.6174, -0.5445,  0.0000,  0.0000,  0.0000],
        [-0.0866,  0.1663, -1.3561,  0.0000,  0.0000,  0.0000],
        [ 1.1787, -0.7455,  0.4563,  0.0000,  0.0000,  0.0000],
        [ 0.2024, -0.5774,  1.7335,  0.0000,  0.0000,  0.0000],
        [-0.4145, -0.4725,  1.9356,  0.0000,  0.0000,  0.0000],
        [ 0.2840,  1.0563, -2.3576,  0.0000,  0.0000,  0.0000],
        [ 0.5068, -0.9568, -1.1521,  0.0000,  0.0000,  0.0000],
        [ 1.1713,  0.3684, -2.5779,  0.0000,  0.0000,  0.0000],
        [-1.1955, -1.2795, -0.0416,  0.0000,  0.0000,  0.0000],
        [-1.1656,  0.5243, -2.4916,  0.0000,  0.0000,  0.0000],
        [ 0.6879,  0.5099,  1.3394,  0.0000,  0.0000,  0.0000],
        [ 1.2408, -0.9965,  1.6258,  0.0000,  0.0000,  0.0000],
        [-0.5370, -0.4764, -2.1305,  0.0000,  0.0000,  0.0000],
        [-0.8182, -0.9573,  3.0817,  0.0000,  0.0000,  0.0000],
        [ 0.6121,  0.2383, -1.4000,  0.0000,  0.0000,  0.0000],
        [ 0.5527, -1.0935,  0.0967,  0.0000,  0.0000,  0.0000],
        [-0.7517,  1.0652, -0.5647,  0.0000,  0.0000,  0.0000],
        [ 0.5277, -1.0022,  1.2617,  0.0000,  0.0000,  0.0000],
        [ 1.1038, -1.2776, -1.8953,  0.0000,  0.0000,  0.0000],
        [-1.1363, -1.1932,  1.2719,  0.0000,  0.0000,  0.0000],
        [-0.0618,  0.9890,  0.7619,  0.0000,  0.0000,  0.0000],
        [-0.5800,  0.5108,  2.3079,  0.0000,  0.0000,  0.0000],
        [ 0.1751, -1.2471, -2.6156,  0.0000,  0.0000,  0.0000],
        [-0.0487,  0.1071, -0.0985,  0.0000,  0.0000,  0.0000],
        [-1.2765, -0.9332,  0.6600,  0.0000,  0.0000,  0.0000],
        [ 1.0474,  0.0806, -2.0018,  0.0000,  0.0000,  0.0000],
        [-0.2372, -0.4646, -0.7080,  0.0000,  0.0000,  0.0000],
        [ 0.2680, -1.2936, -1.6361,  0.0000,  0.0000,  0.0000],
        [-0.5750,  0.1712,  0.4709,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  5
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.1012, grad_fn=<DivBackward0>)
Projection Loss:  tensor(1128.9628, grad_fn=<AddBackward0>)
Total Loss:  tensor(1129.0640, grad_fn=<AddBackward0>)
Gradients:
59.909454345703125
Gradient before update: tensor(25.5196)
Gradient after update: tensor(25.5196)
current Learning Rate:  0.1
------------------------------------------------------------------------------------------------------------------
Iteration:  6
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0564, grad_fn=<DivBackward0>)
Projection Loss:  tensor(1073.4895, grad_fn=<AddBackward0>)
Total Loss:  tensor(1073.5459, grad_fn=<AddBackward0>)
Gradients:
516.9066162109375
Gradient before update: tensor(627.7189)
Gradient after update: tensor(627.7189)
current Learning Rate:  0.1
Total Loss:  tensor(1073.5459, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 1.9111e-01,  6.1375e-01, -3.2600e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.9649e-01,  8.4659e-01,  1.9499e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.3412e+00, -3.1374e-01,  2.5625e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2038e+00, -1.2698e-01,  2.3466e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.3703e-01, -4.5726e-02,  8.2119e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.2688e-01, -7.7800e-02, -6.6903e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 2.1634e-01,  2.7504e-01, -6.2828e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.6498e-01,  3.2545e-01,  4.2043e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.3077e-01, -1.2662e+00, -1.4784e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2754e+00,  9.2358e-02,  1.4787e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2734e+00, -1.0494e+00, -3.3559e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-8.1460e-01, -3.1388e-01,  1.2824e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4565e-01, -1.3636e-01, -2.2445e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2938e+00,  4.8765e-01,  2.9339e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-9.5285e-01, -4.5398e-01, -2.8905e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1018e+00,  9.2439e-01, -3.1790e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1735e+00,  1.1540e+00,  2.4222e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 2.5055e-01, -8.1497e-01,  2.6128e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.9478e-01,  8.2893e-01, -2.3026e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-2.6526e-01, -1.1560e+00,  5.2406e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0860e+00,  6.2678e-01, -2.3066e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-9.5589e-01,  7.6864e-01,  1.5612e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.2011e-01,  9.6710e-01, -1.1682e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.8501e-02,  9.0860e-01, -1.6261e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0321e+00,  4.7293e-02, -1.6324e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.7020e-01, -4.8286e-01, -3.0685e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2030e+00, -5.4793e-01, -4.7291e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.7334e-01,  6.3150e-02, -1.3246e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0967e+00, -8.5578e-01,  3.8309e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.9979e-01, -5.6458e-01,  1.6581e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.6755e-01, -4.7178e-01,  2.0312e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.0898e-01,  9.9541e-01, -2.4776e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.5269e-01, -9.7836e-01, -1.0864e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2734e+00,  2.7694e-01, -2.6832e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2880e+00, -1.3722e+00,  3.1669e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2535e+00,  6.0871e-01, -2.5732e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.3197e-01,  6.2887e-01,  1.3197e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.3565e+00, -1.0783e+00,  1.6654e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.9308e-01, -4.1983e-01, -2.1580e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-8.8502e-01, -1.0241e+00,  3.1485e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.2514e-01,  1.8692e-01, -1.3437e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.2044e-01, -1.1847e+00,  1.6674e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.7059e-01,  9.7617e-01, -4.6750e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.5057e-01, -1.1007e+00,  1.2478e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0128e+00, -1.3696e+00, -1.8037e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1833e+00, -1.3002e+00,  1.3120e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.4531e-02,  8.8314e-01,  6.3661e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.9793e-01,  5.8075e-01,  2.4351e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2156e-01, -1.3179e+00, -2.7145e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.4837e-03, -1.7208e-03, -6.4236e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.3758e+00, -8.4507e-01,  6.5433e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1670e+00, -6.4952e-02, -2.0291e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.0821e-01, -3.8204e-01, -7.7823e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.2589e-01, -1.4235e+00, -1.6551e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.7462e-01,  2.8670e-01,  5.7005e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00]], requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  7
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0444, grad_fn=<DivBackward0>)
Projection Loss:  tensor(1015.6955, grad_fn=<AddBackward0>)
Total Loss:  tensor(1015.7399, grad_fn=<AddBackward0>)
Gradients:
413.4593200683594
Gradient before update: tensor(208.1528)
Gradient after update: tensor(208.1528)
current Learning Rate:  0.1
------------------------------------------------------------------------------------------------------------------
Iteration:  8
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0655, grad_fn=<DivBackward0>)
Projection Loss:  tensor(965.9497, grad_fn=<AddBackward0>)
Total Loss:  tensor(966.0153, grad_fn=<AddBackward0>)
Gradients:
30.544343948364258
Gradient before update: tensor(-3.8280)
Gradient after update: tensor(-3.8280)
current Learning Rate:  0.1
Total Loss:  tensor(966.0153, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 2.5637e-01,  5.6235e-01, -3.3216e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.7692e-01,  7.8031e-01,  1.9192e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.4516e+00, -2.0961e-01,  2.6790e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1086e+00, -3.1583e-02,  2.4566e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.2131e-01, -3.9479e-02,  7.6449e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.0452e-01, -8.7814e-02, -6.6632e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.0102e-01,  3.4600e-01, -6.2073e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0743e+00,  3.6686e-01,  4.4682e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.0766e-01, -1.3795e+00, -1.5171e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1798e+00, -5.8888e-04,  1.3792e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.3721e+00, -1.1332e+00, -3.4443e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-8.6989e-01, -3.6601e-01,  1.2051e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.9404e-01, -1.8849e-01, -2.2263e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.3626e+00,  6.2453e-01,  3.0524e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0319e+00, -5.1154e-01, -3.0095e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1983e+00,  1.0199e+00, -3.0871e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2843e+00,  1.0796e+00,  2.3357e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.1137e-01, -8.8350e-01,  2.6859e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.1676e-01,  9.1105e-01, -2.2979e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.2236e-01, -1.2165e+00,  4.6652e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1813e+00,  6.9952e-01, -1.9559e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0192e+00,  8.1822e-01,  1.5819e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.0540e-01,  9.0389e-01, -1.2356e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.1332e-02,  8.8973e-01, -1.5687e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1217e+00,  1.1203e-01, -1.6715e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.6367e-01, -5.9611e-01, -3.1740e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.3127e+00, -4.9508e-01, -4.1848e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-2.4804e-01,  8.9692e-03, -1.3081e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0410e+00, -9.2007e-01,  3.3769e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.9891e-01, -5.2872e-01,  1.6026e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.1325e-01, -4.7008e-01,  2.1078e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.4359e-01,  9.1220e-01, -2.5743e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.7091e-01, -9.9180e-01, -1.0314e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2817e+00,  2.5748e-01, -2.6435e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.3850e+00, -1.2909e+00, -5.9203e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.3473e+00,  6.8499e-01, -2.6390e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.6433e-01,  7.2246e-01,  1.3043e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4602e+00, -9.9441e-01,  1.7272e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.3508e-01, -3.7691e-01, -2.1773e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-9.3577e-01, -1.0749e+00,  3.1993e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.3529e-01,  1.5151e-01, -1.3067e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.3162e-01, -1.3249e+00,  2.0130e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.9994e-01,  9.1489e-01, -3.5356e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.7743e-01, -1.1855e+00,  1.2293e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.4461e-01, -1.4401e+00, -1.7336e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1533e+00, -1.4033e+00,  1.3499e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1846e-01,  7.9623e-01,  5.2212e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.6622e-01,  6.2861e-01,  2.5531e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.0024e-02, -1.3764e+00, -2.7897e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2468e-03, -1.4233e-01,  2.1437e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.4530e+00, -7.7546e-01,  6.4474e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1738e+00, -1.3047e-01, -2.0407e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.5988e-01, -4.2960e-01, -8.1962e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.3255e-01, -1.5339e+00, -1.6616e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.5042e-01,  3.7448e-01,  6.4548e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00]], requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  9
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0840, grad_fn=<DivBackward0>)
Projection Loss:  tensor(920.9499, grad_fn=<AddBackward0>)
Total Loss:  tensor(921.0339, grad_fn=<AddBackward0>)
Gradients:
19.48027801513672
Gradient before update: tensor(18.9591)
Gradient after update: tensor(18.9591)
current Learning Rate:  0.1
------------------------------------------------------------------------------------------------------------------
Iteration:  10
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.1089, grad_fn=<DivBackward0>)
Projection Loss:  tensor(889.9922, grad_fn=<AddBackward0>)
Total Loss:  tensor(890.1011, grad_fn=<AddBackward0>)
Gradients:
480.2732849121094
Gradient before update: tensor(-131.7835)
Gradient after update: tensor(-131.7835)
current Learning Rate:  0.1
Total Loss:  tensor(890.1011, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 3.0774e-01,  5.2190e-01, -3.3701e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.6150e-01,  7.2867e-01,  1.8895e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.5673e+00, -7.6890e-02,  2.7756e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0337e+00,  4.3505e-02,  2.5432e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 2.3151e-01, -3.4101e-02,  7.2064e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.8933e-01, -1.0078e-01, -6.4350e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.5181e-01,  4.1773e-01, -6.1473e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1476e+00,  3.6641e-01,  4.9450e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.9662e-01, -1.5067e+00, -1.4531e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1045e+00, -7.3750e-02,  1.3009e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.4565e+00, -1.1989e+00, -3.5136e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-9.1340e-01, -4.0704e-01,  1.1443e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 2.3213e-01, -2.2951e-01, -2.2119e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4197e+00,  7.3307e-01,  3.1456e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0942e+00, -5.5684e-01, -3.1031e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2987e+00,  1.1204e+00, -3.0900e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.3715e+00,  1.0208e+00,  2.2677e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 2.2392e-01, -7.9776e-01,  2.7187e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.3402e-01,  9.7683e-01, -2.2941e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.6710e-01, -1.2602e+00,  4.2119e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2611e+00,  7.6669e-01, -1.8404e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0690e+00,  8.5725e-01,  1.5982e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.7255e-01,  8.5415e-01, -1.2887e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1351e-01,  8.7591e-01, -1.5235e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2108e+00,  1.6392e-01, -1.7035e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.3739e-01, -6.8523e-01, -3.2570e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.3991e+00, -4.5349e-01, -3.7564e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-2.9567e-01, -7.2502e-03, -1.3068e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0072e+00, -9.2610e-01,  3.1061e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.9822e-01, -5.0055e-01,  1.5590e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.4925e-01, -4.6924e-01,  2.1681e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.7593e-01,  8.3602e-01, -2.6546e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.6396e-01, -1.0024e+00, -9.8808e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2316e+00,  3.0950e-01, -2.5549e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.4614e+00, -1.2283e+00, -1.3060e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.4240e+00,  7.4625e-01, -2.6862e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.8980e-01,  7.9612e-01,  1.2923e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4676e+00, -9.9447e-01,  1.8241e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.6815e-01, -3.4309e-01, -2.1925e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-9.7481e-01, -1.1096e+00,  3.2393e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.3461e-01,  1.2649e-01, -1.2848e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.9414e-01, -1.4936e+00,  2.0921e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.4424e-01,  8.6710e-01, -2.6109e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.9858e-01, -1.2524e+00,  1.2147e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.9258e-01, -1.4960e+00, -1.6782e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0729e+00, -1.5075e+00,  1.3834e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.7666e-01,  7.2782e-01,  4.3200e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.1342e-01,  6.6464e-01,  2.6483e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 2.9274e-02, -1.4228e+00, -2.8488e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-2.8722e-03, -2.5789e-01,  8.6270e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.5247e+00, -7.1002e-01,  6.4257e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1207e+00, -1.6972e-01, -2.0377e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.0424e-01, -5.2790e-01, -8.2823e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.9977e-01, -1.6655e+00, -1.6570e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-8.1005e-01,  4.4224e-01,  7.0486e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00]], requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  11
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.1030, grad_fn=<DivBackward0>)
Projection Loss:  tensor(861.5108, grad_fn=<AddBackward0>)
Total Loss:  tensor(861.6138, grad_fn=<AddBackward0>)
Gradients:
1057.514892578125
Gradient before update: tensor(1119.9004)
Gradient after update: tensor(1119.9004)
current Learning Rate:  0.1
------------------------------------------------------------------------------------------------------------------
Iteration:  12
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0964, grad_fn=<DivBackward0>)
Projection Loss:  tensor(820.2340, grad_fn=<AddBackward0>)
Total Loss:  tensor(820.3304, grad_fn=<AddBackward0>)
Gradients:
1885.7733154296875
Gradient before update: tensor(1703.9561)
Gradient after update: tensor(1703.9561)
current Learning Rate:  0.1
Total Loss:  tensor(820.3304, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.3489,  0.4893, -3.4155,  0.0000,  0.0000,  0.0000],
        [-0.1496,  0.6870,  1.8657,  0.0000,  0.0000,  0.0000],
        [-1.6712,  0.0443,  2.8693,  0.0000,  0.0000,  0.0000],
        [ 0.9736,  0.1038,  2.6127,  0.0000,  0.0000,  0.0000],
        [ 0.1710, -0.0240,  0.6965,  0.0000,  0.0000,  0.0000],
        [ 1.0596, -0.1112, -0.6224,  0.0000,  0.0000,  0.0000],
        [ 0.3926,  0.4753, -0.6099,  0.0000,  0.0000,  0.0000],
        [ 1.2036,  0.3624,  0.5348,  0.0000,  0.0000,  0.0000],
        [-0.5676, -1.6095, -1.4013,  0.0000,  0.0000,  0.0000],
        [ 1.0440, -0.1325,  1.2381,  0.0000,  0.0000,  0.0000],
        [-1.5624, -1.1917, -3.5599,  0.0000,  0.0000,  0.0000],
        [-0.9483, -0.4400,  1.0955,  0.0000,  0.0000,  0.0000],
        [ 0.2627, -0.2624, -2.2004,  0.0000,  0.0000,  0.0000],
        [ 1.4709,  0.8221,  3.2209,  0.0000,  0.0000,  0.0000],
        [-1.1441, -0.5932, -3.1782,  0.0000,  0.0000,  0.0000],
        [-1.3981,  1.2170, -3.1590,  0.0000,  0.0000,  0.0000],
        [ 1.4420,  0.9761,  2.2113,  0.0000,  0.0000,  0.0000],
        [ 0.1537, -0.7290,  2.7451,  0.0000,  0.0000,  0.0000],
        [-0.5953,  1.0560, -2.2802,  0.0000,  0.0000,  0.0000],
        [-0.3290, -1.1800,  0.3819,  0.0000,  0.0000,  0.0000],
        [ 1.3258,  0.8214, -0.1762,  0.0000,  0.0000,  0.0000],
        [-1.1090,  0.8886,  1.6113,  0.0000,  0.0000,  0.0000],
        [ 0.8663,  0.8710, -1.2495,  0.0000,  0.0000,  0.0000],
        [ 0.2061,  0.9600, -1.4291,  0.0000,  0.0000,  0.0000],
        [-1.2955,  0.2063, -1.7302,  0.0000,  0.0000,  0.0000],
        [ 0.7966, -0.7567, -3.3237,  0.0000,  0.0000,  0.0000],
        [-1.4687, -0.4201, -0.3413,  0.0000,  0.0000,  0.0000],
        [-0.3303, -0.0151, -1.3116,  0.0000,  0.0000,  0.0000],
        [ 0.9819, -0.9234,  0.2911,  0.0000,  0.0000,  0.0000],
        [ 0.1977, -0.4779,  1.5239,  0.0000,  0.0000,  0.0000],
        [-0.5783, -0.4693,  2.2166,  0.0000,  0.0000,  0.0000],
        [ 0.4026,  0.7758, -2.7188,  0.0000,  0.0000,  0.0000],
        [ 0.9386, -1.0109, -0.9533,  0.0000,  0.0000,  0.0000],
        [ 1.1914,  0.3535, -2.4923,  0.0000,  0.0000,  0.0000],
        [-1.5285, -1.2059, -0.1867,  0.0000,  0.0000,  0.0000],
        [-1.4880,  0.7963, -2.7194,  0.0000,  0.0000,  0.0000],
        [ 0.8102,  0.8553,  1.2826,  0.0000,  0.0000,  0.0000],
        [ 1.3742, -1.0884,  1.7389,  0.0000,  0.0000,  0.0000],
        [-0.6948, -0.3158, -2.2047,  0.0000,  0.0000,  0.0000],
        [-1.0056, -1.1328,  3.2714,  0.0000,  0.0000,  0.0000],
        [ 0.6281,  0.1023, -1.2689,  0.0000,  0.0000,  0.0000],
        [ 0.5561, -1.6483,  0.2117,  0.0000,  0.0000,  0.0000],
        [-0.4995,  0.8287, -0.1869,  0.0000,  0.0000,  0.0000],
        [ 0.6156, -1.3060,  1.2031,  0.0000,  0.0000,  0.0000],
        [ 0.8648, -1.5695, -1.6496,  0.0000,  0.0000,  0.0000],
        [-1.0113, -1.6002,  1.4091,  0.0000,  0.0000,  0.0000],
        [ 0.2234,  0.6729,  0.3597,  0.0000,  0.0000,  0.0000],
        [-0.7505,  0.6935,  2.7247,  0.0000,  0.0000,  0.0000],
        [-0.0040, -1.4625, -2.8963,  0.0000,  0.0000,  0.0000],
        [-0.0244, -0.3806,  0.1140,  0.0000,  0.0000,  0.0000],
        [-1.5918, -0.6569,  0.6373,  0.0000,  0.0000,  0.0000],
        [ 1.1319, -0.2438, -2.0273,  0.0000,  0.0000,  0.0000],
        [-0.4414, -0.6342, -0.8235,  0.0000,  0.0000,  0.0000],
        [ 0.4505, -1.7775, -1.6987,  0.0000,  0.0000,  0.0000],
        [-0.8380,  0.4229,  0.7558,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  13
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.1211, grad_fn=<DivBackward0>)
Projection Loss:  tensor(801.8242, grad_fn=<AddBackward0>)
Total Loss:  tensor(801.9454, grad_fn=<AddBackward0>)
Gradients:
19.047962188720703
Gradient before update: tensor(26.9253)
Gradient after update: tensor(26.9253)
current Learning Rate:  0.1
------------------------------------------------------------------------------------------------------------------
Iteration:  14
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.1526, grad_fn=<DivBackward0>)
Projection Loss:  tensor(778.8159, grad_fn=<AddBackward0>)
Total Loss:  tensor(778.9684, grad_fn=<AddBackward0>)
Gradients:
53.1983528137207
Gradient before update: tensor(45.2275)
Gradient after update: tensor(45.2275)
current Learning Rate:  0.1
Total Loss:  tensor(778.9684, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.3817,  0.4625, -3.4618,  0.0000,  0.0000,  0.0000],
        [-0.1407,  0.6543,  1.8466,  0.0000,  0.0000,  0.0000],
        [-1.7635,  0.1469,  2.9476,  0.0000,  0.0000,  0.0000],
        [ 0.9248,  0.1527,  2.6692,  0.0000,  0.0000,  0.0000],
        [ 0.1309, -0.0086,  0.6886,  0.0000,  0.0000,  0.0000],
        [ 1.1166, -0.1197, -0.6052,  0.0000,  0.0000,  0.0000],
        [ 0.4256,  0.5221, -0.6060,  0.0000,  0.0000,  0.0000],
        [ 1.3003,  0.2786,  0.5721,  0.0000,  0.0000,  0.0000],
        [-0.6238, -1.7014, -1.3625,  0.0000,  0.0000,  0.0000],
        [ 0.9949, -0.1802,  1.1870,  0.0000,  0.0000,  0.0000],
        [-1.6614, -1.2400, -3.5289,  0.0000,  0.0000,  0.0000],
        [-0.9770, -0.4663,  1.0559,  0.0000,  0.0000,  0.0000],
        [ 0.2882, -0.2893, -2.1910,  0.0000,  0.0000,  0.0000],
        [ 1.3842,  0.9189,  3.3189,  0.0000,  0.0000,  0.0000],
        [-1.1847, -0.6228, -3.2392,  0.0000,  0.0000,  0.0000],
        [-1.4748,  1.2910, -3.2173,  0.0000,  0.0000,  0.0000],
        [ 1.4993,  0.9398,  2.1655,  0.0000,  0.0000,  0.0000],
        [ 0.0967, -0.6740,  2.7664,  0.0000,  0.0000,  0.0000],
        [-0.5134,  1.1396, -2.2908,  0.0000,  0.0000,  0.0000],
        [-0.2981, -1.1149,  0.3500,  0.0000,  0.0000,  0.0000],
        [ 1.3784,  0.8658, -0.1698,  0.0000,  0.0000,  0.0000],
        [-1.1415,  0.9142,  1.6219,  0.0000,  0.0000,  0.0000],
        [ 0.8618,  0.8848, -1.2175,  0.0000,  0.0000,  0.0000],
        [ 0.2464,  0.9054, -1.3360,  0.0000,  0.0000,  0.0000],
        [-1.2819,  0.1772, -1.7909,  0.0000,  0.0000,  0.0000],
        [ 0.8446, -0.8147, -3.3778,  0.0000,  0.0000,  0.0000],
        [-1.5259, -0.3929, -0.3133,  0.0000,  0.0000,  0.0000],
        [-0.3582, -0.0207, -1.3162,  0.0000,  0.0000,  0.0000],
        [ 0.9613, -0.9212,  0.2752,  0.0000,  0.0000,  0.0000],
        [ 0.1972, -0.4596,  1.4955,  0.0000,  0.0000,  0.0000],
        [-0.6019, -0.4693,  2.2559,  0.0000,  0.0000,  0.0000],
        [ 0.4248,  0.7274, -2.7654,  0.0000,  0.0000,  0.0000],
        [ 0.9993, -1.0178, -0.9251,  0.0000,  0.0000,  0.0000],
        [ 1.1588,  0.3897, -2.4426,  0.0000,  0.0000,  0.0000],
        [-1.5828, -1.1904, -0.2326,  0.0000,  0.0000,  0.0000],
        [-1.5409,  0.8361, -2.7426,  0.0000,  0.0000,  0.0000],
        [ 0.8267,  0.9039,  1.2748,  0.0000,  0.0000,  0.0000],
        [ 1.2985, -1.1644,  1.6699,  0.0000,  0.0000,  0.0000],
        [-0.7167, -0.2933, -2.2146,  0.0000,  0.0000,  0.0000],
        [-1.0302, -1.1482,  3.2974,  0.0000,  0.0000,  0.0000],
        [ 0.6228,  0.0826, -1.2560,  0.0000,  0.0000,  0.0000],
        [ 0.5251, -1.7741,  0.2137,  0.0000,  0.0000,  0.0000],
        [-0.4632,  0.7976, -0.1266,  0.0000,  0.0000,  0.0000],
        [ 0.6281, -1.3485,  1.1936,  0.0000,  0.0000,  0.0000],
        [ 0.8551, -1.6551, -1.6405,  0.0000,  0.0000,  0.0000],
        [-1.0125, -1.7201,  1.4382,  0.0000,  0.0000,  0.0000],
        [ 0.2613,  0.6283,  0.3009,  0.0000,  0.0000,  0.0000],
        [-0.7807,  0.7169,  2.7867,  0.0000,  0.0000,  0.0000],
        [-0.0307, -1.4970, -2.9349,  0.0000,  0.0000,  0.0000],
        [-0.0560, -0.5125,  0.1156,  0.0000,  0.0000,  0.0000],
        [-1.6709, -0.6504,  0.6563,  0.0000,  0.0000,  0.0000],
        [ 1.1809, -0.3357, -2.0154,  0.0000,  0.0000,  0.0000],
        [-0.4721, -0.7223, -0.8191,  0.0000,  0.0000,  0.0000],
        [ 0.5292, -1.8642, -1.7848,  0.0000,  0.0000,  0.0000],
        [-0.8438,  0.3430,  0.8000,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  15
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.1717, grad_fn=<DivBackward0>)
Projection Loss:  tensor(760.7750, grad_fn=<AddBackward0>)
Total Loss:  tensor(760.9467, grad_fn=<AddBackward0>)
Gradients:
208.9059600830078
Gradient before update: tensor(273.3549)
Gradient after update: tensor(273.3549)
current Learning Rate:  0.05
------------------------------------------------------------------------------------------------------------------
Iteration:  16
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.1846, grad_fn=<DivBackward0>)
Projection Loss:  tensor(720.9660, grad_fn=<AddBackward0>)
Total Loss:  tensor(721.1506, grad_fn=<AddBackward0>)
Gradients:
90.06990051269531
Gradient before update: tensor(11.9023)
Gradient after update: tensor(11.9023)
current Learning Rate:  0.05
Total Loss:  tensor(721.1506, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 4.0144e-01,  4.4565e-01, -3.5045e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.3508e-01,  6.3393e-01,  1.8347e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8267e+00,  2.1356e-01,  2.9980e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.9431e-01,  1.8330e-01,  2.7045e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0580e-01, -1.7744e-03,  6.8631e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1537e+00, -1.2498e-01, -5.9448e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.4630e-01,  5.5125e-01, -6.0355e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.3288e+00,  2.3235e-01,  6.0372e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.4926e-01, -1.7633e+00, -1.3262e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.6427e-01, -2.0999e-01,  1.1552e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.7256e+00, -1.3032e+00, -3.4656e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-9.9505e-01, -4.8250e-01,  1.0311e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.0462e-01, -3.0607e-01, -2.1852e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.3282e+00,  9.8577e-01,  3.3817e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2100e+00, -6.4120e-01, -3.2773e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.5194e+00,  1.3349e+00, -3.2549e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.5386e+00,  9.1846e-01,  2.1374e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.1208e-02, -6.4193e-01,  2.7798e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.7972e-01,  1.0803e+00, -2.2354e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-2.8292e-01, -1.0823e+00,  3.3884e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4112e+00,  8.9358e-01, -1.6587e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1617e+00,  9.3024e-01,  1.6285e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.5984e-01,  8.9346e-01, -1.1974e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 2.4392e-01,  8.4920e-01, -1.2852e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2184e+00,  1.1521e-01, -1.8558e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.7148e-01, -8.4268e-01, -3.4114e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.6036e+00, -3.5975e-01, -2.9829e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.7556e-01, -2.4240e-02, -1.3191e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.4842e-01, -9.1983e-01,  2.6530e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.9694e-01, -4.4819e-01,  1.4777e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.1658e-01, -4.6934e-01,  2.2804e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.3891e-01,  6.9764e-01, -2.7899e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0372e+00, -1.0221e+00, -9.0743e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1384e+00,  4.1226e-01, -2.4116e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.6167e+00, -1.1809e+00, -2.6127e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.5799e+00,  8.5852e-01, -2.7553e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.3697e-01,  9.3472e-01,  1.2699e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2512e+00, -1.2118e+00,  1.6269e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.3040e-01, -2.7929e-01, -2.2208e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0451e+00, -1.1587e+00,  3.3137e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.1956e-01,  7.0359e-02, -1.2479e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.0577e-01, -1.8526e+00,  2.1490e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.4055e-01,  7.7813e-01, -8.8937e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.5944e-01, -1.2860e+00,  1.1551e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.4915e-01, -1.7085e+00, -1.6347e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0160e+00, -1.8069e+00,  1.4593e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 2.8526e-01,  6.0046e-01,  2.6363e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.9946e-01,  7.3149e-01,  2.8255e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.6761e-02, -1.5182e+00, -2.9590e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.3268e-02, -5.2484e-01,  1.0136e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.7372e+00, -6.7164e-01,  6.8435e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2142e+00, -4.0500e-01, -2.0073e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.9118e-01, -7.7729e-01, -8.1628e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.7549e-01, -1.9198e+00, -1.8574e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-8.4746e-01,  2.9319e-01,  8.2768e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00]], requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  17
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.1787, grad_fn=<DivBackward0>)
Projection Loss:  tensor(711.9024, grad_fn=<AddBackward0>)
Total Loss:  tensor(712.0811, grad_fn=<AddBackward0>)
Gradients:
46.21267318725586
Gradient before update: tensor(-38.4830)
Gradient after update: tensor(-38.4830)
current Learning Rate:  0.05
------------------------------------------------------------------------------------------------------------------
Iteration:  18
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.1645, grad_fn=<DivBackward0>)
Projection Loss:  tensor(698.5926, grad_fn=<AddBackward0>)
Total Loss:  tensor(698.7571, grad_fn=<AddBackward0>)
Gradients:
160.85267639160156
Gradient before update: tensor(30.9529)
Gradient after update: tensor(30.9529)
current Learning Rate:  0.05
Total Loss:  tensor(698.7571, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 4.1208e-01,  4.3646e-01, -3.5293e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.3207e-01,  6.2293e-01,  1.8282e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8618e+00,  2.4905e-01,  3.0249e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.7785e-01,  1.9980e-01,  2.7235e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.9382e-02, -2.4864e-03,  6.8734e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1738e+00, -1.2782e-01, -5.8867e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.5790e-01,  5.6618e-01, -6.0171e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2867e+00,  2.6661e-01,  6.2141e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.6031e-01, -1.7961e+00, -1.3110e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.4772e-01, -2.2607e-01,  1.1380e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.7607e+00, -1.3371e+00, -3.4314e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0048e+00, -4.9124e-01,  1.0178e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.1355e-01, -3.1520e-01, -2.1821e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2980e+00,  1.0220e+00,  3.4157e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2237e+00, -6.5116e-01, -3.2979e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.5309e+00,  1.3594e+00, -3.2783e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.5614e+00,  9.0701e-01,  2.1227e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.2290e-02, -6.2688e-01,  2.7872e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.2131e-01,  1.0350e+00, -2.1939e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-2.8448e-01, -1.0790e+00,  3.4467e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4289e+00,  9.0855e-01, -1.6372e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1727e+00,  9.3886e-01,  1.6321e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.5937e-01,  8.9813e-01, -1.1865e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 2.3586e-01,  8.1910e-01, -1.2606e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1844e+00,  8.2020e-02, -1.8841e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.2476e-01, -7.9572e-01, -3.4520e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.6517e+00, -3.0983e-01, -3.3843e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.8495e-01, -2.6138e-02, -1.3207e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.4148e-01, -9.1908e-01,  2.5995e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.9681e-01, -4.4230e-01,  1.4681e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.2452e-01, -4.6935e-01,  2.2937e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.4657e-01,  6.8184e-01, -2.7977e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0577e+00, -1.0244e+00, -8.9791e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1274e+00,  4.2444e-01, -2.3949e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.6350e+00, -1.1757e+00, -2.7673e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.6073e+00,  8.6771e-01, -2.7612e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.3172e-01,  9.8211e-01,  1.2231e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2257e+00, -1.2374e+00,  1.6037e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.3201e-01, -2.7433e-01, -2.2282e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0504e+00, -1.1858e+00,  3.3220e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.1778e-01,  6.3733e-02, -1.2436e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.9401e-01, -1.8969e+00,  2.1555e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.2831e-01,  7.6763e-01, -6.8618e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.1648e-01, -1.2431e+00,  1.1119e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.4605e-01, -1.7373e+00, -1.6312e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0185e+00, -1.8577e+00,  1.4710e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 2.9825e-01,  5.8544e-01,  2.4339e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-8.0962e-01,  7.3938e-01,  2.8464e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.4718e-02, -1.5489e+00, -2.9714e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-2.5754e-02, -4.7548e-01,  7.8159e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.7731e+00, -6.8302e-01,  6.9943e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2260e+00, -4.5168e-01, -2.0027e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.0150e-01, -8.0698e-01, -8.1479e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.1503e-01, -1.9642e+00, -1.9196e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-8.5051e-01,  2.6675e-01,  8.4260e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00]], requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  19
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.1491, grad_fn=<DivBackward0>)
Projection Loss:  tensor(674.2537, grad_fn=<AddBackward0>)
Total Loss:  tensor(674.4028, grad_fn=<AddBackward0>)
Gradients:
4291.67529296875
Gradient before update: tensor(3596.7773)
Gradient after update: tensor(3596.7773)
current Learning Rate:  0.05
------------------------------------------------------------------------------------------------------------------
Iteration:  20
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.1321, grad_fn=<DivBackward0>)
Projection Loss:  tensor(673.7418, grad_fn=<AddBackward0>)
Total Loss:  tensor(673.8738, grad_fn=<AddBackward0>)
Gradients:
153.02061462402344
Gradient before update: tensor(184.4810)
Gradient after update: tensor(184.4810)
current Learning Rate:  0.05
Total Loss:  tensor(673.8738, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4210,  0.4287, -3.5563,  0.0000,  0.0000,  0.0000],
        [-0.1296,  0.6138,  1.8229,  0.0000,  0.0000,  0.0000],
        [-1.8290,  0.3048,  2.9896,  0.0000,  0.0000,  0.0000],
        [ 0.8643,  0.2134,  2.7392,  0.0000,  0.0000,  0.0000],
        [ 0.0746, -0.0056,  0.6898,  0.0000,  0.0000,  0.0000],
        [ 1.1903, -0.1302, -0.5839,  0.0000,  0.0000,  0.0000],
        [ 0.4716,  0.5742, -0.5966,  0.0000,  0.0000,  0.0000],
        [ 1.2225,  0.3221,  0.6342,  0.0000,  0.0000,  0.0000],
        [-0.6683, -1.8210, -1.3014,  0.0000,  0.0000,  0.0000],
        [ 0.9341, -0.2394,  1.1238,  0.0000,  0.0000,  0.0000],
        [-1.7677, -1.3789, -3.4032,  0.0000,  0.0000,  0.0000],
        [-1.0129, -0.4985,  1.0067,  0.0000,  0.0000,  0.0000],
        [ 0.3209, -0.3227, -2.1795,  0.0000,  0.0000,  0.0000],
        [ 1.2724,  1.0696,  3.4443,  0.0000,  0.0000,  0.0000],
        [-1.2350, -0.6594, -3.3149,  0.0000,  0.0000,  0.0000],
        [-1.5353,  1.3720, -3.2988,  0.0000,  0.0000,  0.0000],
        [ 1.5805,  0.8978,  2.1106,  0.0000,  0.0000,  0.0000],
        [ 0.0269, -0.6199,  2.7932,  0.0000,  0.0000,  0.0000],
        [-0.6608,  0.9864, -2.1493,  0.0000,  0.0000,  0.0000],
        [-0.3000, -1.0934,  0.3530,  0.0000,  0.0000,  0.0000],
        [ 1.4436,  0.9209, -0.1620,  0.0000,  0.0000,  0.0000],
        [-1.1821,  0.9441,  1.6350,  0.0000,  0.0000,  0.0000],
        [ 0.8595,  0.9020, -1.1774,  0.0000,  0.0000,  0.0000],
        [ 0.2235,  0.7943, -1.2447,  0.0000,  0.0000,  0.0000],
        [-1.1567,  0.0551, -1.8944,  0.0000,  0.0000,  0.0000],
        [ 0.7861, -0.7569, -3.4856,  0.0000,  0.0000,  0.0000],
        [-1.6914, -0.2685, -0.3716,  0.0000,  0.0000,  0.0000],
        [-0.3927, -0.0277, -1.3219,  0.0000,  0.0000,  0.0000],
        [ 0.9357, -0.9185,  0.2555,  0.0000,  0.0000,  0.0000],
        [ 0.1967, -0.4379,  1.4602,  0.0000,  0.0000,  0.0000],
        [-0.6311, -0.4694,  2.3046,  0.0000,  0.0000,  0.0000],
        [ 0.4529,  0.6689, -2.8028,  0.0000,  0.0000,  0.0000],
        [ 1.0746, -1.0263, -0.8900,  0.0000,  0.0000,  0.0000],
        [ 1.1183,  0.4345, -2.3810,  0.0000,  0.0000,  0.0000],
        [-1.6501, -1.1715, -0.2895,  0.0000,  0.0000,  0.0000],
        [-1.6293,  0.8749, -2.7651,  0.0000,  0.0000,  0.0000],
        [ 0.8257,  1.0213,  1.1846,  0.0000,  0.0000,  0.0000],
        [ 1.2046, -1.2585,  1.5845,  0.0000,  0.0000,  0.0000],
        [-0.7185, -0.2784, -2.2473,  0.0000,  0.0000,  0.0000],
        [-1.0514, -1.2250,  3.3285,  0.0000,  0.0000,  0.0000],
        [ 0.6163,  0.0583, -1.2400,  0.0000,  0.0000,  0.0000],
        [ 0.4830, -1.9355,  0.2160,  0.0000,  0.0000,  0.0000],
        [-0.4182,  0.7590, -0.0518,  0.0000,  0.0000,  0.0000],
        [ 0.4810, -1.2077,  1.0763,  0.0000,  0.0000,  0.0000],
        [ 0.8435, -1.7611, -1.6280,  0.0000,  0.0000,  0.0000],
        [-1.0664, -1.8101,  1.5189,  0.0000,  0.0000,  0.0000],
        [ 0.3092,  0.5730,  0.2264,  0.0000,  0.0000,  0.0000],
        [-0.8180,  0.7459,  2.8637,  0.0000,  0.0000,  0.0000],
        [-0.0331, -1.5926, -2.9811,  0.0000,  0.0000,  0.0000],
        [ 0.0072, -0.4178,  0.0526,  0.0000,  0.0000,  0.0000],
        [-1.8043, -0.6927,  0.7122,  0.0000,  0.0000,  0.0000],
        [ 1.2329, -0.4901, -1.9989,  0.0000,  0.0000,  0.0000],
        [-0.5100, -0.8316, -0.8136,  0.0000,  0.0000,  0.0000],
        [ 0.6610, -2.0134, -1.9841,  0.0000,  0.0000,  0.0000],
        [-0.8781,  0.2583,  0.8572,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  21
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.1136, grad_fn=<DivBackward0>)
Projection Loss:  tensor(654.9526, grad_fn=<AddBackward0>)
Total Loss:  tensor(655.0662, grad_fn=<AddBackward0>)
Gradients:
364.2482604980469
Gradient before update: tensor(-157.5223)
Gradient after update: tensor(-157.5223)
current Learning Rate:  0.05
------------------------------------------------------------------------------------------------------------------
Iteration:  22
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0922, grad_fn=<DivBackward0>)
Projection Loss:  tensor(650.5859, grad_fn=<AddBackward0>)
Total Loss:  tensor(650.6782, grad_fn=<AddBackward0>)
Gradients:
7514.830078125
Gradient before update: tensor(-8958.3242)
Gradient after update: tensor(-8958.3242)
current Learning Rate:  0.05
Total Loss:  tensor(650.6782, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4284,  0.4223, -3.5786,  0.0000,  0.0000,  0.0000],
        [-0.1275,  0.6063,  1.8185,  0.0000,  0.0000,  0.0000],
        [-1.8020,  0.3504,  2.9607,  0.0000,  0.0000,  0.0000],
        [ 0.8530,  0.2247,  2.7522,  0.0000,  0.0000,  0.0000],
        [ 0.0623, -0.0079,  0.6956,  0.0000,  0.0000,  0.0000],
        [ 1.2033, -0.1208, -0.5794,  0.0000,  0.0000,  0.0000],
        [ 0.4863,  0.5758, -0.5884,  0.0000,  0.0000,  0.0000],
        [ 1.1711,  0.3679,  0.6438,  0.0000,  0.0000,  0.0000],
        [-0.6748, -1.8420, -1.2931,  0.0000,  0.0000,  0.0000],
        [ 0.9227, -0.2504,  1.1120,  0.0000,  0.0000,  0.0000],
        [-1.7530, -1.4259, -3.3798,  0.0000,  0.0000,  0.0000],
        [-1.0195, -0.5044,  0.9976,  0.0000,  0.0000,  0.0000],
        [ 0.3270, -0.3290, -2.1774,  0.0000,  0.0000,  0.0000],
        [ 1.2502,  1.1134,  3.4693,  0.0000,  0.0000,  0.0000],
        [-1.2443, -0.6662, -3.3290,  0.0000,  0.0000,  0.0000],
        [-1.5287,  1.3550, -3.2969,  0.0000,  0.0000,  0.0000],
        [ 1.5737,  0.8981,  2.1109,  0.0000,  0.0000,  0.0000],
        [ 0.0142, -0.6146,  2.7983,  0.0000,  0.0000,  0.0000],
        [-0.6935,  0.9461, -2.1124,  0.0000,  0.0000,  0.0000],
        [-0.3183, -1.1148,  0.3592,  0.0000,  0.0000,  0.0000],
        [ 1.4557,  0.9312, -0.1605,  0.0000,  0.0000,  0.0000],
        [-1.1909,  0.9442,  1.6374,  0.0000,  0.0000,  0.0000],
        [ 0.8601,  0.9052, -1.1699,  0.0000,  0.0000,  0.0000],
        [ 0.2389,  0.8112, -1.2665,  0.0000,  0.0000,  0.0000],
        [-1.1349,  0.0343, -1.8891,  0.0000,  0.0000,  0.0000],
        [ 0.7541, -0.7248, -3.5134,  0.0000,  0.0000,  0.0000],
        [-1.7495, -0.3102, -0.4080,  0.0000,  0.0000,  0.0000],
        [-0.3992, -0.0290, -1.3230,  0.0000,  0.0000,  0.0000],
        [ 0.9310, -0.9180,  0.2519,  0.0000,  0.0000,  0.0000],
        [ 0.1966, -0.4344,  1.4536,  0.0000,  0.0000,  0.0000],
        [-0.6365, -0.4694,  2.3137,  0.0000,  0.0000,  0.0000],
        [ 0.4581,  0.6581, -2.8070,  0.0000,  0.0000,  0.0000],
        [ 1.0893, -1.0278, -0.8835,  0.0000,  0.0000,  0.0000],
        [ 1.1108,  0.4428, -2.3696,  0.0000,  0.0000,  0.0000],
        [-1.6627, -1.1680, -0.3001,  0.0000,  0.0000,  0.0000],
        [-1.6451,  0.8802, -2.7671,  0.0000,  0.0000,  0.0000],
        [ 0.7683,  1.0648,  1.1456,  0.0000,  0.0000,  0.0000],
        [ 1.1872, -1.2761,  1.5686,  0.0000,  0.0000,  0.0000],
        [-0.6882, -0.2926, -2.2802,  0.0000,  0.0000,  0.0000],
        [-1.0025, -1.2739,  3.3775,  0.0000,  0.0000,  0.0000],
        [ 0.6151,  0.0537, -1.2370,  0.0000,  0.0000,  0.0000],
        [ 0.4511, -1.9848,  0.2131,  0.0000,  0.0000,  0.0000],
        [-0.4098,  0.7518, -0.0379,  0.0000,  0.0000,  0.0000],
        [ 0.4516, -1.1784,  1.0468,  0.0000,  0.0000,  0.0000],
        [ 0.8416, -1.7808, -1.6251,  0.0000,  0.0000,  0.0000],
        [-1.1062, -1.7716,  1.5585,  0.0000,  0.0000,  0.0000],
        [ 0.3182,  0.5628,  0.2123,  0.0000,  0.0000,  0.0000],
        [-0.8250,  0.7513,  2.8780,  0.0000,  0.0000,  0.0000],
        [-0.0686, -1.6319, -2.9870,  0.0000,  0.0000,  0.0000],
        [ 0.0348, -0.3699,  0.0303,  0.0000,  0.0000,  0.0000],
        [-1.8307, -0.6995,  0.7227,  0.0000,  0.0000,  0.0000],
        [ 1.2379, -0.5229, -1.9958,  0.0000,  0.0000,  0.0000],
        [-0.5171, -0.8519, -0.8125,  0.0000,  0.0000,  0.0000],
        [ 0.6984, -2.0548, -2.0462,  0.0000,  0.0000,  0.0000],
        [-0.9017,  0.2517,  0.8692,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  23
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0788, grad_fn=<DivBackward0>)
Projection Loss:  tensor(638.7778, grad_fn=<AddBackward0>)
Total Loss:  tensor(638.8566, grad_fn=<AddBackward0>)
Gradients:
79.97264862060547
Gradient before update: tensor(141.1476)
Gradient after update: tensor(141.1476)
current Learning Rate:  0.05
------------------------------------------------------------------------------------------------------------------
Iteration:  24
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0680, grad_fn=<DivBackward0>)
Projection Loss:  tensor(623.9964, grad_fn=<AddBackward0>)
Total Loss:  tensor(624.0644, grad_fn=<AddBackward0>)
Gradients:
2877.281005859375
Gradient before update: tensor(-2601.8865)
Gradient after update: tensor(-2601.8865)
current Learning Rate:  0.05
Total Loss:  tensor(624.0644, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4346,  0.4170, -3.5972,  0.0000,  0.0000,  0.0000],
        [-0.1258,  0.6001,  1.8148,  0.0000,  0.0000,  0.0000],
        [-1.8003,  0.3991,  2.9213,  0.0000,  0.0000,  0.0000],
        [ 0.8437,  0.2341,  2.7630,  0.0000,  0.0000,  0.0000],
        [ 0.0521, -0.0083,  0.7026,  0.0000,  0.0000,  0.0000],
        [ 1.2455, -0.0598, -0.5927,  0.0000,  0.0000,  0.0000],
        [ 0.4965,  0.5714, -0.5781,  0.0000,  0.0000,  0.0000],
        [ 1.1296,  0.4063,  0.6511,  0.0000,  0.0000,  0.0000],
        [-0.6815, -1.8618, -1.2865,  0.0000,  0.0000,  0.0000],
        [ 0.9134, -0.2595,  1.1022,  0.0000,  0.0000,  0.0000],
        [-1.7303, -1.4475, -3.3589,  0.0000,  0.0000,  0.0000],
        [-1.0251, -0.5094,  0.9900,  0.0000,  0.0000,  0.0000],
        [ 0.3321, -0.3341, -2.1756,  0.0000,  0.0000,  0.0000],
        [ 1.2339,  1.0674,  3.5231,  0.0000,  0.0000,  0.0000],
        [-1.2521, -0.6718, -3.3406,  0.0000,  0.0000,  0.0000],
        [-1.4910,  1.3245, -3.3113,  0.0000,  0.0000,  0.0000],
        [ 1.5478,  0.9040,  2.1181,  0.0000,  0.0000,  0.0000],
        [ 0.0037, -0.6130,  2.8024,  0.0000,  0.0000,  0.0000],
        [-0.7205,  0.9128, -2.0818,  0.0000,  0.0000,  0.0000],
        [-0.3320, -1.1326,  0.3645,  0.0000,  0.0000,  0.0000],
        [ 1.4658,  0.9397, -0.1593,  0.0000,  0.0000,  0.0000],
        [-1.1984,  0.9427,  1.6393,  0.0000,  0.0000,  0.0000],
        [ 0.8613,  0.9079, -1.1636,  0.0000,  0.0000,  0.0000],
        [ 0.2839,  0.8562, -1.3115,  0.0000,  0.0000,  0.0000],
        [-1.1177,  0.0183, -1.8768,  0.0000,  0.0000,  0.0000],
        [ 0.7276, -0.6982, -3.5364,  0.0000,  0.0000,  0.0000],
        [-1.8080, -0.2819, -0.4475,  0.0000,  0.0000,  0.0000],
        [-0.4045, -0.0300, -1.3239,  0.0000,  0.0000,  0.0000],
        [ 0.9271, -0.9175,  0.2488,  0.0000,  0.0000,  0.0000],
        [ 0.1966, -0.4315,  1.4482,  0.0000,  0.0000,  0.0000],
        [-0.6410, -0.4694,  2.3212,  0.0000,  0.0000,  0.0000],
        [ 0.4624,  0.6492, -2.8105,  0.0000,  0.0000,  0.0000],
        [ 1.1015, -1.0290, -0.8781,  0.0000,  0.0000,  0.0000],
        [ 1.1046,  0.4497, -2.3601,  0.0000,  0.0000,  0.0000],
        [-1.6730, -1.1652, -0.3088,  0.0000,  0.0000,  0.0000],
        [-1.6531,  0.8813, -2.7695,  0.0000,  0.0000,  0.0000],
        [ 0.6883,  1.1133,  1.1245,  0.0000,  0.0000,  0.0000],
        [ 1.1728, -1.2906,  1.5555,  0.0000,  0.0000,  0.0000],
        [-0.6488, -0.3127, -2.3217,  0.0000,  0.0000,  0.0000],
        [-0.9619, -1.3145,  3.4180,  0.0000,  0.0000,  0.0000],
        [ 0.6141,  0.0500, -1.2346,  0.0000,  0.0000,  0.0000],
        [ 0.4052, -2.0388,  0.2076,  0.0000,  0.0000,  0.0000],
        [-0.4029,  0.7458, -0.0264,  0.0000,  0.0000,  0.0000],
        [ 0.4272, -1.1540,  1.0224,  0.0000,  0.0000,  0.0000],
        [ 0.8401, -1.7971, -1.6223,  0.0000,  0.0000,  0.0000],
        [-1.1398, -1.7416,  1.5919,  0.0000,  0.0000,  0.0000],
        [ 0.3257,  0.5542,  0.2006,  0.0000,  0.0000,  0.0000],
        [-0.8307,  0.7558,  2.8898,  0.0000,  0.0000,  0.0000],
        [-0.0961, -1.6712, -2.9911,  0.0000,  0.0000,  0.0000],
        [ 0.0577, -0.3302,  0.0118,  0.0000,  0.0000,  0.0000],
        [-1.8532, -0.7064,  0.7312,  0.0000,  0.0000,  0.0000],
        [ 1.2629, -0.5209, -1.9952,  0.0000,  0.0000,  0.0000],
        [-0.5230, -0.8688, -0.8117,  0.0000,  0.0000,  0.0000],
        [ 0.7318, -2.0924, -2.1055,  0.0000,  0.0000,  0.0000],
        [-0.9223,  0.2466,  0.8792,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  25
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0569, grad_fn=<DivBackward0>)
Projection Loss:  tensor(613.9564, grad_fn=<AddBackward0>)
Total Loss:  tensor(614.0133, grad_fn=<AddBackward0>)
Gradients:
176.92079162597656
Gradient before update: tensor(186.0896)
Gradient after update: tensor(186.0896)
current Learning Rate:  0.05
------------------------------------------------------------------------------------------------------------------
Iteration:  26
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0502, grad_fn=<DivBackward0>)
Projection Loss:  tensor(606.9962, grad_fn=<AddBackward0>)
Total Loss:  tensor(607.0464, grad_fn=<AddBackward0>)
Gradients:
1617.175048828125
Gradient before update: tensor(602.0527)
Gradient after update: tensor(602.0527)
current Learning Rate:  0.05
Total Loss:  tensor(607.0464, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 4.3967e-01,  4.1258e-01, -3.6125e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2440e-01,  5.9493e-01,  1.8118e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8187e+00,  4.4832e-01,  2.8751e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.3595e-01,  2.4181e-01,  2.7720e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.3560e-02, -8.4152e-03,  7.0879e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2547e+00,  1.9312e-02, -6.2774e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.0499e-01,  5.6776e-01, -5.6950e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1266e+00,  4.1574e-01,  6.7478e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.8852e-01, -1.8816e+00, -1.2814e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.0558e-01, -2.6703e-01,  1.0942e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.6992e+00, -1.4482e+00, -3.3390e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0296e+00, -5.1349e-01,  9.8373e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.3629e-01, -3.3844e-01, -2.1741e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2097e+00,  1.0370e+00,  3.5411e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2585e+00, -6.7648e-01, -3.3503e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.4432e+00,  1.3002e+00, -3.3533e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.5265e+00,  9.0914e-01,  2.1236e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.0010e-03, -6.1194e-01,  2.8058e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.4301e-01,  8.8534e-01, -2.0566e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.4468e-01, -1.1495e+00,  3.6906e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4744e+00,  9.4813e-01, -1.5818e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2048e+00,  9.4070e-01,  1.6410e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.6297e-01,  9.1007e-01, -1.1581e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.2115e-01,  8.9349e-01, -1.3489e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1053e+00,  5.6343e-03, -1.8620e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.0557e-01, -6.7614e-01, -3.5554e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8565e+00, -2.5793e-01, -4.8044e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.0903e-01, -3.0837e-02, -1.3246e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.2381e-01, -9.1719e-01,  2.4633e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.9654e-01, -4.2911e-01,  1.4437e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.4475e-01, -4.6939e-01,  2.3275e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.6595e-01,  6.4187e-01, -2.8134e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1330e+00, -1.0310e+00, -8.7359e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0994e+00,  4.5547e-01, -2.3522e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.6816e+00, -1.1628e+00, -3.1608e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.6291e+00,  8.5510e-01, -2.7961e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.7616e-01,  1.1037e+00,  1.1418e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1609e+00, -1.3027e+00,  1.5446e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.0951e-01, -3.3251e-01, -2.3634e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-9.2823e-01, -1.3482e+00,  3.4517e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.1326e-01,  4.6858e-02, -1.2325e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.7267e-01, -2.0367e+00,  2.0650e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.9713e-01,  7.4089e-01, -1.6832e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.0695e-01, -1.1339e+00,  1.0022e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.3818e-01, -1.8097e+00, -1.6187e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1677e+00, -1.7170e+00,  1.6195e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.3187e-01,  5.4719e-01,  1.9087e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-8.3554e-01,  7.5947e-01,  2.8996e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.3546e-01, -1.7156e+00, -3.0182e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.6701e-02, -2.9730e-01, -3.4793e-03,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.9079e+00, -7.3946e-01,  7.8103e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2630e+00, -5.2910e-01, -1.9891e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.6024e-01, -8.9829e-01, -8.1363e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.4961e-01, -2.1416e+00, -2.1703e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-9.3957e-01,  2.4240e-01,  8.8751e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00]], requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  27
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0433, grad_fn=<DivBackward0>)
Projection Loss:  tensor(599.0471, grad_fn=<AddBackward0>)
Total Loss:  tensor(599.0905, grad_fn=<AddBackward0>)
Gradients:
2498.131103515625
Gradient before update: tensor(-1685.2926)
Gradient after update: tensor(-1685.2926)
current Learning Rate:  0.05
------------------------------------------------------------------------------------------------------------------
Iteration:  28
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0394, grad_fn=<DivBackward0>)
Projection Loss:  tensor(595.9603, grad_fn=<AddBackward0>)
Total Loss:  tensor(595.9997, grad_fn=<AddBackward0>)
Gradients:
242.3240509033203
Gradient before update: tensor(38.9595)
Gradient after update: tensor(38.9595)
current Learning Rate:  0.05
Total Loss:  tensor(595.9997, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 4.4390e-01,  4.0892e-01, -3.6253e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2323e-01,  5.9065e-01,  1.8093e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8350e+00,  4.8792e-01,  2.8373e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.2952e-01,  2.4825e-01,  2.7794e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.6448e-02, -8.4962e-03,  7.1396e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2508e+00,  9.3689e-02, -6.7124e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.1015e-01,  5.6330e-01, -5.6129e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1527e+00,  4.0316e-01,  7.1047e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.9583e-01, -1.9054e+00, -1.2799e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.9912e-01, -2.7331e-01,  1.0874e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.6699e+00, -1.4532e+00, -3.3215e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0335e+00, -5.1690e-01,  9.7851e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.3978e-01, -3.4200e-01, -2.1729e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1794e+00,  1.0188e+00,  3.5319e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2640e+00, -6.8023e-01, -3.3583e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.4034e+00,  1.2788e+00, -3.3882e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.5239e+00,  9.1143e-01,  2.1287e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2215e-02, -6.1113e-01,  2.8087e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.6011e-01,  8.6768e-01, -2.0422e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.5523e-01, -1.1656e+00,  3.7297e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4882e+00,  9.6614e-01, -1.5738e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2101e+00,  9.3887e-01,  1.6423e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.6532e-01,  9.1191e-01, -1.1532e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.5206e-01,  9.2449e-01, -1.3801e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1115e+00, -2.7744e-03, -1.8334e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.8730e-01, -6.5781e-01, -3.5713e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8950e+00, -2.3471e-01, -5.1024e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.1280e-01, -3.1498e-02, -1.3252e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.2110e-01, -9.1690e-01,  2.4424e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.9650e-01, -4.2715e-01,  1.4400e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.4785e-01, -4.6939e-01,  2.3326e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.6892e-01,  6.3574e-01, -2.8158e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1790e+00, -1.0334e+00, -8.6980e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0951e+00,  4.6022e-01, -2.3457e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.6935e+00, -1.1611e+00, -3.2383e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.5662e+00,  7.8897e-01, -2.7520e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.2291e-01,  1.0560e+00,  1.1881e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1510e+00, -1.3127e+00,  1.5356e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.7552e-01, -3.4960e-01, -2.3998e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-9.0030e-01, -1.3761e+00,  3.4797e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.1257e-01,  4.4271e-02, -1.2308e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.4935e-01, -1.9919e+00,  2.0883e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.9235e-01,  7.3680e-01, -8.8426e-03,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.8937e-01, -1.1201e+00,  9.8516e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.3601e-01, -1.8195e+00, -1.6145e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1908e+00, -1.6967e+00,  1.6425e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.3703e-01,  5.4132e-01,  1.8282e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-8.3953e-01,  7.6255e-01,  2.9078e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8325e-01, -1.7630e+00, -3.0620e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.2401e-02, -2.7227e-01, -1.9139e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.9560e+00, -7.4912e-01,  8.2088e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2268e+00, -5.6482e-01, -1.9780e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.9119e-01, -9.2277e-01, -8.1525e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.5335e-01, -2.1967e+00, -2.2346e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-9.7476e-01,  2.6834e-01,  9.1888e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00]], requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  29
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0383, grad_fn=<DivBackward0>)
Projection Loss:  tensor(589.7449, grad_fn=<AddBackward0>)
Total Loss:  tensor(589.7833, grad_fn=<AddBackward0>)
Gradients:
12515.6435546875
Gradient before update: tensor(15528.9023)
Gradient after update: tensor(15528.9023)
current Learning Rate:  0.05
------------------------------------------------------------------------------------------------------------------
Iteration:  30
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0388, grad_fn=<DivBackward0>)
Projection Loss:  tensor(591.5482, grad_fn=<AddBackward0>)
Total Loss:  tensor(591.5870, grad_fn=<AddBackward0>)
Gradients:
210.62991333007812
Gradient before update: tensor(151.3393)
Gradient after update: tensor(151.3393)
current Learning Rate:  0.025
Total Loss:  tensor(591.5870, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 4.4741e-01,  4.0589e-01, -3.6359e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2226e-01,  5.8709e-01,  1.8072e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8486e+00,  5.2054e-01,  2.8059e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.2419e-01,  2.5360e-01,  2.7856e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.0543e-02, -8.5626e-03,  7.1824e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2482e+00,  1.5501e-01, -7.0824e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.1414e-01,  5.5967e-01, -5.5876e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1744e+00,  3.9272e-01,  7.4011e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.9546e-01, -1.9405e+00, -1.2856e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.9376e-01, -2.7853e-01,  1.0819e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.6448e+00, -1.4627e+00, -3.3070e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0366e+00, -5.1974e-01,  9.7418e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.4267e-01, -3.4496e-01, -2.1719e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1464e+00,  1.0487e+00,  3.4804e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2686e+00, -6.8321e-01, -3.3649e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.3703e+00,  1.2524e+00, -3.4166e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.5164e+00,  9.1578e-01,  2.1338e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8199e-02, -6.1119e-01,  2.8110e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.7407e-01,  8.5348e-01, -2.0303e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.6107e-01, -1.1801e+00,  3.7626e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.5420e+00,  1.0204e+00, -2.0142e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2145e+00,  9.3743e-01,  1.6435e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.6833e-01,  9.1344e-01, -1.1485e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.7779e-01,  9.5031e-01, -1.4062e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1346e+00, -7.8225e-03, -1.7923e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.7213e-01, -6.4259e-01, -3.5844e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.9514e+00, -2.6111e-01, -5.0870e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.1595e-01, -3.2021e-02, -1.3258e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.1885e-01, -9.1666e-01,  2.4251e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.9647e-01, -4.2553e-01,  1.4369e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.5043e-01, -4.6940e-01,  2.3369e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.7139e-01,  6.3065e-01, -2.8178e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2179e+00, -1.0354e+00, -8.6666e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0915e+00,  4.6417e-01, -2.3402e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.7471e+00, -1.2147e+00, -3.7751e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.5140e+00,  7.3411e-01, -2.7154e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.6182e-01,  1.0164e+00,  1.2266e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1583e+00, -1.3602e+00,  1.4835e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.4730e-01, -3.6378e-01, -2.4301e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-8.7716e-01, -1.3991e+00,  3.5032e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.1199e-01,  4.2124e-02, -1.2294e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.3412e-01, -1.9471e+00,  2.1020e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.8838e-01,  7.3340e-01, -2.1649e-03,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.7492e-01, -1.1088e+00,  9.7126e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.3421e-01, -1.8275e+00, -1.6109e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2100e+00, -1.6809e+00,  1.6616e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.4130e-01,  5.3645e-01,  1.7614e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-8.4284e-01,  7.6510e-01,  2.9146e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-2.2245e-01, -1.8024e+00, -3.0982e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0544e-01, -2.5219e-01, -3.3078e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.9931e+00, -7.5729e-01,  8.5369e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1959e+00, -5.9592e-01, -1.9680e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.1689e-01, -9.4310e-01, -8.1659e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.5696e-01, -2.2430e+00, -2.2885e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0229e+00,  3.1665e-01,  9.6722e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00]], requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  31
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0406, grad_fn=<DivBackward0>)
Projection Loss:  tensor(589.9758, grad_fn=<AddBackward0>)
Total Loss:  tensor(590.0164, grad_fn=<AddBackward0>)
Gradients:
2387.008544921875
Gradient before update: tensor(2603.7793)
Gradient after update: tensor(2603.7793)
current Learning Rate:  0.025
------------------------------------------------------------------------------------------------------------------
Iteration:  32
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0413, grad_fn=<DivBackward0>)
Projection Loss:  tensor(588.8340, grad_fn=<AddBackward0>)
Total Loss:  tensor(588.8752, grad_fn=<AddBackward0>)
Gradients:
120.61543273925781
Gradient before update: tensor(17.8845)
Gradient after update: tensor(17.8845)
current Learning Rate:  0.025
Total Loss:  tensor(588.8752, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 4.4887e-01,  4.0463e-01, -3.6402e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2186e-01,  5.8562e-01,  1.8064e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8534e+00,  5.3735e-01,  2.8039e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.2198e-01,  2.5581e-01,  2.7881e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 2.8093e-02, -8.5898e-03,  7.2002e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2475e+00,  1.8028e-01, -7.2398e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.1602e-01,  5.5850e-01, -5.6053e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1834e+00,  3.8839e-01,  7.5240e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.9658e-01, -1.9675e+00, -1.2910e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.9153e-01, -2.8069e-01,  1.0795e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.6367e+00, -1.4699e+00, -3.3025e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0379e+00, -5.2091e-01,  9.7238e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.4387e-01, -3.4619e-01, -2.1715e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1323e+00,  1.0613e+00,  3.4592e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2706e+00, -6.8435e-01, -3.3677e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.3562e+00,  1.2374e+00, -3.4281e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.5114e+00,  9.1857e-01,  2.1363e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-2.0682e-02, -6.1154e-01,  2.8120e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.7983e-01,  8.4841e-01, -2.0243e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.6228e-01, -1.1865e+00,  3.7761e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.5195e+00,  9.9293e-01, -2.2924e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2163e+00,  9.3685e-01,  1.6439e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.7012e-01,  9.1407e-01, -1.1462e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.8851e-01,  9.6105e-01, -1.4172e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1442e+00, -9.9356e-03, -1.7752e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.6583e-01, -6.3628e-01, -3.5899e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.9276e+00, -2.9007e-01, -4.8208e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.1728e-01, -3.2224e-02, -1.3260e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.1791e-01, -9.1657e-01,  2.4179e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.9645e-01, -4.2486e-01,  1.4356e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.5149e-01, -4.6940e-01,  2.3387e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.7241e-01,  6.2854e-01, -2.8187e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2349e+00, -1.0363e+00, -8.6537e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0901e+00,  4.6581e-01, -2.3380e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.7694e+00, -1.2370e+00, -3.9978e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.4923e+00,  7.1135e-01, -2.7002e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.7797e-01,  9.9997e-01,  1.2425e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1613e+00, -1.3799e+00,  1.4619e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.3559e-01, -3.6966e-01, -2.4426e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-8.6755e-01, -1.4087e+00,  3.5130e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.1175e-01,  4.1233e-02, -1.2288e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.3015e-01, -1.9481e+00,  2.0474e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.8673e-01,  7.3199e-01,  6.1373e-04,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.6894e-01, -1.1046e+00,  9.6525e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.3346e-01, -1.8308e+00, -1.6095e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2180e+00, -1.6748e+00,  1.6695e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.4308e-01,  5.3443e-01,  1.7336e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-8.4420e-01,  7.6616e-01,  2.9174e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-2.3868e-01, -1.8188e+00, -3.1132e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1085e-01, -2.4385e-01, -3.8864e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-2.0075e+00, -7.6199e-01,  8.6770e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1831e+00, -6.0916e-01, -1.9630e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.2769e-01, -9.5162e-01, -8.1713e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.5852e-01, -2.2622e+00, -2.3109e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0429e+00,  3.3671e-01,  9.8727e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00]], requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  33
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0415, grad_fn=<DivBackward0>)
Projection Loss:  tensor(589.8650, grad_fn=<AddBackward0>)
Total Loss:  tensor(589.9065, grad_fn=<AddBackward0>)
Gradients:
1669.122314453125
Gradient before update: tensor(643.4884)
Gradient after update: tensor(643.4884)
current Learning Rate:  0.025
------------------------------------------------------------------------------------------------------------------
Iteration:  34
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0415, grad_fn=<DivBackward0>)
Projection Loss:  tensor(582.5118, grad_fn=<AddBackward0>)
Total Loss:  tensor(582.5533, grad_fn=<AddBackward0>)
Gradients:
482.5754089355469
Gradient before update: tensor(-469.3597)
Gradient after update: tensor(-469.3597)
current Learning Rate:  0.025
Total Loss:  tensor(582.5533, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 4.5008e-01,  4.0358e-01, -3.6439e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2153e-01,  5.8439e-01,  1.8056e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8292e+00,  5.1786e-01,  2.7972e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.2014e-01,  2.5766e-01,  2.7903e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 2.6059e-02, -8.6120e-03,  7.2150e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2471e+00,  1.9976e-01, -7.3789e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.1748e-01,  5.5742e-01, -5.6414e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1921e+00,  3.8515e-01,  7.6198e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.6849e-01, -1.9957e+00, -1.3194e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.8969e-01, -2.8248e-01,  1.0776e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.6325e+00, -1.4793e+00, -3.3000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0390e+00, -5.2189e-01,  9.7089e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.4487e-01, -3.4720e-01, -2.1711e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1205e+00,  1.0717e+00,  3.4416e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2723e+00, -6.8520e-01, -3.3699e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.3443e+00,  1.2239e+00, -3.4378e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.5071e+00,  9.2089e-01,  2.1383e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-2.2739e-02, -6.1214e-01,  2.8128e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8461e-01,  8.4421e-01, -2.0193e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.6263e-01, -1.1920e+00,  3.7873e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.5032e+00,  9.7007e-01, -2.5260e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2178e+00,  9.3636e-01,  1.6443e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.7217e-01,  9.1459e-01, -1.1440e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.9751e-01,  9.6987e-01, -1.4264e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1545e+00, -9.8544e-03, -1.7570e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.6061e-01, -6.3104e-01, -3.5944e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.9104e+00, -3.1110e-01, -4.6659e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.1843e-01, -3.2375e-02, -1.3261e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.1713e-01, -9.1651e-01,  2.4119e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.9644e-01, -4.2431e-01,  1.4345e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.5238e-01, -4.6940e-01,  2.3402e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.7326e-01,  6.2679e-01, -2.8193e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2580e+00, -1.0229e+00, -8.5670e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0888e+00,  4.6717e-01, -2.3361e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.7878e+00, -1.2554e+00, -4.1825e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.4743e+00,  6.9245e-01, -2.6876e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.9136e-01,  9.8633e-01,  1.2558e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1638e+00, -1.3963e+00,  1.4439e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.2587e-01, -3.7455e-01, -2.4530e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-8.5959e-01, -1.4165e+00,  3.5210e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.1155e-01,  4.0493e-02, -1.2283e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.2471e-01, -1.9696e+00,  1.9520e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.8545e-01,  7.3083e-01,  1.2500e-03,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.9714e-01, -1.1352e+00,  9.9497e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.3284e-01, -1.8336e+00, -1.6083e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2246e+00, -1.6698e+00,  1.6761e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.4455e-01,  5.3276e-01,  1.7106e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-8.4517e-01,  7.6699e-01,  2.9197e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-2.1687e-01, -1.8173e+00, -3.0915e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1534e-01, -2.3693e-01, -4.3665e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-2.0036e+00, -7.4933e-01,  8.7699e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1742e+00, -6.0988e-01, -1.9583e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.3668e-01, -9.5869e-01, -8.1759e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.6007e-01, -2.2784e+00, -2.3295e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0595e+00,  3.5335e-01,  1.0039e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00]], requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  35
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0413, grad_fn=<DivBackward0>)
Projection Loss:  tensor(579.5327, grad_fn=<AddBackward0>)
Total Loss:  tensor(579.5740, grad_fn=<AddBackward0>)
Gradients:
8855.7666015625
Gradient before update: tensor(-11468.0469)
Gradient after update: tensor(-11468.0469)
current Learning Rate:  0.025
------------------------------------------------------------------------------------------------------------------
Iteration:  36
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0409, grad_fn=<DivBackward0>)
Projection Loss:  tensor(572.9553, grad_fn=<AddBackward0>)
Total Loss:  tensor(572.9962, grad_fn=<AddBackward0>)
Gradients:
47.36698913574219
Gradient before update: tensor(59.8477)
Gradient after update: tensor(59.8477)
current Learning Rate:  0.025
Total Loss:  tensor(572.9962, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4511,  0.4027, -3.6469,  0.0000,  0.0000,  0.0000],
        [-0.1213,  0.5834,  1.8050,  0.0000,  0.0000,  0.0000],
        [-1.8087,  0.5016,  2.7917,  0.0000,  0.0000,  0.0000],
        [ 0.8186,  0.2592,  2.7920,  0.0000,  0.0000,  0.0000],
        [ 0.0244, -0.0086,  0.7227,  0.0000,  0.0000,  0.0000],
        [ 1.2475,  0.2141, -0.7502,  0.0000,  0.0000,  0.0000],
        [ 0.5175,  0.5553, -0.5669,  0.0000,  0.0000,  0.0000],
        [ 1.2007,  0.3829,  0.7697,  0.0000,  0.0000,  0.0000],
        [-0.6452, -2.0192, -1.3428,  0.0000,  0.0000,  0.0000],
        [ 0.8882, -0.2840,  1.0760,  0.0000,  0.0000,  0.0000],
        [-1.6291, -1.4871, -3.2980,  0.0000,  0.0000,  0.0000],
        [-1.0399, -0.5227,  0.9697,  0.0000,  0.0000,  0.0000],
        [ 0.3457, -0.3480, -2.1708,  0.0000,  0.0000,  0.0000],
        [ 1.1106,  1.0805,  3.4270,  0.0000,  0.0000,  0.0000],
        [-1.2742, -0.6860, -3.3718,  0.0000,  0.0000,  0.0000],
        [-1.3345,  1.2119, -3.4459,  0.0000,  0.0000,  0.0000],
        [ 1.5036,  0.9228,  2.1400,  0.0000,  0.0000,  0.0000],
        [-0.0244, -0.6135,  2.8134,  0.0000,  0.0000,  0.0000],
        [-0.7886,  0.8407, -2.0152,  0.0000,  0.0000,  0.0000],
        [-0.3625, -1.1967,  0.3796,  0.0000,  0.0000,  0.0000],
        [ 1.4899,  0.9511, -0.2720,  0.0000,  0.0000,  0.0000],
        [-1.2191,  0.9360,  1.6446,  0.0000,  0.0000,  0.0000],
        [ 0.8745,  0.9150, -1.1416,  0.0000,  0.0000,  0.0000],
        [ 0.4049,  0.9772, -1.4341,  0.0000,  0.0000,  0.0000],
        [-1.1631, -0.0098, -1.7419,  0.0000,  0.0000,  0.0000],
        [ 0.6563, -0.6267, -3.5982,  0.0000,  0.0000,  0.0000],
        [-1.8812, -0.2827, -0.4953,  0.0000,  0.0000,  0.0000],
        [-0.4195, -0.0325, -1.3263,  0.0000,  0.0000,  0.0000],
        [ 0.9165, -0.9165,  0.2407,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4239,  1.4336,  0.0000,  0.0000,  0.0000],
        [-0.6531, -0.4694,  2.3414,  0.0000,  0.0000,  0.0000],
        [ 0.4740,  0.6253, -2.8199,  0.0000,  0.0000,  0.0000],
        [ 1.2948, -1.0104, -0.8386,  0.0000,  0.0000,  0.0000],
        [ 1.0878,  0.4683, -2.3346,  0.0000,  0.0000,  0.0000],
        [-1.8031, -1.2707, -0.4336,  0.0000,  0.0000,  0.0000],
        [-1.4594,  0.6768, -2.6771,  0.0000,  0.0000,  0.0000],
        [ 0.8025,  0.9750,  1.2668,  0.0000,  0.0000,  0.0000],
        [ 1.1659, -1.4099,  1.4291,  0.0000,  0.0000,  0.0000],
        [-0.5178, -0.3786, -2.4617,  0.0000,  0.0000,  0.0000],
        [-0.8530, -1.4229,  3.5274,  0.0000,  0.0000,  0.0000],
        [ 0.6114,  0.0399, -1.2279,  0.0000,  0.0000,  0.0000],
        [ 0.3202, -1.9869,  0.1797,  0.0000,  0.0000,  0.0000],
        [-0.3847,  0.7299, -0.0047,  0.0000,  0.0000,  0.0000],
        [ 0.4256, -1.1632,  1.0213,  0.0000,  0.0000,  0.0000],
        [ 0.8323, -1.8359, -1.6073,  0.0000,  0.0000,  0.0000],
        [-1.2301, -1.6657,  1.6816,  0.0000,  0.0000,  0.0000],
        [ 0.3458,  0.5314,  0.1692,  0.0000,  0.0000,  0.0000],
        [-0.8427,  0.7667,  2.9216,  0.0000,  0.0000,  0.0000],
        [-0.1988, -1.8160, -3.0736,  0.0000,  0.0000,  0.0000],
        [ 0.1191, -0.2312, -0.0476,  0.0000,  0.0000,  0.0000],
        [-1.9859, -0.7237,  0.8825,  0.0000,  0.0000,  0.0000],
        [ 1.1683, -0.6009, -1.9539,  0.0000,  0.0000,  0.0000],
        [-0.6441, -0.9646, -0.8180,  0.0000,  0.0000,  0.0000],
        [ 0.7450, -2.3043, -2.3456,  0.0000,  0.0000,  0.0000],
        [-1.0732,  0.3672,  1.0177,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  37
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0404, grad_fn=<DivBackward0>)
Projection Loss:  tensor(569.9122, grad_fn=<AddBackward0>)
Total Loss:  tensor(569.9526, grad_fn=<AddBackward0>)
Gradients:
2109.8623046875
Gradient before update: tensor(1550.3634)
Gradient after update: tensor(1550.3634)
current Learning Rate:  0.025
------------------------------------------------------------------------------------------------------------------
Iteration:  38
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0398, grad_fn=<DivBackward0>)
Projection Loss:  tensor(562.8339, grad_fn=<AddBackward0>)
Total Loss:  tensor(562.8737, grad_fn=<AddBackward0>)
Gradients:
69.8535385131836
Gradient before update: tensor(-24.9632)
Gradient after update: tensor(-24.9632)
current Learning Rate:  0.025
Total Loss:  tensor(562.8737, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4519,  0.4020, -3.6494,  0.0000,  0.0000,  0.0000],
        [-0.1210,  0.5825,  1.8045,  0.0000,  0.0000,  0.0000],
        [-1.7918,  0.4880,  2.7872,  0.0000,  0.0000,  0.0000],
        [ 0.8174,  0.2604,  2.7935,  0.0000,  0.0000,  0.0000],
        [ 0.0230, -0.0086,  0.7237,  0.0000,  0.0000,  0.0000],
        [ 1.2574,  0.2112, -0.7603,  0.0000,  0.0000,  0.0000],
        [ 0.5163,  0.5524, -0.5679,  0.0000,  0.0000,  0.0000],
        [ 1.2096,  0.3829,  0.7735,  0.0000,  0.0000,  0.0000],
        [-0.6259, -2.0387, -1.3613,  0.0000,  0.0000,  0.0000],
        [ 0.8869, -0.2852,  1.0747,  0.0000,  0.0000,  0.0000],
        [-1.6262, -1.4937, -3.2963,  0.0000,  0.0000,  0.0000],
        [-1.0407, -0.5234,  0.9686,  0.0000,  0.0000,  0.0000],
        [ 0.3464, -0.3487, -2.1706,  0.0000,  0.0000,  0.0000],
        [ 1.1025,  1.0878,  3.4150,  0.0000,  0.0000,  0.0000],
        [-1.2448, -0.7154, -3.3424,  0.0000,  0.0000,  0.0000],
        [-1.3261,  1.2010, -3.4525,  0.0000,  0.0000,  0.0000],
        [ 1.5007,  0.9244,  2.1414,  0.0000,  0.0000,  0.0000],
        [-0.0258, -0.6154,  2.8139,  0.0000,  0.0000,  0.0000],
        [-0.7919,  0.8378, -2.0117,  0.0000,  0.0000,  0.0000],
        [-0.3622, -1.2006,  0.3804,  0.0000,  0.0000,  0.0000],
        [ 1.4789,  0.9355, -0.2880,  0.0000,  0.0000,  0.0000],
        [-1.2201,  0.9356,  1.6449,  0.0000,  0.0000,  0.0000],
        [ 0.8769,  0.9154, -1.1393,  0.0000,  0.0000,  0.0000],
        [ 0.4111,  0.9832, -1.4404,  0.0000,  0.0000,  0.0000],
        [-1.1702, -0.0097, -1.7294,  0.0000,  0.0000,  0.0000],
        [ 0.6527, -0.6231, -3.6013,  0.0000,  0.0000,  0.0000],
        [-1.8569, -0.2591, -0.5190,  0.0000,  0.0000,  0.0000],
        [-0.4204, -0.0325, -1.3264,  0.0000,  0.0000,  0.0000],
        [ 0.9160, -0.9164,  0.2403,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4235,  1.4329,  0.0000,  0.0000,  0.0000],
        [-0.6537, -0.4694,  2.3424,  0.0000,  0.0000,  0.0000],
        [ 0.4746,  0.6241, -2.8204,  0.0000,  0.0000,  0.0000],
        [ 1.3282, -1.0002, -0.8232,  0.0000,  0.0000,  0.0000],
        [ 1.0870,  0.4692, -2.3333,  0.0000,  0.0000,  0.0000],
        [-1.8158, -1.2833, -0.4462,  0.0000,  0.0000,  0.0000],
        [-1.4470,  0.6638, -2.6684,  0.0000,  0.0000,  0.0000],
        [ 0.8117,  0.9656,  1.2759,  0.0000,  0.0000,  0.0000],
        [ 1.1677, -1.4212,  1.4167,  0.0000,  0.0000,  0.0000],
        [-0.5111, -0.3820, -2.4688,  0.0000,  0.0000,  0.0000],
        [-0.8476, -1.4282,  3.5327,  0.0000,  0.0000,  0.0000],
        [ 0.6112,  0.0394, -1.2276,  0.0000,  0.0000,  0.0000],
        [ 0.3165, -2.0012,  0.1667,  0.0000,  0.0000,  0.0000],
        [-0.3844,  0.7291, -0.0146,  0.0000,  0.0000,  0.0000],
        [ 0.4492, -1.1864,  1.0431,  0.0000,  0.0000,  0.0000],
        [ 0.8319, -1.8378, -1.6064,  0.0000,  0.0000,  0.0000],
        [-1.2347, -1.6622,  1.6861,  0.0000,  0.0000,  0.0000],
        [ 0.3468,  0.5302,  0.1676,  0.0000,  0.0000,  0.0000],
        [-0.8353,  0.7647,  2.9234,  0.0000,  0.0000,  0.0000],
        [-0.1837, -1.8150, -3.0586,  0.0000,  0.0000,  0.0000],
        [ 0.1222, -0.2264, -0.0509,  0.0000,  0.0000,  0.0000],
        [-1.9626, -0.6966,  0.8616,  0.0000,  0.0000,  0.0000],
        [ 1.1635, -0.5933, -1.9502,  0.0000,  0.0000,  0.0000],
        [-0.6503, -0.9694, -0.8183,  0.0000,  0.0000,  0.0000],
        [ 0.7284, -2.3242, -2.3598,  0.0000,  0.0000,  0.0000],
        [-1.0846,  0.3786,  1.0292,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  39
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0392, grad_fn=<DivBackward0>)
Projection Loss:  tensor(562.9027, grad_fn=<AddBackward0>)
Total Loss:  tensor(562.9419, grad_fn=<AddBackward0>)
Gradients:
128.38021850585938
Gradient before update: tensor(177.4727)
Gradient after update: tensor(177.4727)
current Learning Rate:  0.025
------------------------------------------------------------------------------------------------------------------
Iteration:  40
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0385, grad_fn=<DivBackward0>)
Projection Loss:  tensor(559.7805, grad_fn=<AddBackward0>)
Total Loss:  tensor(559.8190, grad_fn=<AddBackward0>)
Gradients:
11731.8154296875
Gradient before update: tensor(-4598.2300)
Gradient after update: tensor(-4598.2300)
current Learning Rate:  0.025
Total Loss:  tensor(559.8190, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4526,  0.4014, -3.6515,  0.0000,  0.0000,  0.0000],
        [-0.1208,  0.5818,  1.8041,  0.0000,  0.0000,  0.0000],
        [-1.7778,  0.4768,  2.7834,  0.0000,  0.0000,  0.0000],
        [ 0.8163,  0.2615,  2.7947,  0.0000,  0.0000,  0.0000],
        [ 0.0218, -0.0087,  0.7246,  0.0000,  0.0000,  0.0000],
        [ 1.2658,  0.2086, -0.7685,  0.0000,  0.0000,  0.0000],
        [ 0.5139,  0.5488, -0.5673,  0.0000,  0.0000,  0.0000],
        [ 1.2185,  0.3849,  0.7743,  0.0000,  0.0000,  0.0000],
        [-0.6095, -2.0566, -1.3423,  0.0000,  0.0000,  0.0000],
        [ 0.8858, -0.2862,  1.0736,  0.0000,  0.0000,  0.0000],
        [-1.6513, -1.5241, -3.3236,  0.0000,  0.0000,  0.0000],
        [-1.0413, -0.5239,  0.9678,  0.0000,  0.0000,  0.0000],
        [ 0.3469, -0.3493, -2.1704,  0.0000,  0.0000,  0.0000],
        [ 1.1158,  1.0967,  3.4053,  0.0000,  0.0000,  0.0000],
        [-1.2212, -0.7398, -3.3181,  0.0000,  0.0000,  0.0000],
        [-1.3188,  1.1904, -3.4579,  0.0000,  0.0000,  0.0000],
        [ 1.4983,  0.9257,  2.1426,  0.0000,  0.0000,  0.0000],
        [-0.0109, -0.6323,  2.8298,  0.0000,  0.0000,  0.0000],
        [-0.7946,  0.8354, -2.0089,  0.0000,  0.0000,  0.0000],
        [-0.3617, -1.2039,  0.3811,  0.0000,  0.0000,  0.0000],
        [ 1.4698,  0.9225, -0.3013,  0.0000,  0.0000,  0.0000],
        [-1.2210,  0.9354,  1.6451,  0.0000,  0.0000,  0.0000],
        [ 0.8795,  0.9156, -1.1368,  0.0000,  0.0000,  0.0000],
        [ 0.4162,  0.9882, -1.4457,  0.0000,  0.0000,  0.0000],
        [-1.1761, -0.0096, -1.7190,  0.0000,  0.0000,  0.0000],
        [ 0.6497, -0.6201, -3.6039,  0.0000,  0.0000,  0.0000],
        [-1.8368, -0.2395, -0.5387,  0.0000,  0.0000,  0.0000],
        [-0.4217, -0.0325, -1.3265,  0.0000,  0.0000,  0.0000],
        [ 0.9155, -0.9164,  0.2399,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4232,  1.4323,  0.0000,  0.0000,  0.0000],
        [-0.6542, -0.4694,  2.3433,  0.0000,  0.0000,  0.0000],
        [ 0.4750,  0.6231, -2.8208,  0.0000,  0.0000,  0.0000],
        [ 1.3563, -0.9916, -0.8104,  0.0000,  0.0000,  0.0000],
        [ 1.0863,  0.4700, -2.3322,  0.0000,  0.0000,  0.0000],
        [-1.8262, -1.2937, -0.4567,  0.0000,  0.0000,  0.0000],
        [-1.4368,  0.6530, -2.6612,  0.0000,  0.0000,  0.0000],
        [ 0.8193,  0.9579,  1.2834,  0.0000,  0.0000,  0.0000],
        [ 1.1691, -1.4305,  1.4065,  0.0000,  0.0000,  0.0000],
        [-0.5056, -0.3847, -2.4748,  0.0000,  0.0000,  0.0000],
        [-0.8431, -1.4326,  3.5372,  0.0000,  0.0000,  0.0000],
        [ 0.6111,  0.0389, -1.2273,  0.0000,  0.0000,  0.0000],
        [ 0.2990, -2.0236,  0.1766,  0.0000,  0.0000,  0.0000],
        [-0.3842,  0.7285, -0.0227,  0.0000,  0.0000,  0.0000],
        [ 0.4687, -1.2057,  1.0612,  0.0000,  0.0000,  0.0000],
        [ 0.8315, -1.8394, -1.6057,  0.0000,  0.0000,  0.0000],
        [-1.2385, -1.6593,  1.6898,  0.0000,  0.0000,  0.0000],
        [ 0.3476,  0.5293,  0.1663,  0.0000,  0.0000,  0.0000],
        [-0.8282,  0.7629,  2.9249,  0.0000,  0.0000,  0.0000],
        [-0.1713, -1.8142, -3.0463,  0.0000,  0.0000,  0.0000],
        [ 0.1247, -0.2225, -0.0537,  0.0000,  0.0000,  0.0000],
        [-1.9414, -0.6738,  0.8421,  0.0000,  0.0000,  0.0000],
        [ 1.1595, -0.5870, -1.9471,  0.0000,  0.0000,  0.0000],
        [-0.6555, -0.9735, -0.8185,  0.0000,  0.0000,  0.0000],
        [ 0.7373, -2.3490, -2.3501,  0.0000,  0.0000,  0.0000],
        [-1.0941,  0.3881,  1.0386,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  41
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0378, grad_fn=<DivBackward0>)
Projection Loss:  tensor(552.5770, grad_fn=<AddBackward0>)
Total Loss:  tensor(552.6148, grad_fn=<AddBackward0>)
Gradients:
339.348388671875
Gradient before update: tensor(-416.7146)
Gradient after update: tensor(-416.7146)
current Learning Rate:  0.025
------------------------------------------------------------------------------------------------------------------
Iteration:  42
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0370, grad_fn=<DivBackward0>)
Projection Loss:  tensor(548.0049, grad_fn=<AddBackward0>)
Total Loss:  tensor(548.0419, grad_fn=<AddBackward0>)
Gradients:
2319.650390625
Gradient before update: tensor(1784.6725)
Gradient after update: tensor(1784.6725)
current Learning Rate:  0.025
Total Loss:  tensor(548.0419, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4532,  0.4009, -3.6532,  0.0000,  0.0000,  0.0000],
        [-0.1207,  0.5813,  1.8038,  0.0000,  0.0000,  0.0000],
        [-1.7663,  0.4676,  2.7803,  0.0000,  0.0000,  0.0000],
        [ 0.8154,  0.2624,  2.7957,  0.0000,  0.0000,  0.0000],
        [ 0.0209, -0.0087,  0.7253,  0.0000,  0.0000,  0.0000],
        [ 1.2533,  0.2236, -0.7883,  0.0000,  0.0000,  0.0000],
        [ 0.5110,  0.5450, -0.5658,  0.0000,  0.0000,  0.0000],
        [ 1.2260,  0.3865,  0.7750,  0.0000,  0.0000,  0.0000],
        [-0.5959, -2.0715, -1.3265,  0.0000,  0.0000,  0.0000],
        [ 0.8850, -0.2871,  1.0727,  0.0000,  0.0000,  0.0000],
        [-1.6519, -1.5374, -3.3478,  0.0000,  0.0000,  0.0000],
        [-1.0420, -0.5244,  0.9671,  0.0000,  0.0000,  0.0000],
        [ 0.3474, -0.3498, -2.1702,  0.0000,  0.0000,  0.0000],
        [ 1.1270,  1.1041,  3.3973,  0.0000,  0.0000,  0.0000],
        [-1.2023, -0.7600, -3.2979,  0.0000,  0.0000,  0.0000],
        [-1.3128,  1.1809, -3.4624,  0.0000,  0.0000,  0.0000],
        [ 1.4964,  0.9268,  2.1436,  0.0000,  0.0000,  0.0000],
        [ 0.0162, -0.6599,  2.8569,  0.0000,  0.0000,  0.0000],
        [-0.7968,  0.8335, -2.0066,  0.0000,  0.0000,  0.0000],
        [-0.3611, -1.2066,  0.3816,  0.0000,  0.0000,  0.0000],
        [ 1.4622,  0.9117, -0.3124,  0.0000,  0.0000,  0.0000],
        [-1.2217,  0.9351,  1.6453,  0.0000,  0.0000,  0.0000],
        [ 0.8823,  0.9159, -1.1343,  0.0000,  0.0000,  0.0000],
        [ 0.4204,  0.9924, -1.4502,  0.0000,  0.0000,  0.0000],
        [-1.1809, -0.0096, -1.7104,  0.0000,  0.0000,  0.0000],
        [ 0.6472, -0.6176, -3.6057,  0.0000,  0.0000,  0.0000],
        [-1.8202, -0.2234, -0.5550,  0.0000,  0.0000,  0.0000],
        [-0.4387, -0.0163, -1.3423,  0.0000,  0.0000,  0.0000],
        [ 0.9151, -0.9163,  0.2397,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4230,  1.4318,  0.0000,  0.0000,  0.0000],
        [-0.6547, -0.4694,  2.3440,  0.0000,  0.0000,  0.0000],
        [ 0.4754,  0.6223, -2.8211,  0.0000,  0.0000,  0.0000],
        [ 1.3901, -0.9979, -0.8194,  0.0000,  0.0000,  0.0000],
        [ 1.0857,  0.4706, -2.3313,  0.0000,  0.0000,  0.0000],
        [-1.8349, -1.3023, -0.4654,  0.0000,  0.0000,  0.0000],
        [-1.4283,  0.6441, -2.6553,  0.0000,  0.0000,  0.0000],
        [ 0.8256,  0.9514,  1.2897,  0.0000,  0.0000,  0.0000],
        [ 1.1703, -1.4382,  1.3980,  0.0000,  0.0000,  0.0000],
        [-0.5010, -0.3870, -2.4797,  0.0000,  0.0000,  0.0000],
        [-0.8393, -1.4362,  3.5408,  0.0000,  0.0000,  0.0000],
        [ 0.6110,  0.0386, -1.2271,  0.0000,  0.0000,  0.0000],
        [ 0.2714, -2.0518,  0.2038,  0.0000,  0.0000,  0.0000],
        [-0.3839,  0.7280, -0.0294,  0.0000,  0.0000,  0.0000],
        [ 0.4847, -1.2216,  1.0762,  0.0000,  0.0000,  0.0000],
        [ 0.8313, -1.8407, -1.6052,  0.0000,  0.0000,  0.0000],
        [-1.2416, -1.6570,  1.6929,  0.0000,  0.0000,  0.0000],
        [ 0.3483,  0.5285,  0.1652,  0.0000,  0.0000,  0.0000],
        [-0.8223,  0.7613,  2.9261,  0.0000,  0.0000,  0.0000],
        [-0.1610, -1.8134, -3.0361,  0.0000,  0.0000,  0.0000],
        [ 0.1268, -0.2192, -0.0560,  0.0000,  0.0000,  0.0000],
        [-1.9075, -0.6491,  0.8388,  0.0000,  0.0000,  0.0000],
        [ 1.1563, -0.5818, -1.9446,  0.0000,  0.0000,  0.0000],
        [-0.6597, -0.9768, -0.8188,  0.0000,  0.0000,  0.0000],
        [ 0.7649, -2.3768, -2.3226,  0.0000,  0.0000,  0.0000],
        [-1.1019,  0.3959,  1.0465,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  43
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0362, grad_fn=<DivBackward0>)
Projection Loss:  tensor(548.6028, grad_fn=<AddBackward0>)
Total Loss:  tensor(548.6390, grad_fn=<AddBackward0>)
Gradients:
176.35336303710938
Gradient before update: tensor(151.1604)
Gradient after update: tensor(151.1604)
current Learning Rate:  0.025
------------------------------------------------------------------------------------------------------------------
Iteration:  44
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0355, grad_fn=<DivBackward0>)
Projection Loss:  tensor(543.0110, grad_fn=<AddBackward0>)
Total Loss:  tensor(543.0465, grad_fn=<AddBackward0>)
Gradients:
410.1123046875
Gradient before update: tensor(-514.4748)
Gradient after update: tensor(-514.4748)
current Learning Rate:  0.025
Total Loss:  tensor(543.0465, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4536,  0.4005, -3.6546,  0.0000,  0.0000,  0.0000],
        [-0.1206,  0.5808,  1.8035,  0.0000,  0.0000,  0.0000],
        [-1.7568,  0.4599,  2.7779,  0.0000,  0.0000,  0.0000],
        [ 0.8147,  0.2631,  2.7965,  0.0000,  0.0000,  0.0000],
        [ 0.0201, -0.0087,  0.7259,  0.0000,  0.0000,  0.0000],
        [ 1.2251,  0.2518, -0.8166,  0.0000,  0.0000,  0.0000],
        [ 0.5085,  0.5418, -0.5646,  0.0000,  0.0000,  0.0000],
        [ 1.2321,  0.3879,  0.7755,  0.0000,  0.0000,  0.0000],
        [-0.5846, -2.0839, -1.3134,  0.0000,  0.0000,  0.0000],
        [ 0.8842, -0.2878,  1.0720,  0.0000,  0.0000,  0.0000],
        [-1.6311, -1.5321, -3.3708,  0.0000,  0.0000,  0.0000],
        [-1.0440, -0.5245,  0.9665,  0.0000,  0.0000,  0.0000],
        [ 0.3478, -0.3502, -2.1701,  0.0000,  0.0000,  0.0000],
        [ 1.1488,  1.0765,  3.3661,  0.0000,  0.0000,  0.0000],
        [-1.1867, -0.7767, -3.2812,  0.0000,  0.0000,  0.0000],
        [-1.3084,  1.1717, -3.4666,  0.0000,  0.0000,  0.0000],
        [ 1.4947,  0.9277,  2.1444,  0.0000,  0.0000,  0.0000],
        [ 0.0386, -0.6828,  2.8795,  0.0000,  0.0000,  0.0000],
        [-0.7986,  0.8320, -2.0046,  0.0000,  0.0000,  0.0000],
        [-0.3605, -1.2088,  0.3821,  0.0000,  0.0000,  0.0000],
        [ 1.4560,  0.9028, -0.3215,  0.0000,  0.0000,  0.0000],
        [-1.2223,  0.9350,  1.6455,  0.0000,  0.0000,  0.0000],
        [ 0.8851,  0.9160, -1.1317,  0.0000,  0.0000,  0.0000],
        [ 0.4239,  0.9958, -1.4541,  0.0000,  0.0000,  0.0000],
        [-1.1850, -0.0095, -1.7033,  0.0000,  0.0000,  0.0000],
        [ 0.6451, -0.6156, -3.6073,  0.0000,  0.0000,  0.0000],
        [-1.8064, -0.2100, -0.5685,  0.0000,  0.0000,  0.0000],
        [-0.4669,  0.0120, -1.3694,  0.0000,  0.0000,  0.0000],
        [ 0.9148, -0.9163,  0.2394,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4228,  1.4314,  0.0000,  0.0000,  0.0000],
        [-0.6550, -0.4694,  2.3445,  0.0000,  0.0000,  0.0000],
        [ 0.4758,  0.6216, -2.8214,  0.0000,  0.0000,  0.0000],
        [ 1.4264, -1.0249, -0.8444,  0.0000,  0.0000,  0.0000],
        [ 1.0852,  0.4712, -2.3306,  0.0000,  0.0000,  0.0000],
        [-1.8418, -1.3075, -0.4744,  0.0000,  0.0000,  0.0000],
        [-1.4213,  0.6367, -2.6504,  0.0000,  0.0000,  0.0000],
        [ 0.8308,  0.9461,  1.2948,  0.0000,  0.0000,  0.0000],
        [ 1.1720, -1.4454,  1.3919,  0.0000,  0.0000,  0.0000],
        [-0.4972, -0.3890, -2.4837,  0.0000,  0.0000,  0.0000],
        [-0.8363, -1.4393,  3.5438,  0.0000,  0.0000,  0.0000],
        [ 0.6110,  0.0383, -1.2269,  0.0000,  0.0000,  0.0000],
        [ 0.2485, -2.0750,  0.2271,  0.0000,  0.0000,  0.0000],
        [-0.3837,  0.7275, -0.0348,  0.0000,  0.0000,  0.0000],
        [ 0.4978, -1.2348,  1.0887,  0.0000,  0.0000,  0.0000],
        [ 0.8310, -1.8418, -1.6047,  0.0000,  0.0000,  0.0000],
        [-1.2442, -1.6550,  1.6955,  0.0000,  0.0000,  0.0000],
        [ 0.3489,  0.5278,  0.1643,  0.0000,  0.0000,  0.0000],
        [-0.8172,  0.7599,  2.9272,  0.0000,  0.0000,  0.0000],
        [-0.1416, -1.8070, -3.0152,  0.0000,  0.0000,  0.0000],
        [ 0.1286, -0.2165, -0.0578,  0.0000,  0.0000,  0.0000],
        [-1.8794, -0.6287,  0.8360,  0.0000,  0.0000,  0.0000],
        [ 1.1535, -0.5774, -1.9425,  0.0000,  0.0000,  0.0000],
        [-0.6632, -0.9796, -0.8189,  0.0000,  0.0000,  0.0000],
        [ 0.7877, -2.3998, -2.2999,  0.0000,  0.0000,  0.0000],
        [-1.1084,  0.4024,  1.0530,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  45
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0350, grad_fn=<DivBackward0>)
Projection Loss:  tensor(539.8990, grad_fn=<AddBackward0>)
Total Loss:  tensor(539.9340, grad_fn=<AddBackward0>)
Gradients:
1671.2750244140625
Gradient before update: tensor(2572.5574)
Gradient after update: tensor(2572.5574)
current Learning Rate:  0.0125
------------------------------------------------------------------------------------------------------------------
Iteration:  46
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0344, grad_fn=<DivBackward0>)
Projection Loss:  tensor(538.9916, grad_fn=<AddBackward0>)
Total Loss:  tensor(539.0260, grad_fn=<AddBackward0>)
Gradients:
3814.858154296875
Gradient before update: tensor(-3482.1003)
Gradient after update: tensor(-3482.1003)
current Learning Rate:  0.0125
Total Loss:  tensor(539.0260, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4539,  0.4002, -3.6555,  0.0000,  0.0000,  0.0000],
        [-0.1205,  0.5805,  1.8033,  0.0000,  0.0000,  0.0000],
        [-1.7508,  0.4551,  2.7763,  0.0000,  0.0000,  0.0000],
        [ 0.8143,  0.2635,  2.7970,  0.0000,  0.0000,  0.0000],
        [ 0.0196, -0.0087,  0.7262,  0.0000,  0.0000,  0.0000],
        [ 1.2073,  0.2695, -0.8343,  0.0000,  0.0000,  0.0000],
        [ 0.5070,  0.5398, -0.5642,  0.0000,  0.0000,  0.0000],
        [ 1.2360,  0.3887,  0.7759,  0.0000,  0.0000,  0.0000],
        [-0.5775, -2.0917, -1.3051,  0.0000,  0.0000,  0.0000],
        [ 0.8838, -0.2882,  1.0715,  0.0000,  0.0000,  0.0000],
        [-1.6181, -1.5293, -3.3850,  0.0000,  0.0000,  0.0000],
        [-1.0460, -0.5245,  0.9661,  0.0000,  0.0000,  0.0000],
        [ 0.3481, -0.3505, -2.1700,  0.0000,  0.0000,  0.0000],
        [ 1.1623,  1.0592,  3.3464,  0.0000,  0.0000,  0.0000],
        [-1.1769, -0.7873, -3.2707,  0.0000,  0.0000,  0.0000],
        [-1.3064,  1.1549, -3.4656,  0.0000,  0.0000,  0.0000],
        [ 1.4937,  0.9283,  2.1449,  0.0000,  0.0000,  0.0000],
        [ 0.0528, -0.6972,  2.8936,  0.0000,  0.0000,  0.0000],
        [-0.7994,  0.8317, -2.0032,  0.0000,  0.0000,  0.0000],
        [-0.3599, -1.2102,  0.3824,  0.0000,  0.0000,  0.0000],
        [ 1.4520,  0.8972, -0.3272,  0.0000,  0.0000,  0.0000],
        [-1.2226,  0.9348,  1.6456,  0.0000,  0.0000,  0.0000],
        [ 0.8873,  0.9161, -1.1297,  0.0000,  0.0000,  0.0000],
        [ 0.4262,  0.9980, -1.4565,  0.0000,  0.0000,  0.0000],
        [-1.2094, -0.0338, -1.6789,  0.0000,  0.0000,  0.0000],
        [ 0.6438, -0.6143, -3.6083,  0.0000,  0.0000,  0.0000],
        [-1.7977, -0.2015, -0.5770,  0.0000,  0.0000,  0.0000],
        [-0.4848,  0.0299, -1.3863,  0.0000,  0.0000,  0.0000],
        [ 0.9146, -0.9163,  0.2393,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4227,  1.4311,  0.0000,  0.0000,  0.0000],
        [-0.6552, -0.4694,  2.3449,  0.0000,  0.0000,  0.0000],
        [ 0.4760,  0.6212, -2.8215,  0.0000,  0.0000,  0.0000],
        [ 1.4498, -1.0418, -0.8601,  0.0000,  0.0000,  0.0000],
        [ 1.0849,  0.4715, -2.3301,  0.0000,  0.0000,  0.0000],
        [-1.8458, -1.3094, -0.4813,  0.0000,  0.0000,  0.0000],
        [-1.4168,  0.6321, -2.6472,  0.0000,  0.0000,  0.0000],
        [ 0.8267,  0.9514,  1.3054,  0.0000,  0.0000,  0.0000],
        [ 1.1736, -1.4504,  1.3885,  0.0000,  0.0000,  0.0000],
        [-0.4948, -0.3902, -2.4863,  0.0000,  0.0000,  0.0000],
        [-0.8343, -1.4412,  3.5457,  0.0000,  0.0000,  0.0000],
        [ 0.6105,  0.0380, -1.2269,  0.0000,  0.0000,  0.0000],
        [ 0.2340, -2.0894,  0.2425,  0.0000,  0.0000,  0.0000],
        [-0.3836,  0.7273, -0.0381,  0.0000,  0.0000,  0.0000],
        [ 0.5060, -1.2431,  1.0965,  0.0000,  0.0000,  0.0000],
        [ 0.8309, -1.8425, -1.6044,  0.0000,  0.0000,  0.0000],
        [-1.2458, -1.6538,  1.6971,  0.0000,  0.0000,  0.0000],
        [ 0.3493,  0.5274,  0.1637,  0.0000,  0.0000,  0.0000],
        [-0.8141,  0.7590,  2.9278,  0.0000,  0.0000,  0.0000],
        [-0.1293, -1.8029, -3.0021,  0.0000,  0.0000,  0.0000],
        [ 0.1297, -0.2148, -0.0590,  0.0000,  0.0000,  0.0000],
        [-1.8617, -0.6158,  0.8343,  0.0000,  0.0000,  0.0000],
        [ 1.1518, -0.5747, -1.9411,  0.0000,  0.0000,  0.0000],
        [-0.6655, -0.9814, -0.8190,  0.0000,  0.0000,  0.0000],
        [ 0.8025, -2.4149, -2.2860,  0.0000,  0.0000,  0.0000],
        [-1.1125,  0.4065,  1.0571,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  47
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0341, grad_fn=<DivBackward0>)
Projection Loss:  tensor(536.9192, grad_fn=<AddBackward0>)
Total Loss:  tensor(536.9533, grad_fn=<AddBackward0>)
Gradients:
27.457887649536133
Gradient before update: tensor(-24.7603)
Gradient after update: tensor(-24.7603)
current Learning Rate:  0.0125
------------------------------------------------------------------------------------------------------------------
Iteration:  48
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0339, grad_fn=<DivBackward0>)
Projection Loss:  tensor(531.0090, grad_fn=<AddBackward0>)
Total Loss:  tensor(531.0429, grad_fn=<AddBackward0>)
Gradients:
170.0391082763672
Gradient before update: tensor(54.5215)
Gradient after update: tensor(54.5215)
current Learning Rate:  0.0125
Total Loss:  tensor(531.0429, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4541,  0.4001, -3.6560,  0.0000,  0.0000,  0.0000],
        [-0.1204,  0.5803,  1.8032,  0.0000,  0.0000,  0.0000],
        [-1.7476,  0.4525,  2.7754,  0.0000,  0.0000,  0.0000],
        [ 0.8140,  0.2638,  2.7973,  0.0000,  0.0000,  0.0000],
        [ 0.0193, -0.0087,  0.7264,  0.0000,  0.0000,  0.0000],
        [ 1.1977,  0.2790, -0.8440,  0.0000,  0.0000,  0.0000],
        [ 0.5062,  0.5389, -0.5652,  0.0000,  0.0000,  0.0000],
        [ 1.2381,  0.3892,  0.7761,  0.0000,  0.0000,  0.0000],
        [-0.5736, -2.0959, -1.3007,  0.0000,  0.0000,  0.0000],
        [ 0.8835, -0.2885,  1.0712,  0.0000,  0.0000,  0.0000],
        [-1.6110, -1.5278, -3.3926,  0.0000,  0.0000,  0.0000],
        [-1.0475, -0.5245,  0.9659,  0.0000,  0.0000,  0.0000],
        [ 0.3482, -0.3506, -2.1699,  0.0000,  0.0000,  0.0000],
        [ 1.1727,  1.0512,  3.3352,  0.0000,  0.0000,  0.0000],
        [-1.1716, -0.7930, -3.2650,  0.0000,  0.0000,  0.0000],
        [-1.3041,  1.1433, -3.4639,  0.0000,  0.0000,  0.0000],
        [ 1.4931,  0.9286,  2.1452,  0.0000,  0.0000,  0.0000],
        [ 0.0604, -0.7051,  2.9013,  0.0000,  0.0000,  0.0000],
        [-0.7993,  0.8327, -2.0023,  0.0000,  0.0000,  0.0000],
        [-0.3596, -1.2110,  0.3826,  0.0000,  0.0000,  0.0000],
        [ 1.4499,  0.8941, -0.3303,  0.0000,  0.0000,  0.0000],
        [-1.2228,  0.9348,  1.6456,  0.0000,  0.0000,  0.0000],
        [ 0.8888,  0.9162, -1.1284,  0.0000,  0.0000,  0.0000],
        [ 0.4274,  0.9991, -1.4579,  0.0000,  0.0000,  0.0000],
        [-1.2226, -0.0471, -1.6657,  0.0000,  0.0000,  0.0000],
        [ 0.6431, -0.6136, -3.6088,  0.0000,  0.0000,  0.0000],
        [-1.7930, -0.1969, -0.5817,  0.0000,  0.0000,  0.0000],
        [-0.4946,  0.0396, -1.3955,  0.0000,  0.0000,  0.0000],
        [ 0.9145, -0.9163,  0.2392,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4226,  1.4310,  0.0000,  0.0000,  0.0000],
        [-0.6553, -0.4694,  2.3451,  0.0000,  0.0000,  0.0000],
        [ 0.4761,  0.6210, -2.8216,  0.0000,  0.0000,  0.0000],
        [ 1.4662, -1.0433, -0.8501,  0.0000,  0.0000,  0.0000],
        [ 1.0848,  0.4717, -2.3299,  0.0000,  0.0000,  0.0000],
        [-1.8480, -1.3104, -0.4851,  0.0000,  0.0000,  0.0000],
        [-1.4144,  0.6296, -2.6456,  0.0000,  0.0000,  0.0000],
        [ 0.8154,  0.9647,  1.3199,  0.0000,  0.0000,  0.0000],
        [ 1.1745, -1.4531,  1.3867,  0.0000,  0.0000,  0.0000],
        [-0.4934, -0.3910, -2.4877,  0.0000,  0.0000,  0.0000],
        [-0.8333, -1.4422,  3.5467,  0.0000,  0.0000,  0.0000],
        [ 0.6075,  0.0374, -1.2274,  0.0000,  0.0000,  0.0000],
        [ 0.2262, -2.0973,  0.2508,  0.0000,  0.0000,  0.0000],
        [-0.3836,  0.7271, -0.0398,  0.0000,  0.0000,  0.0000],
        [ 0.5105, -1.2476,  1.1007,  0.0000,  0.0000,  0.0000],
        [ 0.8308, -1.8429, -1.6042,  0.0000,  0.0000,  0.0000],
        [-1.2467, -1.6531,  1.6980,  0.0000,  0.0000,  0.0000],
        [ 0.3495,  0.5272,  0.1634,  0.0000,  0.0000,  0.0000],
        [-0.8123,  0.7586,  2.9281,  0.0000,  0.0000,  0.0000],
        [-0.1168, -1.7982, -2.9956,  0.0000,  0.0000,  0.0000],
        [ 0.1303, -0.2139, -0.0596,  0.0000,  0.0000,  0.0000],
        [-1.8521, -0.6088,  0.8333,  0.0000,  0.0000,  0.0000],
        [ 1.1509, -0.5732, -1.9404,  0.0000,  0.0000,  0.0000],
        [-0.6667, -0.9823, -0.8191,  0.0000,  0.0000,  0.0000],
        [ 0.8104, -2.4232, -2.2783,  0.0000,  0.0000,  0.0000],
        [-1.1147,  0.4088,  1.0593,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  49
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0336, grad_fn=<DivBackward0>)
Projection Loss:  tensor(534.7864, grad_fn=<AddBackward0>)
Total Loss:  tensor(534.8200, grad_fn=<AddBackward0>)
Gradients:
158.01055908203125
Gradient before update: tensor(-254.5860)
Gradient after update: tensor(-254.5860)
current Learning Rate:  0.0125
------------------------------------------------------------------------------------------------------------------
Iteration:  50
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0337, grad_fn=<DivBackward0>)
Projection Loss:  tensor(537.8789, grad_fn=<AddBackward0>)
Total Loss:  tensor(537.9126, grad_fn=<AddBackward0>)
Gradients:
542.460693359375
Gradient before update: tensor(74.2409)
Gradient after update: tensor(74.2409)
current Learning Rate:  0.0125
Total Loss:  tensor(537.9126, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4542,  0.4000, -3.6564,  0.0000,  0.0000,  0.0000],
        [-0.1204,  0.5802,  1.8032,  0.0000,  0.0000,  0.0000],
        [-1.7457,  0.4509,  2.7734,  0.0000,  0.0000,  0.0000],
        [ 0.8138,  0.2640,  2.7976,  0.0000,  0.0000,  0.0000],
        [ 0.0191, -0.0087,  0.7266,  0.0000,  0.0000,  0.0000],
        [ 1.1898,  0.2869, -0.8520,  0.0000,  0.0000,  0.0000],
        [ 0.5056,  0.5382, -0.5662,  0.0000,  0.0000,  0.0000],
        [ 1.2398,  0.3896,  0.7763,  0.0000,  0.0000,  0.0000],
        [-0.5677, -2.1029, -1.3073,  0.0000,  0.0000,  0.0000],
        [ 0.8833, -0.2886,  1.0710,  0.0000,  0.0000,  0.0000],
        [-1.6051, -1.5265, -3.3989,  0.0000,  0.0000,  0.0000],
        [-1.0489, -0.5244,  0.9657,  0.0000,  0.0000,  0.0000],
        [ 0.3483, -0.3507, -2.1699,  0.0000,  0.0000,  0.0000],
        [ 1.1923,  1.0486,  3.3252,  0.0000,  0.0000,  0.0000],
        [-1.1672, -0.7977, -3.2603,  0.0000,  0.0000,  0.0000],
        [-1.3021,  1.1335, -3.4626,  0.0000,  0.0000,  0.0000],
        [ 1.4926,  0.9289,  2.1454,  0.0000,  0.0000,  0.0000],
        [ 0.0667, -0.7115,  2.9077,  0.0000,  0.0000,  0.0000],
        [-0.7990,  0.8339, -2.0015,  0.0000,  0.0000,  0.0000],
        [-0.3593, -1.2117,  0.3827,  0.0000,  0.0000,  0.0000],
        [ 1.4481,  0.8916, -0.3329,  0.0000,  0.0000,  0.0000],
        [-1.2230,  0.9347,  1.6457,  0.0000,  0.0000,  0.0000],
        [ 0.8902,  0.9162, -1.1271,  0.0000,  0.0000,  0.0000],
        [ 0.4283,  1.0001, -1.4591,  0.0000,  0.0000,  0.0000],
        [-1.2335, -0.0580, -1.6548,  0.0000,  0.0000,  0.0000],
        [ 0.6425, -0.6131, -3.6092,  0.0000,  0.0000,  0.0000],
        [-1.7891, -0.1932, -0.5855,  0.0000,  0.0000,  0.0000],
        [-0.5026,  0.0476, -1.4031,  0.0000,  0.0000,  0.0000],
        [ 0.9145, -0.9163,  0.2391,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4226,  1.4308,  0.0000,  0.0000,  0.0000],
        [-0.6554, -0.4694,  2.3453,  0.0000,  0.0000,  0.0000],
        [ 0.4762,  0.6208, -2.8217,  0.0000,  0.0000,  0.0000],
        [ 1.4751, -1.0460, -0.8405,  0.0000,  0.0000,  0.0000],
        [ 1.0846,  0.4718, -2.3297,  0.0000,  0.0000,  0.0000],
        [-1.8499, -1.3113, -0.4882,  0.0000,  0.0000,  0.0000],
        [-1.4125,  0.6275, -2.6442,  0.0000,  0.0000,  0.0000],
        [ 0.8062,  0.9756,  1.3319,  0.0000,  0.0000,  0.0000],
        [ 1.1752, -1.4554,  1.3852,  0.0000,  0.0000,  0.0000],
        [-0.4917, -0.3927, -2.4887,  0.0000,  0.0000,  0.0000],
        [-0.8324, -1.4430,  3.5475,  0.0000,  0.0000,  0.0000],
        [ 0.6032,  0.0367, -1.2283,  0.0000,  0.0000,  0.0000],
        [ 0.2197, -2.1038,  0.2577,  0.0000,  0.0000,  0.0000],
        [-0.3835,  0.7270, -0.0411,  0.0000,  0.0000,  0.0000],
        [ 0.5142, -1.2514,  1.1042,  0.0000,  0.0000,  0.0000],
        [ 0.8307, -1.8432, -1.6041,  0.0000,  0.0000,  0.0000],
        [-1.2474, -1.6526,  1.6987,  0.0000,  0.0000,  0.0000],
        [ 0.3496,  0.5270,  0.1631,  0.0000,  0.0000,  0.0000],
        [-0.8109,  0.7582,  2.9284,  0.0000,  0.0000,  0.0000],
        [-0.0997, -1.7887, -2.9916,  0.0000,  0.0000,  0.0000],
        [ 0.1308, -0.2131, -0.0602,  0.0000,  0.0000,  0.0000],
        [-1.8444, -0.6030,  0.8325,  0.0000,  0.0000,  0.0000],
        [ 1.1502, -0.5720, -1.9398,  0.0000,  0.0000,  0.0000],
        [-0.6677, -0.9831, -0.8191,  0.0000,  0.0000,  0.0000],
        [ 0.8170, -2.4295, -2.2721,  0.0000,  0.0000,  0.0000],
        [-1.1165,  0.4106,  1.0612,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  51
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0338, grad_fn=<DivBackward0>)
Projection Loss:  tensor(530.9883, grad_fn=<AddBackward0>)
Total Loss:  tensor(531.0220, grad_fn=<AddBackward0>)
Gradients:
1163.69970703125
Gradient before update: tensor(1285.4708)
Gradient after update: tensor(1285.4708)
current Learning Rate:  0.0125
------------------------------------------------------------------------------------------------------------------
Iteration:  52
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0337, grad_fn=<DivBackward0>)
Projection Loss:  tensor(531.8173, grad_fn=<AddBackward0>)
Total Loss:  tensor(531.8510, grad_fn=<AddBackward0>)
Gradients:
39.09825897216797
Gradient before update: tensor(-33.7038)
Gradient after update: tensor(-33.7038)
current Learning Rate:  0.0125
Total Loss:  tensor(531.8510, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4543,  0.3999, -3.6568,  0.0000,  0.0000,  0.0000],
        [-0.1204,  0.5801,  1.8031,  0.0000,  0.0000,  0.0000],
        [-1.7441,  0.4496,  2.7717,  0.0000,  0.0000,  0.0000],
        [ 0.8137,  0.2642,  2.7978,  0.0000,  0.0000,  0.0000],
        [ 0.0189, -0.0087,  0.7267,  0.0000,  0.0000,  0.0000],
        [ 1.1832,  0.2933, -0.8585,  0.0000,  0.0000,  0.0000],
        [ 0.5038,  0.5381, -0.5667,  0.0000,  0.0000,  0.0000],
        [ 1.2413,  0.3899,  0.7764,  0.0000,  0.0000,  0.0000],
        [-0.5603, -2.1119, -1.3222,  0.0000,  0.0000,  0.0000],
        [ 0.8832, -0.2888,  1.0709,  0.0000,  0.0000,  0.0000],
        [-1.6003, -1.5255, -3.4041,  0.0000,  0.0000,  0.0000],
        [-1.0503, -0.5243,  0.9656,  0.0000,  0.0000,  0.0000],
        [ 0.3484, -0.3508, -2.1699,  0.0000,  0.0000,  0.0000],
        [ 1.2085,  1.0465,  3.3169,  0.0000,  0.0000,  0.0000],
        [-1.1636, -0.8016, -3.2564,  0.0000,  0.0000,  0.0000],
        [-1.3004,  1.1252, -3.4614,  0.0000,  0.0000,  0.0000],
        [ 1.4923,  0.9291,  2.1456,  0.0000,  0.0000,  0.0000],
        [ 0.0719, -0.7169,  2.9129,  0.0000,  0.0000,  0.0000],
        [-0.7988,  0.8349, -2.0008,  0.0000,  0.0000,  0.0000],
        [-0.3590, -1.2122,  0.3829,  0.0000,  0.0000,  0.0000],
        [ 1.4467,  0.8896, -0.3350,  0.0000,  0.0000,  0.0000],
        [-1.2231,  0.9347,  1.6457,  0.0000,  0.0000,  0.0000],
        [ 0.8917,  0.9162, -1.1258,  0.0000,  0.0000,  0.0000],
        [ 0.4292,  1.0009, -1.4602,  0.0000,  0.0000,  0.0000],
        [-1.2426, -0.0670, -1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.6420, -0.6126, -3.6096,  0.0000,  0.0000,  0.0000],
        [-1.7859, -0.1900, -0.5886,  0.0000,  0.0000,  0.0000],
        [-0.5092,  0.0542, -1.4094,  0.0000,  0.0000,  0.0000],
        [ 0.9144, -0.9163,  0.2391,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4225,  1.4307,  0.0000,  0.0000,  0.0000],
        [-0.6555, -0.4694,  2.3454,  0.0000,  0.0000,  0.0000],
        [ 0.4763,  0.6206, -2.8218,  0.0000,  0.0000,  0.0000],
        [ 1.4828, -1.0497, -0.8325,  0.0000,  0.0000,  0.0000],
        [ 1.0845,  0.4720, -2.3295,  0.0000,  0.0000,  0.0000],
        [-1.8514, -1.3120, -0.4907,  0.0000,  0.0000,  0.0000],
        [-1.4108,  0.6258, -2.6430,  0.0000,  0.0000,  0.0000],
        [ 0.7985,  0.9846,  1.3418,  0.0000,  0.0000,  0.0000],
        [ 1.1758, -1.4573,  1.3840,  0.0000,  0.0000,  0.0000],
        [-0.4896, -0.3952, -2.4894,  0.0000,  0.0000,  0.0000],
        [-0.8317, -1.4437,  3.5482,  0.0000,  0.0000,  0.0000],
        [ 0.5969,  0.0357, -1.2298,  0.0000,  0.0000,  0.0000],
        [ 0.2115, -2.1192,  0.2494,  0.0000,  0.0000,  0.0000],
        [-0.3834,  0.7269, -0.0421,  0.0000,  0.0000,  0.0000],
        [ 0.5173, -1.2544,  1.1071,  0.0000,  0.0000,  0.0000],
        [ 0.8307, -1.8434, -1.6040,  0.0000,  0.0000,  0.0000],
        [-1.2480, -1.6521,  1.6993,  0.0000,  0.0000,  0.0000],
        [ 0.3498,  0.5268,  0.1629,  0.0000,  0.0000,  0.0000],
        [-0.8096,  0.7578,  2.9287,  0.0000,  0.0000,  0.0000],
        [-0.0855, -1.7808, -2.9883,  0.0000,  0.0000,  0.0000],
        [ 0.1312, -0.2125, -0.0606,  0.0000,  0.0000,  0.0000],
        [-1.8382, -0.5983,  0.8319,  0.0000,  0.0000,  0.0000],
        [ 1.1495, -0.5709, -1.9393,  0.0000,  0.0000,  0.0000],
        [-0.6685, -0.9837, -0.8192,  0.0000,  0.0000,  0.0000],
        [ 0.8225, -2.4346, -2.2670,  0.0000,  0.0000,  0.0000],
        [-1.1180,  0.4121,  1.0627,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  53
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0335, grad_fn=<DivBackward0>)
Projection Loss:  tensor(532.8607, grad_fn=<AddBackward0>)
Total Loss:  tensor(532.8942, grad_fn=<AddBackward0>)
Gradients:
1736.7747802734375
Gradient before update: tensor(1611.5955)
Gradient after update: tensor(1611.5955)
current Learning Rate:  0.0125
------------------------------------------------------------------------------------------------------------------
Iteration:  54
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0333, grad_fn=<DivBackward0>)
Projection Loss:  tensor(527.5887, grad_fn=<AddBackward0>)
Total Loss:  tensor(527.6219, grad_fn=<AddBackward0>)
Gradients:
244.8231658935547
Gradient before update: tensor(-87.9563)
Gradient after update: tensor(-87.9563)
current Learning Rate:  0.0125
Total Loss:  tensor(527.6219, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4544,  0.3998, -3.6570,  0.0000,  0.0000,  0.0000],
        [-0.1203,  0.5800,  1.8030,  0.0000,  0.0000,  0.0000],
        [-1.7428,  0.4485,  2.7703,  0.0000,  0.0000,  0.0000],
        [ 0.8135,  0.2643,  2.7979,  0.0000,  0.0000,  0.0000],
        [ 0.0187, -0.0087,  0.7268,  0.0000,  0.0000,  0.0000],
        [ 1.1778,  0.2986, -0.8639,  0.0000,  0.0000,  0.0000],
        [ 0.5006,  0.5388, -0.5668,  0.0000,  0.0000,  0.0000],
        [ 1.2425,  0.3902,  0.7765,  0.0000,  0.0000,  0.0000],
        [-0.5546, -2.1206, -1.3349,  0.0000,  0.0000,  0.0000],
        [ 0.8830, -0.2889,  1.0707,  0.0000,  0.0000,  0.0000],
        [-1.5963, -1.5249, -3.4084,  0.0000,  0.0000,  0.0000],
        [-1.0515, -0.5243,  0.9655,  0.0000,  0.0000,  0.0000],
        [ 0.3485, -0.3509, -2.1699,  0.0000,  0.0000,  0.0000],
        [ 1.2219,  1.0448,  3.3101,  0.0000,  0.0000,  0.0000],
        [-1.1606, -0.8049, -3.2532,  0.0000,  0.0000,  0.0000],
        [-1.3022,  1.1067, -3.4522,  0.0000,  0.0000,  0.0000],
        [ 1.4919,  0.9292,  2.1458,  0.0000,  0.0000,  0.0000],
        [ 0.0762, -0.7213,  2.9173,  0.0000,  0.0000,  0.0000],
        [-0.7985,  0.8358, -2.0002,  0.0000,  0.0000,  0.0000],
        [-0.3588, -1.2127,  0.3830,  0.0000,  0.0000,  0.0000],
        [ 1.4455,  0.8878, -0.3368,  0.0000,  0.0000,  0.0000],
        [-1.2232,  0.9347,  1.6457,  0.0000,  0.0000,  0.0000],
        [ 0.8931,  0.9163, -1.1245,  0.0000,  0.0000,  0.0000],
        [ 0.4298,  1.0015, -1.4610,  0.0000,  0.0000,  0.0000],
        [-1.2500, -0.0744, -1.6383,  0.0000,  0.0000,  0.0000],
        [ 0.6416, -0.6122, -3.6099,  0.0000,  0.0000,  0.0000],
        [-1.7833, -0.1875, -0.5912,  0.0000,  0.0000,  0.0000],
        [-0.5147,  0.0596, -1.4145,  0.0000,  0.0000,  0.0000],
        [ 0.9143, -0.9163,  0.2390,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4225,  1.4307,  0.0000,  0.0000,  0.0000],
        [-0.6556, -0.4693,  2.3455,  0.0000,  0.0000,  0.0000],
        [ 0.4763,  0.6205, -2.8218,  0.0000,  0.0000,  0.0000],
        [ 1.4889, -1.0521, -0.8259,  0.0000,  0.0000,  0.0000],
        [ 1.0844,  0.4721, -2.3294,  0.0000,  0.0000,  0.0000],
        [-1.8521, -1.3124, -0.4924,  0.0000,  0.0000,  0.0000],
        [-1.4095,  0.6243, -2.6421,  0.0000,  0.0000,  0.0000],
        [ 0.7922,  0.9921,  1.3500,  0.0000,  0.0000,  0.0000],
        [ 1.1763, -1.4588,  1.3830,  0.0000,  0.0000,  0.0000],
        [-0.4877, -0.3976, -2.4900,  0.0000,  0.0000,  0.0000],
        [-0.8311, -1.4443,  3.5487,  0.0000,  0.0000,  0.0000],
        [ 0.5876,  0.0340, -1.2321,  0.0000,  0.0000,  0.0000],
        [ 0.2079, -2.1364,  0.2430,  0.0000,  0.0000,  0.0000],
        [-0.3834,  0.7269, -0.0430,  0.0000,  0.0000,  0.0000],
        [ 0.5198, -1.2570,  1.1095,  0.0000,  0.0000,  0.0000],
        [ 0.8306, -1.8436, -1.6039,  0.0000,  0.0000,  0.0000],
        [-1.2485, -1.6517,  1.6998,  0.0000,  0.0000,  0.0000],
        [ 0.3499,  0.5267,  0.1628,  0.0000,  0.0000,  0.0000],
        [-0.8086,  0.7576,  2.9289,  0.0000,  0.0000,  0.0000],
        [-0.0737, -1.7742, -2.9856,  0.0000,  0.0000,  0.0000],
        [ 0.1315, -0.2120, -0.0610,  0.0000,  0.0000,  0.0000],
        [-1.8330, -0.5945,  0.8314,  0.0000,  0.0000,  0.0000],
        [ 1.1490, -0.5701, -1.9389,  0.0000,  0.0000,  0.0000],
        [-0.6692, -0.9843, -0.8192,  0.0000,  0.0000,  0.0000],
        [ 0.8273, -2.4374, -2.2630,  0.0000,  0.0000,  0.0000],
        [-1.1193,  0.4134,  1.0639,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  55
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0330, grad_fn=<DivBackward0>)
Projection Loss:  tensor(527.8286, grad_fn=<AddBackward0>)
Total Loss:  tensor(527.8615, grad_fn=<AddBackward0>)
Gradients:
1535.16064453125
Gradient before update: tensor(-1557.3053)
Gradient after update: tensor(-1557.3053)
current Learning Rate:  0.0125
------------------------------------------------------------------------------------------------------------------
Iteration:  56
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0328, grad_fn=<DivBackward0>)
Projection Loss:  tensor(524.6526, grad_fn=<AddBackward0>)
Total Loss:  tensor(524.6854, grad_fn=<AddBackward0>)
Gradients:
183.37672424316406
Gradient before update: tensor(-284.1911)
Gradient after update: tensor(-284.1911)
current Learning Rate:  0.0125
Total Loss:  tensor(524.6854, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4545,  0.3997, -3.6573,  0.0000,  0.0000,  0.0000],
        [-0.1203,  0.5799,  1.8030,  0.0000,  0.0000,  0.0000],
        [-1.7419,  0.4477,  2.7691,  0.0000,  0.0000,  0.0000],
        [ 0.8134,  0.2644,  2.7981,  0.0000,  0.0000,  0.0000],
        [ 0.0186, -0.0087,  0.7269,  0.0000,  0.0000,  0.0000],
        [ 1.1733,  0.3029, -0.8684,  0.0000,  0.0000,  0.0000],
        [ 0.4968,  0.5399, -0.5665,  0.0000,  0.0000,  0.0000],
        [ 1.2434,  0.3904,  0.7766,  0.0000,  0.0000,  0.0000],
        [-0.5503, -2.1292, -1.3457,  0.0000,  0.0000,  0.0000],
        [ 0.8829, -0.2890,  1.0706,  0.0000,  0.0000,  0.0000],
        [-1.5931, -1.5251, -3.4122,  0.0000,  0.0000,  0.0000],
        [-1.0525, -0.5242,  0.9654,  0.0000,  0.0000,  0.0000],
        [ 0.3485, -0.3509, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2335,  1.0436,  3.3048,  0.0000,  0.0000,  0.0000],
        [-1.1581, -0.8075, -3.2505,  0.0000,  0.0000,  0.0000],
        [-1.3038,  1.0906, -3.4444,  0.0000,  0.0000,  0.0000],
        [ 1.4917,  0.9294,  2.1459,  0.0000,  0.0000,  0.0000],
        [ 0.0797, -0.7249,  2.9208,  0.0000,  0.0000,  0.0000],
        [-0.7983,  0.8366, -1.9997,  0.0000,  0.0000,  0.0000],
        [-0.3585, -1.2131,  0.3831,  0.0000,  0.0000,  0.0000],
        [ 1.4445,  0.8864, -0.3383,  0.0000,  0.0000,  0.0000],
        [-1.2233,  0.9346,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.8945,  0.9163, -1.1233,  0.0000,  0.0000,  0.0000],
        [ 0.4304,  1.0021, -1.4618,  0.0000,  0.0000,  0.0000],
        [-1.2562, -0.0805, -1.6322,  0.0000,  0.0000,  0.0000],
        [ 0.6413, -0.6119, -3.6101,  0.0000,  0.0000,  0.0000],
        [-1.7811, -0.1853, -0.5934,  0.0000,  0.0000,  0.0000],
        [-0.5192,  0.0641, -1.4188,  0.0000,  0.0000,  0.0000],
        [ 0.9143, -0.9163,  0.2390,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4225,  1.4306,  0.0000,  0.0000,  0.0000],
        [-0.6557, -0.4693,  2.3456,  0.0000,  0.0000,  0.0000],
        [ 0.4764,  0.6204, -2.8219,  0.0000,  0.0000,  0.0000],
        [ 1.4719, -1.0697, -0.8076,  0.0000,  0.0000,  0.0000],
        [ 1.0843,  0.4722, -2.3292,  0.0000,  0.0000,  0.0000],
        [-1.8525, -1.3128, -0.4935,  0.0000,  0.0000,  0.0000],
        [-1.4084,  0.6232, -2.6413,  0.0000,  0.0000,  0.0000],
        [ 0.7870,  0.9982,  1.3567,  0.0000,  0.0000,  0.0000],
        [ 1.1767, -1.4601,  1.3822,  0.0000,  0.0000,  0.0000],
        [-0.4861, -0.3997, -2.4905,  0.0000,  0.0000,  0.0000],
        [-0.8306, -1.4448,  3.5491,  0.0000,  0.0000,  0.0000],
        [ 0.5776,  0.0321, -1.2345,  0.0000,  0.0000,  0.0000],
        [ 0.2049, -2.1505,  0.2377,  0.0000,  0.0000,  0.0000],
        [-0.3833,  0.7268, -0.0437,  0.0000,  0.0000,  0.0000],
        [ 0.5218, -1.2591,  1.1115,  0.0000,  0.0000,  0.0000],
        [ 0.8306, -1.8438, -1.6038,  0.0000,  0.0000,  0.0000],
        [-1.2489, -1.6514,  1.7002,  0.0000,  0.0000,  0.0000],
        [ 0.3500,  0.5266,  0.1626,  0.0000,  0.0000,  0.0000],
        [-0.8078,  0.7573,  2.9290,  0.0000,  0.0000,  0.0000],
        [-0.0639, -1.7687, -2.9835,  0.0000,  0.0000,  0.0000],
        [ 0.1318, -0.2116, -0.0613,  0.0000,  0.0000,  0.0000],
        [-1.8288, -0.5914,  0.8309,  0.0000,  0.0000,  0.0000],
        [ 1.1486, -0.5694, -1.9385,  0.0000,  0.0000,  0.0000],
        [-0.6697, -0.9847, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8333, -2.4361, -2.2608,  0.0000,  0.0000,  0.0000],
        [-1.1203,  0.4144,  1.0650,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  57
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0327, grad_fn=<DivBackward0>)
Projection Loss:  tensor(519.8914, grad_fn=<AddBackward0>)
Total Loss:  tensor(519.9240, grad_fn=<AddBackward0>)
Gradients:
218.1068878173828
Gradient before update: tensor(-16.1609)
Gradient after update: tensor(-16.1609)
current Learning Rate:  0.0125
------------------------------------------------------------------------------------------------------------------
Iteration:  58
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0325, grad_fn=<DivBackward0>)
Projection Loss:  tensor(520.8925, grad_fn=<AddBackward0>)
Total Loss:  tensor(520.9250, grad_fn=<AddBackward0>)
Gradients:
249.92288208007812
Gradient before update: tensor(208.5407)
Gradient after update: tensor(208.5407)
current Learning Rate:  0.0125
Total Loss:  tensor(520.9250, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4546,  0.3997, -3.6574,  0.0000,  0.0000,  0.0000],
        [-0.1203,  0.5799,  1.8030,  0.0000,  0.0000,  0.0000],
        [-1.7413,  0.4473,  2.7677,  0.0000,  0.0000,  0.0000],
        [ 0.8133,  0.2645,  2.7982,  0.0000,  0.0000,  0.0000],
        [ 0.0185, -0.0087,  0.7270,  0.0000,  0.0000,  0.0000],
        [ 1.1697,  0.3065, -0.8720,  0.0000,  0.0000,  0.0000],
        [ 0.4936,  0.5408, -0.5662,  0.0000,  0.0000,  0.0000],
        [ 1.2443,  0.3906,  0.7767,  0.0000,  0.0000,  0.0000],
        [-0.5467, -2.1363, -1.3546,  0.0000,  0.0000,  0.0000],
        [ 0.8828, -0.2891,  1.0705,  0.0000,  0.0000,  0.0000],
        [-1.5842, -1.5137, -3.4178,  0.0000,  0.0000,  0.0000],
        [-1.0534, -0.5241,  0.9653,  0.0000,  0.0000,  0.0000],
        [ 0.3486, -0.3510, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2440,  1.0428,  3.3006,  0.0000,  0.0000,  0.0000],
        [-1.1652, -0.8110, -3.2483,  0.0000,  0.0000,  0.0000],
        [-1.3052,  1.0774, -3.4380,  0.0000,  0.0000,  0.0000],
        [ 1.4915,  0.9295,  2.1460,  0.0000,  0.0000,  0.0000],
        [ 0.0826, -0.7279,  2.9238,  0.0000,  0.0000,  0.0000],
        [-0.7982,  0.8373, -1.9993,  0.0000,  0.0000,  0.0000],
        [-0.3583, -1.2134,  0.3832,  0.0000,  0.0000,  0.0000],
        [ 1.4436,  0.8853, -0.3394,  0.0000,  0.0000,  0.0000],
        [-1.2234,  0.9346,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.8959,  0.9163, -1.1221,  0.0000,  0.0000,  0.0000],
        [ 0.4308,  1.0025, -1.4625,  0.0000,  0.0000,  0.0000],
        [-1.2612, -0.0856, -1.6271,  0.0000,  0.0000,  0.0000],
        [ 0.6410, -0.6116, -3.6103,  0.0000,  0.0000,  0.0000],
        [-1.7796, -0.1835, -0.5950,  0.0000,  0.0000,  0.0000],
        [-0.5229,  0.0678, -1.4223,  0.0000,  0.0000,  0.0000],
        [ 0.9142, -0.9163,  0.2390,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4225,  1.4305,  0.0000,  0.0000,  0.0000],
        [-0.6557, -0.4693,  2.3457,  0.0000,  0.0000,  0.0000],
        [ 0.4764,  0.6203, -2.8219,  0.0000,  0.0000,  0.0000],
        [ 1.4578, -1.0848, -0.7943,  0.0000,  0.0000,  0.0000],
        [ 1.0843,  0.4722, -2.3291,  0.0000,  0.0000,  0.0000],
        [-1.8527, -1.3130, -0.4944,  0.0000,  0.0000,  0.0000],
        [-1.4074,  0.6222, -2.6406,  0.0000,  0.0000,  0.0000],
        [ 0.7827,  1.0033,  1.3623,  0.0000,  0.0000,  0.0000],
        [ 1.1771, -1.4611,  1.3815,  0.0000,  0.0000,  0.0000],
        [-0.4847, -0.4014, -2.4909,  0.0000,  0.0000,  0.0000],
        [-0.8302, -1.4452,  3.5493,  0.0000,  0.0000,  0.0000],
        [ 0.5674,  0.0303, -1.2367,  0.0000,  0.0000,  0.0000],
        [ 0.2019, -2.1626,  0.2344,  0.0000,  0.0000,  0.0000],
        [-0.3833,  0.7268, -0.0443,  0.0000,  0.0000,  0.0000],
        [ 0.5235, -1.2608,  1.1131,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8439, -1.6038,  0.0000,  0.0000,  0.0000],
        [-1.2493, -1.6512,  1.7006,  0.0000,  0.0000,  0.0000],
        [ 0.3500,  0.5265,  0.1625,  0.0000,  0.0000,  0.0000],
        [-0.8071,  0.7572,  2.9291,  0.0000,  0.0000,  0.0000],
        [-0.0552, -1.7641, -2.9820,  0.0000,  0.0000,  0.0000],
        [ 0.1320, -0.2112, -0.0615,  0.0000,  0.0000,  0.0000],
        [-1.8253, -0.5888,  0.8306,  0.0000,  0.0000,  0.0000],
        [ 1.1483, -0.5688, -1.9382,  0.0000,  0.0000,  0.0000],
        [-0.6702, -0.9851, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8383, -2.4346, -2.2591,  0.0000,  0.0000,  0.0000],
        [-1.1211,  0.4152,  1.0658,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  59
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0325, grad_fn=<DivBackward0>)
Projection Loss:  tensor(524.5526, grad_fn=<AddBackward0>)
Total Loss:  tensor(524.5851, grad_fn=<AddBackward0>)
Gradients:
9816.3837890625
Gradient before update: tensor(7494.3735)
Gradient after update: tensor(7494.3735)
current Learning Rate:  0.0125
------------------------------------------------------------------------------------------------------------------
Iteration:  60
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0316, grad_fn=<DivBackward0>)
Projection Loss:  tensor(521.4258, grad_fn=<AddBackward0>)
Total Loss:  tensor(521.4574, grad_fn=<AddBackward0>)
Gradients:
939.5027465820312
Gradient before update: tensor(-986.2346)
Gradient after update: tensor(-986.2346)
current Learning Rate:  0.00625
Total Loss:  tensor(521.4574, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4546,  0.3996, -3.6576,  0.0000,  0.0000,  0.0000],
        [-0.1203,  0.5798,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7412,  0.4476,  2.7658,  0.0000,  0.0000,  0.0000],
        [ 0.8132,  0.2646,  2.7982,  0.0000,  0.0000,  0.0000],
        [ 0.0184, -0.0087,  0.7271,  0.0000,  0.0000,  0.0000],
        [ 1.1690,  0.2891, -0.8606,  0.0000,  0.0000,  0.0000],
        [ 0.4910,  0.5415, -0.5660,  0.0000,  0.0000,  0.0000],
        [ 1.2449,  0.3907,  0.7767,  0.0000,  0.0000,  0.0000],
        [-0.5438, -2.1422, -1.3619,  0.0000,  0.0000,  0.0000],
        [ 0.8828, -0.2892,  1.0704,  0.0000,  0.0000,  0.0000],
        [-1.5771, -1.5046, -3.4224,  0.0000,  0.0000,  0.0000],
        [-1.0541, -0.5241,  0.9652,  0.0000,  0.0000,  0.0000],
        [ 0.3486, -0.3510, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2526,  1.0420,  3.2971,  0.0000,  0.0000,  0.0000],
        [-1.1710, -0.8138, -3.2465,  0.0000,  0.0000,  0.0000],
        [-1.3064,  1.0666, -3.4325,  0.0000,  0.0000,  0.0000],
        [ 1.4913,  0.9296,  2.1461,  0.0000,  0.0000,  0.0000],
        [ 0.0851, -0.7304,  2.9262,  0.0000,  0.0000,  0.0000],
        [-0.7980,  0.8378, -1.9990,  0.0000,  0.0000,  0.0000],
        [-0.3581, -1.2137,  0.3833,  0.0000,  0.0000,  0.0000],
        [ 1.4430,  0.8843, -0.3404,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9346,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.8972,  0.9163, -1.1209,  0.0000,  0.0000,  0.0000],
        [ 0.4312,  1.0029, -1.4631,  0.0000,  0.0000,  0.0000],
        [-1.2654, -0.0898, -1.6229,  0.0000,  0.0000,  0.0000],
        [ 0.6408, -0.6114, -3.6105,  0.0000,  0.0000,  0.0000],
        [-1.7934, -0.1741, -0.5897,  0.0000,  0.0000,  0.0000],
        [-0.5260,  0.0709, -1.4252,  0.0000,  0.0000,  0.0000],
        [ 0.9142, -0.9163,  0.2390,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4305,  0.0000,  0.0000,  0.0000],
        [-0.6557, -0.4693,  2.3457,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6202, -2.8219,  0.0000,  0.0000,  0.0000],
        [ 1.4463, -1.0972, -0.7833,  0.0000,  0.0000,  0.0000],
        [ 1.0842,  0.4723, -2.3291,  0.0000,  0.0000,  0.0000],
        [-1.8528, -1.3132, -0.4951,  0.0000,  0.0000,  0.0000],
        [-1.4067,  0.6214, -2.6401,  0.0000,  0.0000,  0.0000],
        [ 0.7792,  1.0075,  1.3669,  0.0000,  0.0000,  0.0000],
        [ 1.1773, -1.4620,  1.3809,  0.0000,  0.0000,  0.0000],
        [-0.4836, -0.4029, -2.4913,  0.0000,  0.0000,  0.0000],
        [-0.8299, -1.4455,  3.5495,  0.0000,  0.0000,  0.0000],
        [ 0.5581,  0.0285, -1.2388,  0.0000,  0.0000,  0.0000],
        [ 0.1991, -2.1728,  0.2327,  0.0000,  0.0000,  0.0000],
        [-0.3833,  0.7268, -0.0450,  0.0000,  0.0000,  0.0000],
        [ 0.5249, -1.2622,  1.1144,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8441, -1.6037,  0.0000,  0.0000,  0.0000],
        [-1.2496, -1.6510,  1.7009,  0.0000,  0.0000,  0.0000],
        [ 0.3501,  0.5265,  0.1624,  0.0000,  0.0000,  0.0000],
        [-0.8065,  0.7570,  2.9293,  0.0000,  0.0000,  0.0000],
        [-0.0480, -1.7604, -2.9809,  0.0000,  0.0000,  0.0000],
        [ 0.1322, -0.2109, -0.0617,  0.0000,  0.0000,  0.0000],
        [-1.8224, -0.5866,  0.8303,  0.0000,  0.0000,  0.0000],
        [ 1.1480, -0.5683, -1.9380,  0.0000,  0.0000,  0.0000],
        [-0.6705, -0.9854, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8426, -2.4312, -2.2579,  0.0000,  0.0000,  0.0000],
        [-1.1218,  0.4159,  1.0665,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  61
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0309, grad_fn=<DivBackward0>)
Projection Loss:  tensor(522.7421, grad_fn=<AddBackward0>)
Total Loss:  tensor(522.7730, grad_fn=<AddBackward0>)
Gradients:
11530.853515625
Gradient before update: tensor(16478.1133)
Gradient after update: tensor(16478.1133)
current Learning Rate:  0.00625
------------------------------------------------------------------------------------------------------------------
Iteration:  62
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0305, grad_fn=<DivBackward0>)
Projection Loss:  tensor(522.0020, grad_fn=<AddBackward0>)
Total Loss:  tensor(522.0325, grad_fn=<AddBackward0>)
Gradients:
677.9846801757812
Gradient before update: tensor(84.2012)
Gradient after update: tensor(84.2012)
current Learning Rate:  0.00625
Total Loss:  tensor(522.0325, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4546,  0.3996, -3.6577,  0.0000,  0.0000,  0.0000],
        [-0.1203,  0.5798,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7414,  0.4479,  2.7647,  0.0000,  0.0000,  0.0000],
        [ 0.8132,  0.2646,  2.7983,  0.0000,  0.0000,  0.0000],
        [ 0.0184, -0.0087,  0.7271,  0.0000,  0.0000,  0.0000],
        [ 1.1687,  0.2819, -0.8559,  0.0000,  0.0000,  0.0000],
        [ 0.4899,  0.5418, -0.5659,  0.0000,  0.0000,  0.0000],
        [ 1.2452,  0.3908,  0.7768,  0.0000,  0.0000,  0.0000],
        [-0.5528, -2.1516, -1.3529,  0.0000,  0.0000,  0.0000],
        [ 0.8828, -0.2892,  1.0704,  0.0000,  0.0000,  0.0000],
        [-1.5741, -1.5008, -3.4243,  0.0000,  0.0000,  0.0000],
        [-1.0544, -0.5241,  0.9652,  0.0000,  0.0000,  0.0000],
        [ 0.3486, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2562,  1.0417,  3.2956,  0.0000,  0.0000,  0.0000],
        [-1.1734, -0.8150, -3.2458,  0.0000,  0.0000,  0.0000],
        [-1.3069,  1.0621, -3.4303,  0.0000,  0.0000,  0.0000],
        [ 1.4912,  0.9296,  2.1461,  0.0000,  0.0000,  0.0000],
        [ 0.0860, -0.7314,  2.9272,  0.0000,  0.0000,  0.0000],
        [-0.7979,  0.8381, -1.9989,  0.0000,  0.0000,  0.0000],
        [-0.3580, -1.2138,  0.3833,  0.0000,  0.0000,  0.0000],
        [ 1.4427,  0.8839, -0.3408,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9346,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.8979,  0.9163, -1.1203,  0.0000,  0.0000,  0.0000],
        [ 0.4314,  1.0030, -1.4634,  0.0000,  0.0000,  0.0000],
        [-1.2671, -0.0915, -1.6212,  0.0000,  0.0000,  0.0000],
        [ 0.6407, -0.6113, -3.6106,  0.0000,  0.0000,  0.0000],
        [-1.7991, -0.1702, -0.5875,  0.0000,  0.0000,  0.0000],
        [-0.5272,  0.0721, -1.4264,  0.0000,  0.0000,  0.0000],
        [ 0.9142, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4305,  0.0000,  0.0000,  0.0000],
        [-0.6558, -0.4693,  2.3458,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6202, -2.8219,  0.0000,  0.0000,  0.0000],
        [ 1.4415, -1.1023, -0.7788,  0.0000,  0.0000,  0.0000],
        [ 1.0842,  0.4723, -2.3290,  0.0000,  0.0000,  0.0000],
        [-1.8527, -1.3132, -0.4953,  0.0000,  0.0000,  0.0000],
        [-1.4064,  0.6211, -2.6399,  0.0000,  0.0000,  0.0000],
        [ 0.7777,  1.0092,  1.3687,  0.0000,  0.0000,  0.0000],
        [ 1.1775, -1.4623,  1.3807,  0.0000,  0.0000,  0.0000],
        [-0.4831, -0.4036, -2.4914,  0.0000,  0.0000,  0.0000],
        [-0.8297, -1.4457,  3.5495,  0.0000,  0.0000,  0.0000],
        [ 0.5526,  0.0276, -1.2400,  0.0000,  0.0000,  0.0000],
        [ 0.1921, -2.1788,  0.2394,  0.0000,  0.0000,  0.0000],
        [-0.3832,  0.7268, -0.0453,  0.0000,  0.0000,  0.0000],
        [ 0.5254, -1.2628,  1.1149,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8441, -1.6037,  0.0000,  0.0000,  0.0000],
        [-1.2497, -1.6509,  1.7010,  0.0000,  0.0000,  0.0000],
        [ 0.3501,  0.5264,  0.1624,  0.0000,  0.0000,  0.0000],
        [-0.8063,  0.7569,  2.9293,  0.0000,  0.0000,  0.0000],
        [-0.0450, -1.7588, -2.9805,  0.0000,  0.0000,  0.0000],
        [ 0.1323, -0.2108, -0.0618,  0.0000,  0.0000,  0.0000],
        [-1.8212, -0.5858,  0.8302,  0.0000,  0.0000,  0.0000],
        [ 1.1479, -0.5681, -1.9378,  0.0000,  0.0000,  0.0000],
        [-0.6707, -0.9855, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8446, -2.4297, -2.2574,  0.0000,  0.0000,  0.0000],
        [-1.1221,  0.4162,  1.0668,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  63
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0300, grad_fn=<DivBackward0>)
Projection Loss:  tensor(521.1232, grad_fn=<AddBackward0>)
Total Loss:  tensor(521.1533, grad_fn=<AddBackward0>)
Gradients:
1879.9945068359375
Gradient before update: tensor(-437.5469)
Gradient after update: tensor(-437.5469)
current Learning Rate:  0.00625
------------------------------------------------------------------------------------------------------------------
Iteration:  64
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0296, grad_fn=<DivBackward0>)
Projection Loss:  tensor(518.2744, grad_fn=<AddBackward0>)
Total Loss:  tensor(518.3040, grad_fn=<AddBackward0>)
Gradients:
3984.524658203125
Gradient before update: tensor(-754.2960)
Gradient after update: tensor(-754.2960)
current Learning Rate:  0.00625
Total Loss:  tensor(518.3040, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6577,  0.0000,  0.0000,  0.0000],
        [-0.1203,  0.5798,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7416,  0.4483,  2.7637,  0.0000,  0.0000,  0.0000],
        [ 0.8132,  0.2646,  2.7983,  0.0000,  0.0000,  0.0000],
        [ 0.0183, -0.0087,  0.7271,  0.0000,  0.0000,  0.0000],
        [ 1.1685,  0.2760, -0.8520,  0.0000,  0.0000,  0.0000],
        [ 0.4890,  0.5421, -0.5659,  0.0000,  0.0000,  0.0000],
        [ 1.2454,  0.3908,  0.7768,  0.0000,  0.0000,  0.0000],
        [-0.5602, -2.1594, -1.3455,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0704,  0.0000,  0.0000,  0.0000],
        [-1.5717, -1.4977, -3.4259,  0.0000,  0.0000,  0.0000],
        [-1.0547, -0.5241,  0.9652,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2591,  1.0415,  3.2945,  0.0000,  0.0000,  0.0000],
        [-1.1754, -0.8159, -3.2452,  0.0000,  0.0000,  0.0000],
        [-1.3073,  1.0584, -3.4285,  0.0000,  0.0000,  0.0000],
        [ 1.4912,  0.9297,  2.1461,  0.0000,  0.0000,  0.0000],
        [ 0.0869, -0.7323,  2.9280,  0.0000,  0.0000,  0.0000],
        [-0.7979,  0.8383, -1.9988,  0.0000,  0.0000,  0.0000],
        [-0.3579, -1.2140,  0.3833,  0.0000,  0.0000,  0.0000],
        [ 1.4425,  0.8836, -0.3412,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9346,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.8985,  0.9163, -1.1197,  0.0000,  0.0000,  0.0000],
        [ 0.4315,  1.0031, -1.4636,  0.0000,  0.0000,  0.0000],
        [-1.2686, -0.0929, -1.6198,  0.0000,  0.0000,  0.0000],
        [ 0.6406, -0.6112, -3.6106,  0.0000,  0.0000,  0.0000],
        [-1.8038, -0.1670, -0.5857,  0.0000,  0.0000,  0.0000],
        [-0.5283,  0.0732, -1.4274,  0.0000,  0.0000,  0.0000],
        [ 0.9142, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4305,  0.0000,  0.0000,  0.0000],
        [-0.6558, -0.4693,  2.3458,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4407, -1.1070, -0.7717,  0.0000,  0.0000,  0.0000],
        [ 1.0842,  0.4723, -2.3290,  0.0000,  0.0000,  0.0000],
        [-1.8526, -1.3133, -0.4955,  0.0000,  0.0000,  0.0000],
        [-1.4061,  0.6208, -2.6397,  0.0000,  0.0000,  0.0000],
        [ 0.7765,  1.0106,  1.3703,  0.0000,  0.0000,  0.0000],
        [ 1.1775, -1.4626,  1.3805,  0.0000,  0.0000,  0.0000],
        [-0.4827, -0.4041, -2.4915,  0.0000,  0.0000,  0.0000],
        [-0.8248, -1.4506,  3.5445,  0.0000,  0.0000,  0.0000],
        [ 0.5470,  0.0266, -1.2413,  0.0000,  0.0000,  0.0000],
        [ 0.1864, -2.1837,  0.2449,  0.0000,  0.0000,  0.0000],
        [-0.3832,  0.7267, -0.0457,  0.0000,  0.0000,  0.0000],
        [ 0.5259, -1.2633,  1.1153,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8441, -1.6037,  0.0000,  0.0000,  0.0000],
        [-1.2498, -1.6508,  1.7011,  0.0000,  0.0000,  0.0000],
        [ 0.3501,  0.5264,  0.1623,  0.0000,  0.0000,  0.0000],
        [-0.8061,  0.7569,  2.9293,  0.0000,  0.0000,  0.0000],
        [-0.0425, -1.7575, -2.9801,  0.0000,  0.0000,  0.0000],
        [ 0.1324, -0.2107, -0.0619,  0.0000,  0.0000,  0.0000],
        [-1.8202, -0.5850,  0.8301,  0.0000,  0.0000,  0.0000],
        [ 1.1478, -0.5679, -1.9378,  0.0000,  0.0000,  0.0000],
        [-0.6708, -0.9856, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8477, -2.4311, -2.2565,  0.0000,  0.0000,  0.0000],
        [-1.1224,  0.4165,  1.0670,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  65
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0293, grad_fn=<DivBackward0>)
Projection Loss:  tensor(514.9349, grad_fn=<AddBackward0>)
Total Loss:  tensor(514.9642, grad_fn=<AddBackward0>)
Gradients:
115.0709457397461
Gradient before update: tensor(42.0998)
Gradient after update: tensor(42.0998)
current Learning Rate:  0.00625
------------------------------------------------------------------------------------------------------------------
Iteration:  66
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0291, grad_fn=<DivBackward0>)
Projection Loss:  tensor(514.8850, grad_fn=<AddBackward0>)
Total Loss:  tensor(514.9141, grad_fn=<AddBackward0>)
Gradients:
42.22014236450195
Gradient before update: tensor(-40.1493)
Gradient after update: tensor(-40.1493)
current Learning Rate:  0.00625
Total Loss:  tensor(514.9141, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6578,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5798,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7418,  0.4487,  2.7628,  0.0000,  0.0000,  0.0000],
        [ 0.8132,  0.2647,  2.7983,  0.0000,  0.0000,  0.0000],
        [ 0.0183, -0.0087,  0.7271,  0.0000,  0.0000,  0.0000],
        [ 1.1683,  0.2711, -0.8488,  0.0000,  0.0000,  0.0000],
        [ 0.4883,  0.5423, -0.5658,  0.0000,  0.0000,  0.0000],
        [ 1.2456,  0.3909,  0.7768,  0.0000,  0.0000,  0.0000],
        [-0.5662, -2.1658, -1.3394,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0704,  0.0000,  0.0000,  0.0000],
        [-1.5697, -1.4952, -3.4272,  0.0000,  0.0000,  0.0000],
        [-1.0549, -0.5240,  0.9652,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2615,  1.0413,  3.2935,  0.0000,  0.0000,  0.0000],
        [-1.1770, -0.8167, -3.2447,  0.0000,  0.0000,  0.0000],
        [-1.3076,  1.0553, -3.4270,  0.0000,  0.0000,  0.0000],
        [ 1.4911,  0.9297,  2.1462,  0.0000,  0.0000,  0.0000],
        [ 0.0875, -0.7330,  2.9287,  0.0000,  0.0000,  0.0000],
        [-0.7978,  0.8384, -1.9987,  0.0000,  0.0000,  0.0000],
        [-0.3578, -1.2141,  0.3833,  0.0000,  0.0000,  0.0000],
        [ 1.4423,  0.8833, -0.3414,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9346,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.8992,  0.9163, -1.1191,  0.0000,  0.0000,  0.0000],
        [ 0.4316,  1.0032, -1.4639,  0.0000,  0.0000,  0.0000],
        [-1.2697, -0.0941, -1.6186,  0.0000,  0.0000,  0.0000],
        [ 0.6406, -0.6112, -3.6107,  0.0000,  0.0000,  0.0000],
        [-1.8077, -0.1643, -0.5842,  0.0000,  0.0000,  0.0000],
        [-0.5291,  0.0740, -1.4282,  0.0000,  0.0000,  0.0000],
        [ 0.9142, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6558, -0.4693,  2.3458,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4427, -1.1112, -0.7627,  0.0000,  0.0000,  0.0000],
        [ 1.0842,  0.4723, -2.3290,  0.0000,  0.0000,  0.0000],
        [-1.8525, -1.3133, -0.4956,  0.0000,  0.0000,  0.0000],
        [-1.4059,  0.6206, -2.6396,  0.0000,  0.0000,  0.0000],
        [ 0.7755,  1.0118,  1.3716,  0.0000,  0.0000,  0.0000],
        [ 1.1776, -1.4629,  1.3804,  0.0000,  0.0000,  0.0000],
        [-0.4824, -0.4045, -2.4916,  0.0000,  0.0000,  0.0000],
        [-0.8163, -1.4591,  3.5359,  0.0000,  0.0000,  0.0000],
        [ 0.5417,  0.0257, -1.2426,  0.0000,  0.0000,  0.0000],
        [ 0.1817, -2.1877,  0.2494,  0.0000,  0.0000,  0.0000],
        [-0.3832,  0.7267, -0.0461,  0.0000,  0.0000,  0.0000],
        [ 0.5263, -1.2637,  1.1157,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8442, -1.6037,  0.0000,  0.0000,  0.0000],
        [-1.2499, -1.6508,  1.7011,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5264,  0.1623,  0.0000,  0.0000,  0.0000],
        [-0.8059,  0.7568,  2.9294,  0.0000,  0.0000,  0.0000],
        [-0.0404, -1.7565, -2.9799,  0.0000,  0.0000,  0.0000],
        [ 0.1324, -0.2106, -0.0619,  0.0000,  0.0000,  0.0000],
        [-1.8194, -0.5844,  0.8300,  0.0000,  0.0000,  0.0000],
        [ 1.1478, -0.5677, -1.9377,  0.0000,  0.0000,  0.0000],
        [-0.6709, -0.9856, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8503, -2.4322, -2.2559,  0.0000,  0.0000,  0.0000],
        [-1.1225,  0.4167,  1.0672,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  67
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0289, grad_fn=<DivBackward0>)
Projection Loss:  tensor(514.8739, grad_fn=<AddBackward0>)
Total Loss:  tensor(514.9028, grad_fn=<AddBackward0>)
Gradients:
45.12528610229492
Gradient before update: tensor(-47.1304)
Gradient after update: tensor(-47.1304)
current Learning Rate:  0.00625
------------------------------------------------------------------------------------------------------------------
Iteration:  68
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0287, grad_fn=<DivBackward0>)
Projection Loss:  tensor(513.8717, grad_fn=<AddBackward0>)
Total Loss:  tensor(513.9004, grad_fn=<AddBackward0>)
Gradients:
50.80824279785156
Gradient before update: tensor(-65.3102)
Gradient after update: tensor(-65.3102)
current Learning Rate:  0.00625
Total Loss:  tensor(513.9004, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6578,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5798,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7421,  0.4491,  2.7620,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0183, -0.0087,  0.7271,  0.0000,  0.0000,  0.0000],
        [ 1.1681,  0.2671, -0.8461,  0.0000,  0.0000,  0.0000],
        [ 0.4877,  0.5425, -0.5658,  0.0000,  0.0000,  0.0000],
        [ 1.2458,  0.3909,  0.7768,  0.0000,  0.0000,  0.0000],
        [-0.5713, -2.1710, -1.3344,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5681, -1.4931, -3.4282,  0.0000,  0.0000,  0.0000],
        [-1.0551, -0.5240,  0.9652,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2635,  1.0411,  3.2927,  0.0000,  0.0000,  0.0000],
        [-1.1783, -0.8174, -3.2442,  0.0000,  0.0000,  0.0000],
        [-1.3078,  1.0528, -3.4257,  0.0000,  0.0000,  0.0000],
        [ 1.4911,  0.9297,  2.1462,  0.0000,  0.0000,  0.0000],
        [ 0.0881, -0.7335,  2.9293,  0.0000,  0.0000,  0.0000],
        [-0.7978,  0.8386, -1.9986,  0.0000,  0.0000,  0.0000],
        [-0.3578, -1.2141,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4421,  0.8831, -0.3417,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9346,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.8998,  0.9163, -1.1185,  0.0000,  0.0000,  0.0000],
        [ 0.4317,  1.0033, -1.4641,  0.0000,  0.0000,  0.0000],
        [-1.2707, -0.0950, -1.6177,  0.0000,  0.0000,  0.0000],
        [ 0.6405, -0.6111, -3.6107,  0.0000,  0.0000,  0.0000],
        [-1.8109, -0.1621, -0.5830,  0.0000,  0.0000,  0.0000],
        [-0.5298,  0.0747, -1.4288,  0.0000,  0.0000,  0.0000],
        [ 0.9142, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6558, -0.4693,  2.3458,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4444, -1.1147, -0.7554,  0.0000,  0.0000,  0.0000],
        [ 1.0842,  0.4724, -2.3290,  0.0000,  0.0000,  0.0000],
        [-1.8523, -1.3133, -0.4957,  0.0000,  0.0000,  0.0000],
        [-1.4057,  0.6204, -2.6394,  0.0000,  0.0000,  0.0000],
        [ 0.7747,  1.0127,  1.3726,  0.0000,  0.0000,  0.0000],
        [ 1.1777, -1.4631,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4821, -0.4049, -2.4917,  0.0000,  0.0000,  0.0000],
        [-0.8093, -1.4661,  3.5289,  0.0000,  0.0000,  0.0000],
        [ 0.5374,  0.0249, -1.2437,  0.0000,  0.0000,  0.0000],
        [ 0.1778, -2.1910,  0.2531,  0.0000,  0.0000,  0.0000],
        [-0.3832,  0.7268, -0.0465,  0.0000,  0.0000,  0.0000],
        [ 0.5266, -1.2640,  1.1160,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8442, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2499, -1.6507,  1.7012,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5264,  0.1623,  0.0000,  0.0000,  0.0000],
        [-0.8058,  0.7568,  2.9294,  0.0000,  0.0000,  0.0000],
        [-0.0388, -1.7556, -2.9796,  0.0000,  0.0000,  0.0000],
        [ 0.1325, -0.2105, -0.0620,  0.0000,  0.0000,  0.0000],
        [-1.8188, -0.5839,  0.8299,  0.0000,  0.0000,  0.0000],
        [ 1.1477, -0.5676, -1.9376,  0.0000,  0.0000,  0.0000],
        [-0.6710, -0.9857, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8524, -2.4331, -2.2553,  0.0000,  0.0000,  0.0000],
        [-1.1227,  0.4168,  1.0674,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  69
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0285, grad_fn=<DivBackward0>)
Projection Loss:  tensor(512.8624, grad_fn=<AddBackward0>)
Total Loss:  tensor(512.8909, grad_fn=<AddBackward0>)
Gradients:
55.41793441772461
Gradient before update: tensor(-49.2973)
Gradient after update: tensor(-49.2973)
current Learning Rate:  0.00625
------------------------------------------------------------------------------------------------------------------
Iteration:  70
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0283, grad_fn=<DivBackward0>)
Projection Loss:  tensor(511.8647, grad_fn=<AddBackward0>)
Total Loss:  tensor(511.8930, grad_fn=<AddBackward0>)
Gradients:
80.183837890625
Gradient before update: tensor(-138.1912)
Gradient after update: tensor(-138.1912)
current Learning Rate:  0.00625
Total Loss:  tensor(511.8930, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6578,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7423,  0.4494,  2.7613,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0183, -0.0087,  0.7271,  0.0000,  0.0000,  0.0000],
        [ 1.1680,  0.2638, -0.8440,  0.0000,  0.0000,  0.0000],
        [ 0.4872,  0.5426, -0.5657,  0.0000,  0.0000,  0.0000],
        [ 1.2459,  0.3909,  0.7768,  0.0000,  0.0000,  0.0000],
        [-0.5754, -2.1753, -1.3303,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5654, -1.4905, -3.4284,  0.0000,  0.0000,  0.0000],
        [-1.0552, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2651,  1.0410,  3.2920,  0.0000,  0.0000,  0.0000],
        [-1.1794, -0.8179, -3.2439,  0.0000,  0.0000,  0.0000],
        [-1.3080,  1.0506, -3.4247,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9297,  2.1462,  0.0000,  0.0000,  0.0000],
        [ 0.0885, -0.7340,  2.9297,  0.0000,  0.0000,  0.0000],
        [-0.7977,  0.8387, -1.9985,  0.0000,  0.0000,  0.0000],
        [-0.3577, -1.2142,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4420,  0.8829, -0.3419,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9346,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9005,  0.9163, -1.1179,  0.0000,  0.0000,  0.0000],
        [ 0.4317,  1.0034, -1.4643,  0.0000,  0.0000,  0.0000],
        [-1.2715, -0.0958, -1.6169,  0.0000,  0.0000,  0.0000],
        [ 0.6405, -0.6111, -3.6107,  0.0000,  0.0000,  0.0000],
        [-1.8136, -0.1603, -0.5820,  0.0000,  0.0000,  0.0000],
        [-0.5304,  0.0753, -1.4294,  0.0000,  0.0000,  0.0000],
        [ 0.9142, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6558, -0.4693,  2.3458,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4458, -1.1175, -0.7494,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3290,  0.0000,  0.0000,  0.0000],
        [-1.8521, -1.3133, -0.4957,  0.0000,  0.0000,  0.0000],
        [-1.4056,  0.6203, -2.6393,  0.0000,  0.0000,  0.0000],
        [ 0.7740,  1.0135,  1.3735,  0.0000,  0.0000,  0.0000],
        [ 1.1777, -1.4632,  1.3802,  0.0000,  0.0000,  0.0000],
        [-0.4818, -0.4052, -2.4918,  0.0000,  0.0000,  0.0000],
        [-0.8036, -1.4719,  3.5231,  0.0000,  0.0000,  0.0000],
        [ 0.5338,  0.0243, -1.2445,  0.0000,  0.0000,  0.0000],
        [ 0.1746, -2.1938,  0.2562,  0.0000,  0.0000,  0.0000],
        [-0.3832,  0.7268, -0.0468,  0.0000,  0.0000,  0.0000],
        [ 0.5268, -1.2643,  1.1162,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8442, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2500, -1.6507,  1.7013,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5264,  0.1623,  0.0000,  0.0000,  0.0000],
        [-0.8057,  0.7568,  2.9294,  0.0000,  0.0000,  0.0000],
        [-0.0374, -1.7549, -2.9794,  0.0000,  0.0000,  0.0000],
        [ 0.1325, -0.2105, -0.0620,  0.0000,  0.0000,  0.0000],
        [-1.8182, -0.5835,  0.8299,  0.0000,  0.0000,  0.0000],
        [ 1.1477, -0.5675, -1.9376,  0.0000,  0.0000,  0.0000],
        [-0.6711, -0.9858, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8542, -2.4339, -2.2549,  0.0000,  0.0000,  0.0000],
        [-1.1228,  0.4170,  1.0675,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  71
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0281, grad_fn=<DivBackward0>)
Projection Loss:  tensor(511.8326, grad_fn=<AddBackward0>)
Total Loss:  tensor(511.8608, grad_fn=<AddBackward0>)
Gradients:
70.66320037841797
Gradient before update: tensor(-75.2102)
Gradient after update: tensor(-75.2102)
current Learning Rate:  0.00625
------------------------------------------------------------------------------------------------------------------
Iteration:  72
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0279, grad_fn=<DivBackward0>)
Projection Loss:  tensor(510.3491, grad_fn=<AddBackward0>)
Total Loss:  tensor(510.3770, grad_fn=<AddBackward0>)
Gradients:
1105.187744140625
Gradient before update: tensor(-1218.9440)
Gradient after update: tensor(-1218.9440)
current Learning Rate:  0.00625
Total Loss:  tensor(510.3770, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6578,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7425,  0.4497,  2.7607,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0183, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1679,  0.2611, -0.8422,  0.0000,  0.0000,  0.0000],
        [ 0.4868,  0.5427, -0.5657,  0.0000,  0.0000,  0.0000],
        [ 1.2460,  0.3909,  0.7768,  0.0000,  0.0000,  0.0000],
        [-0.5788, -2.1789, -1.3269,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5621, -1.4875, -3.4279,  0.0000,  0.0000,  0.0000],
        [-1.0553, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2664,  1.0409,  3.2915,  0.0000,  0.0000,  0.0000],
        [-1.1803, -0.8184, -3.2436,  0.0000,  0.0000,  0.0000],
        [-1.3081,  1.0488, -3.4238,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1462,  0.0000,  0.0000,  0.0000],
        [ 0.0889, -0.7344,  2.9301,  0.0000,  0.0000,  0.0000],
        [-0.7977,  0.8388, -1.9985,  0.0000,  0.0000,  0.0000],
        [-0.3576, -1.2143,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4419,  0.8828, -0.3420,  0.0000,  0.0000,  0.0000],
        [-1.2236,  0.9346,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9011,  0.9163, -1.1172,  0.0000,  0.0000,  0.0000],
        [ 0.4318,  1.0034, -1.4645,  0.0000,  0.0000,  0.0000],
        [-1.2721, -0.0964, -1.6163,  0.0000,  0.0000,  0.0000],
        [ 0.6405, -0.6110, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8158, -0.1589, -0.5811,  0.0000,  0.0000,  0.0000],
        [-0.5309,  0.0758, -1.4298,  0.0000,  0.0000,  0.0000],
        [ 0.9142, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6558, -0.4693,  2.3458,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4469, -1.1199, -0.7444,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8517, -1.3132, -0.4957,  0.0000,  0.0000,  0.0000],
        [-1.4055,  0.6201, -2.6393,  0.0000,  0.0000,  0.0000],
        [ 0.7735,  1.0142,  1.3742,  0.0000,  0.0000,  0.0000],
        [ 1.1778, -1.4634,  1.3802,  0.0000,  0.0000,  0.0000],
        [-0.4816, -0.4055, -2.4918,  0.0000,  0.0000,  0.0000],
        [-0.7989, -1.4766,  3.5184,  0.0000,  0.0000,  0.0000],
        [ 0.5309,  0.0238, -1.2453,  0.0000,  0.0000,  0.0000],
        [ 0.1720, -2.1962,  0.2586,  0.0000,  0.0000,  0.0000],
        [-0.3832,  0.7268, -0.0472,  0.0000,  0.0000,  0.0000],
        [ 0.5270, -1.2645,  1.1164,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8442, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2500, -1.6506,  1.7013,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8056,  0.7567,  2.9294,  0.0000,  0.0000,  0.0000],
        [-0.0362, -1.7543, -2.9793,  0.0000,  0.0000,  0.0000],
        [ 0.1325, -0.2104, -0.0620,  0.0000,  0.0000,  0.0000],
        [-1.8178, -0.5832,  0.8298,  0.0000,  0.0000,  0.0000],
        [ 1.1476, -0.5674, -1.9375,  0.0000,  0.0000,  0.0000],
        [-0.6711, -0.9858, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8557, -2.4334, -2.2546,  0.0000,  0.0000,  0.0000],
        [-1.1229,  0.4171,  1.0676,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  73
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0278, grad_fn=<DivBackward0>)
Projection Loss:  tensor(509.2745, grad_fn=<AddBackward0>)
Total Loss:  tensor(509.3022, grad_fn=<AddBackward0>)
Gradients:
6642.8076171875
Gradient before update: tensor(-5629.0771)
Gradient after update: tensor(-5629.0771)
current Learning Rate:  0.00625
------------------------------------------------------------------------------------------------------------------
Iteration:  74
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0276, grad_fn=<DivBackward0>)
Projection Loss:  tensor(508.7614, grad_fn=<AddBackward0>)
Total Loss:  tensor(508.7889, grad_fn=<AddBackward0>)
Gradients:
147.61053466796875
Gradient before update: tensor(-154.9993)
Gradient after update: tensor(-154.9993)
current Learning Rate:  0.00625
Total Loss:  tensor(508.7889, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7427,  0.4500,  2.7602,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0183, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1678,  0.2589, -0.8407,  0.0000,  0.0000,  0.0000],
        [ 0.4865,  0.5428, -0.5657,  0.0000,  0.0000,  0.0000],
        [ 1.2461,  0.3909,  0.7768,  0.0000,  0.0000,  0.0000],
        [-0.5815, -2.1818, -1.3241,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4850, -3.4274,  0.0000,  0.0000,  0.0000],
        [-1.0555, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2675,  1.0408,  3.2911,  0.0000,  0.0000,  0.0000],
        [-1.1811, -0.8187, -3.2434,  0.0000,  0.0000,  0.0000],
        [-1.3081,  1.0472, -3.4231,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1462,  0.0000,  0.0000,  0.0000],
        [ 0.0892, -0.7347,  2.9304,  0.0000,  0.0000,  0.0000],
        [-0.7977,  0.8389, -1.9985,  0.0000,  0.0000,  0.0000],
        [-0.3575, -1.2144,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4418,  0.8826, -0.3421,  0.0000,  0.0000,  0.0000],
        [-1.2236,  0.9346,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9018,  0.9163, -1.1166,  0.0000,  0.0000,  0.0000],
        [ 0.4318,  1.0035, -1.4646,  0.0000,  0.0000,  0.0000],
        [-1.2726, -0.0970, -1.6157,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6110, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8176, -0.1576, -0.5805,  0.0000,  0.0000,  0.0000],
        [-0.5313,  0.0762, -1.4302,  0.0000,  0.0000,  0.0000],
        [ 0.9142, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6558, -0.4692,  2.3458,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4479, -1.1218, -0.7403,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8513, -1.3131, -0.4956,  0.0000,  0.0000,  0.0000],
        [-1.4054,  0.6200, -2.6392,  0.0000,  0.0000,  0.0000],
        [ 0.7731,  1.0147,  1.3748,  0.0000,  0.0000,  0.0000],
        [ 1.1778, -1.4635,  1.3801,  0.0000,  0.0000,  0.0000],
        [-0.4815, -0.4057, -2.4919,  0.0000,  0.0000,  0.0000],
        [-0.7951, -1.4805,  3.5145,  0.0000,  0.0000,  0.0000],
        [ 0.5285,  0.0233, -1.2458,  0.0000,  0.0000,  0.0000],
        [ 0.1698, -2.1981,  0.2606,  0.0000,  0.0000,  0.0000],
        [-0.3831,  0.7268, -0.0476,  0.0000,  0.0000,  0.0000],
        [ 0.5272, -1.2647,  1.1166,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2500, -1.6506,  1.7013,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8055,  0.7567,  2.9294,  0.0000,  0.0000,  0.0000],
        [-0.0353, -1.7538, -2.9791,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2104, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8174, -0.5829,  0.8298,  0.0000,  0.0000,  0.0000],
        [ 1.1476, -0.5673, -1.9375,  0.0000,  0.0000,  0.0000],
        [-0.6712, -0.9858, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8620, -2.4341, -2.2536,  0.0000,  0.0000,  0.0000],
        [-1.1230,  0.4172,  1.0677,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  75
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0274, grad_fn=<DivBackward0>)
Projection Loss:  tensor(507.9313, grad_fn=<AddBackward0>)
Total Loss:  tensor(507.9587, grad_fn=<AddBackward0>)
Gradients:
2172.641845703125
Gradient before update: tensor(-309.4672)
Gradient after update: tensor(-309.4672)
current Learning Rate:  0.003125
------------------------------------------------------------------------------------------------------------------
Iteration:  76
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0272, grad_fn=<DivBackward0>)
Projection Loss:  tensor(506.5746, grad_fn=<AddBackward0>)
Total Loss:  tensor(506.6019, grad_fn=<AddBackward0>)
Gradients:
576.9495849609375
Gradient before update: tensor(-605.0535)
Gradient after update: tensor(-605.0535)
current Learning Rate:  0.003125
Total Loss:  tensor(506.6019, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7428,  0.4501,  2.7598,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1678,  0.2575, -0.8398,  0.0000,  0.0000,  0.0000],
        [ 0.4863,  0.5429, -0.5657,  0.0000,  0.0000,  0.0000],
        [ 1.2461,  0.3910,  0.7768,  0.0000,  0.0000,  0.0000],
        [-0.5833, -2.1836, -1.3223,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5576, -1.4836, -3.4271,  0.0000,  0.0000,  0.0000],
        [-1.0555, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2682,  1.0408,  3.2908,  0.0000,  0.0000,  0.0000],
        [-1.1816, -0.8190, -3.2432,  0.0000,  0.0000,  0.0000],
        [-1.3080,  1.0461, -3.4227,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1462,  0.0000,  0.0000,  0.0000],
        [ 0.0894, -0.7349,  2.9306,  0.0000,  0.0000,  0.0000],
        [-0.7977,  0.8389, -1.9984,  0.0000,  0.0000,  0.0000],
        [-0.3575, -1.2144,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4417,  0.8826, -0.3422,  0.0000,  0.0000,  0.0000],
        [-1.2236,  0.9346,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9023,  0.9163, -1.1161,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0035, -1.4648,  0.0000,  0.0000,  0.0000],
        [-1.2730, -0.0973, -1.6154,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6110, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8187, -0.1569, -0.5800,  0.0000,  0.0000,  0.0000],
        [-0.5315,  0.0764, -1.4304,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6558, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4485, -1.1230, -0.7378,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8507, -1.3130, -0.4953,  0.0000,  0.0000,  0.0000],
        [-1.4053,  0.6200, -2.6391,  0.0000,  0.0000,  0.0000],
        [ 0.7728,  1.0150,  1.3751,  0.0000,  0.0000,  0.0000],
        [ 1.1779, -1.4636,  1.3801,  0.0000,  0.0000,  0.0000],
        [-0.4814, -0.4059, -2.4919,  0.0000,  0.0000,  0.0000],
        [-0.7895, -1.4868,  3.5108,  0.0000,  0.0000,  0.0000],
        [ 0.5270,  0.0231, -1.2462,  0.0000,  0.0000,  0.0000],
        [ 0.1685, -2.1994,  0.2619,  0.0000,  0.0000,  0.0000],
        [-0.3831,  0.7268, -0.0479,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2648,  1.1167,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8055,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0347, -1.7535, -2.9790,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2104, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8172, -0.5828,  0.8298,  0.0000,  0.0000,  0.0000],
        [ 1.1476, -0.5673, -1.9374,  0.0000,  0.0000,  0.0000],
        [-0.6712, -0.9859, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8659, -2.4345, -2.2530,  0.0000,  0.0000,  0.0000],
        [-1.1231,  0.4172,  1.0678,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  77
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0272, grad_fn=<DivBackward0>)
Projection Loss:  tensor(504.4603, grad_fn=<AddBackward0>)
Total Loss:  tensor(504.4874, grad_fn=<AddBackward0>)
Gradients:
2264.921630859375
Gradient before update: tensor(-584.4414)
Gradient after update: tensor(-584.4414)
current Learning Rate:  0.003125
------------------------------------------------------------------------------------------------------------------
Iteration:  78
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0271, grad_fn=<DivBackward0>)
Projection Loss:  tensor(503.9100, grad_fn=<AddBackward0>)
Total Loss:  tensor(503.9371, grad_fn=<AddBackward0>)
Gradients:
61.94304275512695
Gradient before update: tensor(65.1104)
Gradient after update: tensor(65.1104)
current Learning Rate:  0.003125
Total Loss:  tensor(503.9371, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7429,  0.4502,  2.7596,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1677,  0.2567, -0.8393,  0.0000,  0.0000,  0.0000],
        [ 0.4861,  0.5429, -0.5657,  0.0000,  0.0000,  0.0000],
        [ 1.2462,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5842, -2.1854, -1.3216,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5576, -1.4842, -3.4263,  0.0000,  0.0000,  0.0000],
        [-1.0556, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2686,  1.0407,  3.2906,  0.0000,  0.0000,  0.0000],
        [-1.1818, -0.8191, -3.2432,  0.0000,  0.0000,  0.0000],
        [-1.3079,  1.0453, -3.4225,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1462,  0.0000,  0.0000,  0.0000],
        [ 0.0895, -0.7350,  2.9307,  0.0000,  0.0000,  0.0000],
        [-0.7977,  0.8390, -1.9984,  0.0000,  0.0000,  0.0000],
        [-0.3574, -1.2144,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4417,  0.8825, -0.3423,  0.0000,  0.0000,  0.0000],
        [-1.2236,  0.9346,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9026,  0.9163, -1.1158,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0035, -1.4648,  0.0000,  0.0000,  0.0000],
        [-1.2732, -0.0975, -1.6152,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6110, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8193, -0.1565, -0.5798,  0.0000,  0.0000,  0.0000],
        [-0.5316,  0.0766, -1.4305,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6558, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4488, -1.1236, -0.7365,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8494, -1.3127, -0.4947,  0.0000,  0.0000,  0.0000],
        [-1.4053,  0.6199, -2.6391,  0.0000,  0.0000,  0.0000],
        [ 0.7726,  1.0152,  1.3753,  0.0000,  0.0000,  0.0000],
        [ 1.1779, -1.4636,  1.3801,  0.0000,  0.0000,  0.0000],
        [-0.4813, -0.4060, -2.4919,  0.0000,  0.0000,  0.0000],
        [-0.7865, -1.4902,  3.5089,  0.0000,  0.0000,  0.0000],
        [ 0.5262,  0.0229, -1.2464,  0.0000,  0.0000,  0.0000],
        [ 0.1672, -2.2003,  0.2621,  0.0000,  0.0000,  0.0000],
        [-0.3831,  0.7268, -0.0481,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2649,  1.1167,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8055,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0344, -1.7533, -2.9790,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2104, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8171, -0.5827,  0.8298,  0.0000,  0.0000,  0.0000],
        [ 1.1476, -0.5673, -1.9374,  0.0000,  0.0000,  0.0000],
        [-0.6712, -0.9859, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8681, -2.4348, -2.2526,  0.0000,  0.0000,  0.0000],
        [-1.1231,  0.4172,  1.0678,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  79
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0270, grad_fn=<DivBackward0>)
Projection Loss:  tensor(503.3648, grad_fn=<AddBackward0>)
Total Loss:  tensor(503.3918, grad_fn=<AddBackward0>)
Gradients:
6916.07080078125
Gradient before update: tensor(4435.1758)
Gradient after update: tensor(4435.1758)
current Learning Rate:  0.003125
------------------------------------------------------------------------------------------------------------------
Iteration:  80
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0269, grad_fn=<DivBackward0>)
Projection Loss:  tensor(502.8305, grad_fn=<AddBackward0>)
Total Loss:  tensor(502.8574, grad_fn=<AddBackward0>)
Gradients:
141.43069458007812
Gradient before update: tensor(-0.9495)
Gradient after update: tensor(-0.9495)
current Learning Rate:  0.003125
Total Loss:  tensor(502.8574, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7430,  0.4503,  2.7595,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1677,  0.2561, -0.8389,  0.0000,  0.0000,  0.0000],
        [ 0.4861,  0.5429, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2462,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5850, -2.1868, -1.3210,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5579, -1.4853, -3.4253,  0.0000,  0.0000,  0.0000],
        [-1.0556, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2688,  1.0407,  3.2905,  0.0000,  0.0000,  0.0000],
        [-1.1820, -0.8192, -3.2431,  0.0000,  0.0000,  0.0000],
        [-1.3076,  1.0443, -3.4224,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1462,  0.0000,  0.0000,  0.0000],
        [ 0.0896, -0.7351,  2.9308,  0.0000,  0.0000,  0.0000],
        [-0.7976,  0.8390, -1.9984,  0.0000,  0.0000,  0.0000],
        [-0.3574, -1.2145,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4417,  0.8825, -0.3423,  0.0000,  0.0000,  0.0000],
        [-1.2236,  0.9346,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9029,  0.9163, -1.1154,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0035, -1.4649,  0.0000,  0.0000,  0.0000],
        [-1.2733, -0.0976, -1.6151,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6110, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8198, -0.1561, -0.5796,  0.0000,  0.0000,  0.0000],
        [-0.5317,  0.0767, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6558, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4540, -1.1288, -0.7416,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8483, -1.3125, -0.4943,  0.0000,  0.0000,  0.0000],
        [-1.4052,  0.6199, -2.6391,  0.0000,  0.0000,  0.0000],
        [ 0.7725,  1.0154,  1.3755,  0.0000,  0.0000,  0.0000],
        [ 1.1779, -1.4636,  1.3801,  0.0000,  0.0000,  0.0000],
        [-0.4813, -0.4060, -2.4919,  0.0000,  0.0000,  0.0000],
        [-0.7841, -1.4930,  3.5073,  0.0000,  0.0000,  0.0000],
        [ 0.5255,  0.0228, -1.2466,  0.0000,  0.0000,  0.0000],
        [ 0.1661, -2.2010,  0.2622,  0.0000,  0.0000,  0.0000],
        [-0.3831,  0.7268, -0.0483,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2649,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8054,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0342, -1.7532, -2.9789,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2104, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8170, -0.5826,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1476, -0.5672, -1.9374,  0.0000,  0.0000,  0.0000],
        [-0.6712, -0.9859, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8698, -2.4350, -2.2523,  0.0000,  0.0000,  0.0000],
        [-1.1231,  0.4173,  1.0678,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  81
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0268, grad_fn=<DivBackward0>)
Projection Loss:  tensor(501.9533, grad_fn=<AddBackward0>)
Total Loss:  tensor(501.9802, grad_fn=<AddBackward0>)
Gradients:
2934.31103515625
Gradient before update: tensor(4175.2959)
Gradient after update: tensor(4175.2959)
current Learning Rate:  0.003125
------------------------------------------------------------------------------------------------------------------
Iteration:  82
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0268, grad_fn=<DivBackward0>)
Projection Loss:  tensor(499.0679, grad_fn=<AddBackward0>)
Total Loss:  tensor(499.0946, grad_fn=<AddBackward0>)
Gradients:
188.3852081298828
Gradient before update: tensor(-315.8602)
Gradient after update: tensor(-315.8602)
current Learning Rate:  0.003125
Total Loss:  tensor(499.0946, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7431,  0.4504,  2.7593,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1677,  0.2556, -0.8386,  0.0000,  0.0000,  0.0000],
        [ 0.4860,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2462,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5867, -2.1894, -1.3211,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5582, -1.4863, -3.4246,  0.0000,  0.0000,  0.0000],
        [-1.0556, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2691,  1.0407,  3.2904,  0.0000,  0.0000,  0.0000],
        [-1.1822, -0.8193, -3.2430,  0.0000,  0.0000,  0.0000],
        [-1.3066,  1.0422, -3.4224,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1462,  0.0000,  0.0000,  0.0000],
        [ 0.0897, -0.7352,  2.9309,  0.0000,  0.0000,  0.0000],
        [-0.7976,  0.8390, -1.9984,  0.0000,  0.0000,  0.0000],
        [-0.3574, -1.2145,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4417,  0.8825, -0.3423,  0.0000,  0.0000,  0.0000],
        [-1.2236,  0.9346,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9032,  0.9163, -1.1151,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0035, -1.4650,  0.0000,  0.0000,  0.0000],
        [-1.2734, -0.0978, -1.6149,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6110, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8202, -0.1559, -0.5795,  0.0000,  0.0000,  0.0000],
        [-0.5318,  0.0768, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6558, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4583, -1.1330, -0.7458,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8475, -1.3123, -0.4939,  0.0000,  0.0000,  0.0000],
        [-1.4052,  0.6199, -2.6391,  0.0000,  0.0000,  0.0000],
        [ 0.7724,  1.0155,  1.3756,  0.0000,  0.0000,  0.0000],
        [ 1.1779, -1.4637,  1.3801,  0.0000,  0.0000,  0.0000],
        [-0.4812, -0.4061, -2.4919,  0.0000,  0.0000,  0.0000],
        [-0.7821, -1.4952,  3.5060,  0.0000,  0.0000,  0.0000],
        [ 0.5250,  0.0227, -1.2467,  0.0000,  0.0000,  0.0000],
        [ 0.1652, -2.2017,  0.2623,  0.0000,  0.0000,  0.0000],
        [-0.3831,  0.7268, -0.0485,  0.0000,  0.0000,  0.0000],
        [ 0.5274, -1.2650,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8054,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0340, -1.7531, -2.9789,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2104, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8169, -0.5825,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1476, -0.5672, -1.9374,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9859, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8713, -2.4351, -2.2521,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  83
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0267, grad_fn=<DivBackward0>)
Projection Loss:  tensor(499.1894, grad_fn=<AddBackward0>)
Total Loss:  tensor(499.2161, grad_fn=<AddBackward0>)
Gradients:
837.6179809570312
Gradient before update: tensor(180.1052)
Gradient after update: tensor(180.1052)
current Learning Rate:  0.003125
------------------------------------------------------------------------------------------------------------------
Iteration:  84
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0266, grad_fn=<DivBackward0>)
Projection Loss:  tensor(499.0802, grad_fn=<AddBackward0>)
Total Loss:  tensor(499.1068, grad_fn=<AddBackward0>)
Gradients:
267.7244873046875
Gradient before update: tensor(-4.4806)
Gradient after update: tensor(-4.4806)
current Learning Rate:  0.003125
Total Loss:  tensor(499.1068, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7431,  0.4504,  2.7592,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1677,  0.2552, -0.8383,  0.0000,  0.0000,  0.0000],
        [ 0.4859,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2462,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5882, -2.1915, -1.3212,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5585, -1.4871, -3.4239,  0.0000,  0.0000,  0.0000],
        [-1.0557, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2693,  1.0407,  3.2903,  0.0000,  0.0000,  0.0000],
        [-1.1823, -0.8193, -3.2430,  0.0000,  0.0000,  0.0000],
        [-1.3054,  1.0424, -3.4223,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1462,  0.0000,  0.0000,  0.0000],
        [ 0.0897, -0.7352,  2.9309,  0.0000,  0.0000,  0.0000],
        [-0.7976,  0.8391, -1.9984,  0.0000,  0.0000,  0.0000],
        [-0.3573, -1.2145,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4417,  0.8824, -0.3423,  0.0000,  0.0000,  0.0000],
        [-1.2236,  0.9346,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9036,  0.9163, -1.1147,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4651,  0.0000,  0.0000,  0.0000],
        [-1.2735, -0.0979, -1.6148,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6110, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8206, -0.1556, -0.5793,  0.0000,  0.0000,  0.0000],
        [-0.5319,  0.0768, -1.4307,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6558, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4619, -1.1365, -0.7493,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8468, -1.3121, -0.4935,  0.0000,  0.0000,  0.0000],
        [-1.4052,  0.6199, -2.6391,  0.0000,  0.0000,  0.0000],
        [ 0.7723,  1.0156,  1.3757,  0.0000,  0.0000,  0.0000],
        [ 1.1779, -1.4637,  1.3801,  0.0000,  0.0000,  0.0000],
        [-0.4812, -0.4062, -2.4919,  0.0000,  0.0000,  0.0000],
        [-0.7804, -1.4971,  3.5049,  0.0000,  0.0000,  0.0000],
        [ 0.5245,  0.0226, -1.2468,  0.0000,  0.0000,  0.0000],
        [ 0.1645, -2.2022,  0.2624,  0.0000,  0.0000,  0.0000],
        [-0.3831,  0.7268, -0.0487,  0.0000,  0.0000,  0.0000],
        [ 0.5274, -1.2650,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8054,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0338, -1.7530, -2.9788,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2104, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8168, -0.5825,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1476, -0.5672, -1.9374,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9859, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8722, -2.4353, -2.2519,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  85
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0265, grad_fn=<DivBackward0>)
Projection Loss:  tensor(498.2877, grad_fn=<AddBackward0>)
Total Loss:  tensor(498.3142, grad_fn=<AddBackward0>)
Gradients:
2932.410888671875
Gradient before update: tensor(-2250.7625)
Gradient after update: tensor(-2250.7625)
current Learning Rate:  0.003125
------------------------------------------------------------------------------------------------------------------
Iteration:  86
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0264, grad_fn=<DivBackward0>)
Projection Loss:  tensor(496.2339, grad_fn=<AddBackward0>)
Total Loss:  tensor(496.2604, grad_fn=<AddBackward0>)
Gradients:
1575.731201171875
Gradient before update: tensor(234.2200)
Gradient after update: tensor(234.2200)
current Learning Rate:  0.003125
Total Loss:  tensor(496.2604, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7432,  0.4505,  2.7591,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1677,  0.2548, -0.8381,  0.0000,  0.0000,  0.0000],
        [ 0.4859,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2462,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5892, -2.1941, -1.3216,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5587, -1.4878, -3.4234,  0.0000,  0.0000,  0.0000],
        [-1.0557, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2694,  1.0407,  3.2903,  0.0000,  0.0000,  0.0000],
        [-1.1824, -0.8194, -3.2430,  0.0000,  0.0000,  0.0000],
        [-1.3043,  1.0428, -3.4222,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1462,  0.0000,  0.0000,  0.0000],
        [ 0.0898, -0.7353,  2.9310,  0.0000,  0.0000,  0.0000],
        [-0.7976,  0.8391, -1.9983,  0.0000,  0.0000,  0.0000],
        [-0.3573, -1.2145,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2236,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9039,  0.9163, -1.1144,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4652,  0.0000,  0.0000,  0.0000],
        [-1.2736, -0.0979, -1.6148,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6110, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8208, -0.1554, -0.5792,  0.0000,  0.0000,  0.0000],
        [-0.5319,  0.0769, -1.4307,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4651, -1.1395, -0.7521,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8462, -1.3120, -0.4933,  0.0000,  0.0000,  0.0000],
        [-1.4052,  0.6198, -2.6391,  0.0000,  0.0000,  0.0000],
        [ 0.7722,  1.0157,  1.3758,  0.0000,  0.0000,  0.0000],
        [ 1.1779, -1.4637,  1.3801,  0.0000,  0.0000,  0.0000],
        [-0.4811, -0.4062, -2.4919,  0.0000,  0.0000,  0.0000],
        [-0.7791, -1.4986,  3.5040,  0.0000,  0.0000,  0.0000],
        [ 0.5241,  0.0226, -1.2469,  0.0000,  0.0000,  0.0000],
        [ 0.1639, -2.2026,  0.2625,  0.0000,  0.0000,  0.0000],
        [-0.3831,  0.7268, -0.0489,  0.0000,  0.0000,  0.0000],
        [ 0.5274, -1.2650,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8054,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0337, -1.7529, -2.9788,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8168, -0.5825,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1476, -0.5672, -1.9373,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9859, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8731, -2.4329, -2.2518,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  87
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0263, grad_fn=<DivBackward0>)
Projection Loss:  tensor(495.0203, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0467, grad_fn=<AddBackward0>)
Gradients:
85.84187316894531
Gradient before update: tensor(54.0579)
Gradient after update: tensor(54.0579)
current Learning Rate:  0.003125
------------------------------------------------------------------------------------------------------------------
Iteration:  88
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0262, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9904, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0167, grad_fn=<AddBackward0>)
Gradients:
5.910434246063232
Gradient before update: tensor(-0.8030)
Gradient after update: tensor(-0.8030)
current Learning Rate:  0.003125
Total Loss:  tensor(495.0167, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7432,  0.4505,  2.7590,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1677,  0.2546, -0.8379,  0.0000,  0.0000,  0.0000],
        [ 0.4858,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5897, -2.1967, -1.3221,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5589, -1.4884, -3.4229,  0.0000,  0.0000,  0.0000],
        [-1.0557, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2695,  1.0407,  3.2902,  0.0000,  0.0000,  0.0000],
        [-1.1825, -0.8194, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3034,  1.0432, -3.4221,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0898, -0.7353,  2.9310,  0.0000,  0.0000,  0.0000],
        [-0.7976,  0.8391, -1.9983,  0.0000,  0.0000,  0.0000],
        [-0.3573, -1.2145,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2236,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9043,  0.9163, -1.1140,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4652,  0.0000,  0.0000,  0.0000],
        [-1.2737, -0.0980, -1.6147,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8211, -0.1553, -0.5791,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0769, -1.4307,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4679, -1.1420, -0.7545,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8457, -1.3119, -0.4931,  0.0000,  0.0000,  0.0000],
        [-1.4052,  0.6198, -2.6391,  0.0000,  0.0000,  0.0000],
        [ 0.7722,  1.0157,  1.3759,  0.0000,  0.0000,  0.0000],
        [ 1.1779, -1.4637,  1.3801,  0.0000,  0.0000,  0.0000],
        [-0.4811, -0.4063, -2.4919,  0.0000,  0.0000,  0.0000],
        [-0.7779, -1.4999,  3.5033,  0.0000,  0.0000,  0.0000],
        [ 0.5238,  0.0225, -1.2470,  0.0000,  0.0000,  0.0000],
        [ 0.1634, -2.2029,  0.2625,  0.0000,  0.0000,  0.0000],
        [-0.3831,  0.7268, -0.0491,  0.0000,  0.0000,  0.0000],
        [ 0.5274, -1.2650,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8054,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7528, -2.9787,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8167, -0.5824,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1476, -0.5672, -1.9373,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9859, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8739, -2.4310, -2.2517,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  89
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0262, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9858, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0119, grad_fn=<AddBackward0>)
Gradients:
2.434178352355957
Gradient before update: tensor(-1.9136)
Gradient after update: tensor(-1.9136)
current Learning Rate:  0.003125
------------------------------------------------------------------------------------------------------------------
Iteration:  90
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0261, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9836, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0096, grad_fn=<AddBackward0>)
Gradients:
1.6578387022018433
Gradient before update: tensor(-1.7425)
Gradient after update: tensor(-1.7425)
current Learning Rate:  0.0015625
Total Loss:  tensor(495.0096, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7433,  0.4506,  2.7589,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2543, -0.8377,  0.0000,  0.0000,  0.0000],
        [ 0.4858,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5901, -2.1988, -1.3225,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5590, -1.4888, -3.4225,  0.0000,  0.0000,  0.0000],
        [-1.0557, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2696,  1.0407,  3.2902,  0.0000,  0.0000,  0.0000],
        [-1.1826, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3027,  1.0436, -3.4220,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0898, -0.7353,  2.9310,  0.0000,  0.0000,  0.0000],
        [-0.7976,  0.8391, -1.9983,  0.0000,  0.0000,  0.0000],
        [-0.3572, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2236,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9046,  0.9163, -1.1137,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4653,  0.0000,  0.0000,  0.0000],
        [-1.2737, -0.0981, -1.6146,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8212, -0.1552, -0.5791,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0770, -1.4307,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4702, -1.1440, -0.7564,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8453, -1.3118, -0.4929,  0.0000,  0.0000,  0.0000],
        [-1.4052,  0.6198, -2.6391,  0.0000,  0.0000,  0.0000],
        [ 0.7721,  1.0158,  1.3760,  0.0000,  0.0000,  0.0000],
        [ 1.1779, -1.4637,  1.3802,  0.0000,  0.0000,  0.0000],
        [-0.4811, -0.4063, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7770, -1.5009,  3.5027,  0.0000,  0.0000,  0.0000],
        [ 0.5236,  0.0225, -1.2470,  0.0000,  0.0000,  0.0000],
        [ 0.1630, -2.2032,  0.2626,  0.0000,  0.0000,  0.0000],
        [-0.3831,  0.7268, -0.0493,  0.0000,  0.0000,  0.0000],
        [ 0.5274, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8054,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0335, -1.7528, -2.9787,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8167, -0.5824,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1477, -0.5672, -1.9373,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9859, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8745, -2.4294, -2.2517,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  91
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0260, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9822, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0082, grad_fn=<AddBackward0>)
Gradients:
1.3659648895263672
Gradient before update: tensor(-1.7603)
Gradient after update: tensor(-1.7603)
current Learning Rate:  0.0015625
------------------------------------------------------------------------------------------------------------------
Iteration:  92
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0259, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9817, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0076, grad_fn=<AddBackward0>)
Gradients:
1.3157298564910889
Gradient before update: tensor(-1.7566)
Gradient after update: tensor(-1.7566)
current Learning Rate:  0.0015625
Total Loss:  tensor(495.0076, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7433,  0.4506,  2.7589,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2542, -0.8377,  0.0000,  0.0000,  0.0000],
        [ 0.4858,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5903, -2.1997, -1.3226,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5591, -1.4890, -3.4224,  0.0000,  0.0000,  0.0000],
        [-1.0557, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2696,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1826, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3024,  1.0437, -3.4219,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0898, -0.7353,  2.9310,  0.0000,  0.0000,  0.0000],
        [-0.7976,  0.8392, -1.9982,  0.0000,  0.0000,  0.0000],
        [-0.3572, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2236,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9048,  0.9163, -1.1135,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4653,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0981, -1.6146,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8213, -0.1551, -0.5790,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0770, -1.4307,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4711, -1.1449, -0.7571,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8451, -1.3118, -0.4928,  0.0000,  0.0000,  0.0000],
        [-1.4052,  0.6198, -2.6391,  0.0000,  0.0000,  0.0000],
        [ 0.7721,  1.0158,  1.3760,  0.0000,  0.0000,  0.0000],
        [ 1.1779, -1.4637,  1.3802,  0.0000,  0.0000,  0.0000],
        [-0.4811, -0.4063, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7767, -1.5014,  3.5024,  0.0000,  0.0000,  0.0000],
        [ 0.5235,  0.0224, -1.2471,  0.0000,  0.0000,  0.0000],
        [ 0.1628, -2.2033,  0.2626,  0.0000,  0.0000,  0.0000],
        [-0.3831,  0.7268, -0.0494,  0.0000,  0.0000,  0.0000],
        [ 0.5274, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8054,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0335, -1.7527, -2.9787,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8167, -0.5824,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1477, -0.5672, -1.9372,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9860, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8748, -2.4287, -2.2516,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  93
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0259, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9813, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0071, grad_fn=<AddBackward0>)
Gradients:
1.3044519424438477
Gradient before update: tensor(-1.7644)
Gradient after update: tensor(-1.7644)
current Learning Rate:  0.0015625
------------------------------------------------------------------------------------------------------------------
Iteration:  94
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0258, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9810, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0068, grad_fn=<AddBackward0>)
Gradients:
1.3276768922805786
Gradient before update: tensor(-1.7833)
Gradient after update: tensor(-1.7833)
current Learning Rate:  0.0015625
Total Loss:  tensor(495.0068, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7433,  0.4506,  2.7588,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2542, -0.8376,  0.0000,  0.0000,  0.0000],
        [ 0.4858,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5904, -2.2004, -1.3228,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5591, -1.4892, -3.4223,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1827, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3022,  1.0438, -3.4219,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7976,  0.8392, -1.9982,  0.0000,  0.0000,  0.0000],
        [-0.3572, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2236,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9050,  0.9163, -1.1133,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4654,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0981, -1.6146,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8214, -0.1551, -0.5790,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0770, -1.4307,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4719, -1.1455, -0.7578,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8450, -1.3117, -0.4927,  0.0000,  0.0000,  0.0000],
        [-1.4052,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7721,  1.0158,  1.3760,  0.0000,  0.0000,  0.0000],
        [ 1.1779, -1.4637,  1.3802,  0.0000,  0.0000,  0.0000],
        [-0.4811, -0.4063, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7764, -1.5017,  3.5022,  0.0000,  0.0000,  0.0000],
        [ 0.5234,  0.0224, -1.2471,  0.0000,  0.0000,  0.0000],
        [ 0.1626, -2.2034,  0.2626,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7268, -0.0495,  0.0000,  0.0000,  0.0000],
        [ 0.5274, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8054,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0335, -1.7527, -2.9786,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8167, -0.5824,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1478, -0.5673, -1.9371,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9860, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8750, -2.4282, -2.2516,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  95
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0258, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9807, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0065, grad_fn=<AddBackward0>)
Gradients:
1.3742576837539673
Gradient before update: tensor(-1.7947)
Gradient after update: tensor(-1.7947)
current Learning Rate:  0.0015625
------------------------------------------------------------------------------------------------------------------
Iteration:  96
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0258, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9806, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0063, grad_fn=<AddBackward0>)
Gradients:
1.4569259881973267
Gradient before update: tensor(-1.7764)
Gradient after update: tensor(-1.7764)
current Learning Rate:  0.0015625
Total Loss:  tensor(495.0063, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7434,  0.4506,  2.7588,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2541, -0.8376,  0.0000,  0.0000,  0.0000],
        [ 0.4858,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5905, -2.2010, -1.3229,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5592, -1.4893, -3.4222,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1827, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3020,  1.0439, -3.4219,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7976,  0.8392, -1.9982,  0.0000,  0.0000,  0.0000],
        [-0.3572, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2236,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9051,  0.9163, -1.1131,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4654,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0981, -1.6146,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8214, -0.1550, -0.5790,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0770, -1.4307,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4725, -1.1461, -0.7583,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8449, -1.3117, -0.4927,  0.0000,  0.0000,  0.0000],
        [-1.4052,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7721,  1.0158,  1.3760,  0.0000,  0.0000,  0.0000],
        [ 1.1779, -1.4637,  1.3802,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4063, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7761, -1.5020,  3.5021,  0.0000,  0.0000,  0.0000],
        [ 0.5233,  0.0224, -1.2471,  0.0000,  0.0000,  0.0000],
        [ 0.1625, -2.2035,  0.2626,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7268, -0.0496,  0.0000,  0.0000,  0.0000],
        [ 0.5274, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8054,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0335, -1.7527, -2.9786,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8167, -0.5824,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1479, -0.5674, -1.9370,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9860, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8751, -2.4278, -2.2516,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  97
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0257, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9805, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0062, grad_fn=<AddBackward0>)
Gradients:
1.5697788000106812
Gradient before update: tensor(-1.8375)
Gradient after update: tensor(-1.8375)
current Learning Rate:  0.0015625
------------------------------------------------------------------------------------------------------------------
Iteration:  98
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0257, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9803, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0060, grad_fn=<AddBackward0>)
Gradients:
1.6977148056030273
Gradient before update: tensor(-1.8179)
Gradient after update: tensor(-1.8179)
current Learning Rate:  0.0015625
Total Loss:  tensor(495.0060, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7434,  0.4506,  2.7588,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2540, -0.8375,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5906, -2.2015, -1.3230,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5592, -1.4894, -3.4221,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1827, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3018,  1.0440, -3.4219,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7976,  0.8392, -1.9982,  0.0000,  0.0000,  0.0000],
        [-0.3571, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9053,  0.9163, -1.1129,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4654,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0981, -1.6146,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8215, -0.1550, -0.5790,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0770, -1.4307,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4730, -1.1466, -0.7587,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8448, -1.3117, -0.4927,  0.0000,  0.0000,  0.0000],
        [-1.4052,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7721,  1.0159,  1.3760,  0.0000,  0.0000,  0.0000],
        [ 1.1779, -1.4637,  1.3802,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4064, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7759, -1.5022,  3.5019,  0.0000,  0.0000,  0.0000],
        [ 0.5233,  0.0224, -1.2471,  0.0000,  0.0000,  0.0000],
        [ 0.1624, -2.2036,  0.2626,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7268, -0.0497,  0.0000,  0.0000,  0.0000],
        [ 0.5274, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8054,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0335, -1.7527, -2.9786,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5824,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1480, -0.5675, -1.9369,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9860, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8753, -2.4274, -2.2516,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  99
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0256, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9803, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0059, grad_fn=<AddBackward0>)
Gradients:
1.8554364442825317
Gradient before update: tensor(-1.8205)
Gradient after update: tensor(-1.8205)
current Learning Rate:  0.0015625
------------------------------------------------------------------------------------------------------------------
Iteration:  100
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0256, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9802, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0058, grad_fn=<AddBackward0>)
Gradients:
2.0554091930389404
Gradient before update: tensor(-1.8498)
Gradient after update: tensor(-1.8498)
current Learning Rate:  0.0015625
Total Loss:  tensor(495.0058, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7434,  0.4507,  2.7588,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2540, -0.8375,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5907, -2.2018, -1.3230,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5592, -1.4895, -3.4220,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1827, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3017,  1.0441, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7976,  0.8392, -1.9982,  0.0000,  0.0000,  0.0000],
        [-0.3571, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9055,  0.9163, -1.1127,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4655,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0981, -1.6146,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8215, -0.1550, -0.5790,  0.0000,  0.0000,  0.0000],
        [-0.5321,  0.0770, -1.4307,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4735, -1.1469, -0.7591,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8447, -1.3117, -0.4926,  0.0000,  0.0000,  0.0000],
        [-1.4052,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7721,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1779, -1.4638,  1.3802,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4064, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7757, -1.5024,  3.5018,  0.0000,  0.0000,  0.0000],
        [ 0.5232,  0.0224, -1.2471,  0.0000,  0.0000,  0.0000],
        [ 0.1624, -2.2036,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0498,  0.0000,  0.0000,  0.0000],
        [ 0.5274, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8054,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0335, -1.7527, -2.9786,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5824,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1481, -0.5677, -1.9367,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9860, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8754, -2.4271, -2.2516,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  101
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0255, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9802, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0057, grad_fn=<AddBackward0>)
Gradients:
2.275623321533203
Gradient before update: tensor(-1.8344)
Gradient after update: tensor(-1.8344)
current Learning Rate:  0.0015625
------------------------------------------------------------------------------------------------------------------
Iteration:  102
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0255, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9803, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0058, grad_fn=<AddBackward0>)
Gradients:
2.5272934436798096
Gradient before update: tensor(-1.8065)
Gradient after update: tensor(-1.8065)
current Learning Rate:  0.0015625
Total Loss:  tensor(495.0058, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7434,  0.4507,  2.7587,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2540, -0.8375,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5908, -2.2022, -1.3231,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4896, -3.4220,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1827, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3016,  1.0441, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7976,  0.8392, -1.9981,  0.0000,  0.0000,  0.0000],
        [-0.3571, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9057,  0.9163, -1.1126,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4655,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0981, -1.6146,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8215, -0.1550, -0.5790,  0.0000,  0.0000,  0.0000],
        [-0.5321,  0.0770, -1.4307,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4738, -1.1472, -0.7594,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8447, -1.3116, -0.4926,  0.0000,  0.0000,  0.0000],
        [-1.4052,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7721,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1779, -1.4638,  1.3802,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4064, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7756, -1.5026,  3.5017,  0.0000,  0.0000,  0.0000],
        [ 0.5232,  0.0224, -1.2471,  0.0000,  0.0000,  0.0000],
        [ 0.1623, -2.2037,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0499,  0.0000,  0.0000,  0.0000],
        [ 0.5274, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0335, -1.7527, -2.9786,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1483, -0.5679, -1.9365,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9860, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8755, -2.4269, -2.2516,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  103
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0254, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9803, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0058, grad_fn=<AddBackward0>)
Gradients:
2.8071677684783936
Gradient before update: tensor(-1.7808)
Gradient after update: tensor(-1.7808)
current Learning Rate:  0.0015625
------------------------------------------------------------------------------------------------------------------
Iteration:  104
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0254, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9804, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0058, grad_fn=<AddBackward0>)
Gradients:
3.1117007732391357
Gradient before update: tensor(-1.7495)
Gradient after update: tensor(-1.7495)
current Learning Rate:  0.0015625
Total Loss:  tensor(495.0058, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7435,  0.4507,  2.7587,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8375,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5908, -2.2024, -1.3231,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4897, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1827, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3015,  1.0442, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8392, -1.9981,  0.0000,  0.0000,  0.0000],
        [-0.3571, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9059,  0.9163, -1.1124,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4656,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1550, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5321,  0.0770, -1.4307,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4741, -1.1475, -0.7596,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8446, -1.3116, -0.4926,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7721,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1779, -1.4638,  1.3802,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4064, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5016,  0.0000,  0.0000,  0.0000],
        [ 0.5232,  0.0224, -1.2471,  0.0000,  0.0000,  0.0000],
        [ 0.1623, -2.2037,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0500,  0.0000,  0.0000,  0.0000],
        [ 0.5274, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0335, -1.7527, -2.9785,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1485, -0.5681, -1.9362,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9860, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8756, -2.4267, -2.2516,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  105
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0253, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9804, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0057, grad_fn=<AddBackward0>)
Gradients:
3.4352786540985107
Gradient before update: tensor(-1.7135)
Gradient after update: tensor(-1.7135)
current Learning Rate:  0.00078125
------------------------------------------------------------------------------------------------------------------
Iteration:  106
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0253, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9805, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0057, grad_fn=<AddBackward0>)
Gradients:
3.771764039993286
Gradient before update: tensor(-1.6739)
Gradient after update: tensor(-1.6739)
current Learning Rate:  0.00078125
Total Loss:  tensor(495.0057, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7435,  0.4507,  2.7587,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8375,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2026, -1.3232,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4897, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1827, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3014,  1.0442, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8392, -1.9981,  0.0000,  0.0000,  0.0000],
        [-0.3571, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9060,  0.9163, -1.1122,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4656,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5321,  0.0770, -1.4307,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4743, -1.1477, -0.7598,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8446, -1.3116, -0.4926,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7721,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1779, -1.4638,  1.3802,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4064, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5027,  3.5016,  0.0000,  0.0000,  0.0000],
        [ 0.5232,  0.0224, -1.2471,  0.0000,  0.0000,  0.0000],
        [ 0.1622, -2.2037,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0500,  0.0000,  0.0000,  0.0000],
        [ 0.5274, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0335, -1.7527, -2.9785,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1487, -0.5683, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9860, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8756, -2.4265, -2.2516,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  107
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0253, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9805, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0057, grad_fn=<AddBackward0>)
Gradients:
3.9350175857543945
Gradient before update: tensor(-1.6327)
Gradient after update: tensor(-1.6327)
current Learning Rate:  0.00078125
------------------------------------------------------------------------------------------------------------------
Iteration:  108
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0252, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9805, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0058, grad_fn=<AddBackward0>)
Gradients:
4.088501453399658
Gradient before update: tensor(-1.6130)
Gradient after update: tensor(-1.6130)
current Learning Rate:  0.00078125
Total Loss:  tensor(495.0058, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7435,  0.4507,  2.7587,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2027, -1.3232,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4897, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1827, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3014,  1.0442, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8392, -1.9981,  0.0000,  0.0000,  0.0000],
        [-0.3571, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9061,  0.9163, -1.1121,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4656,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5321,  0.0770, -1.4307,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4744, -1.1477, -0.7598,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8446, -1.3116, -0.4926,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7721,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1779, -1.4638,  1.3802,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4064, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5016,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2471,  0.0000,  0.0000,  0.0000],
        [ 0.1622, -2.2037,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0501,  0.0000,  0.0000,  0.0000],
        [ 0.5274, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0335, -1.7527, -2.9785,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1488, -0.5685, -1.9359,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9860, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8756, -2.4265, -2.2516,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  109
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0252, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9806, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0058, grad_fn=<AddBackward0>)
Gradients:
4.2276291847229
Gradient before update: tensor(-1.5658)
Gradient after update: tensor(-1.5658)
current Learning Rate:  0.00078125
------------------------------------------------------------------------------------------------------------------
Iteration:  110
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0252, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9806, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0057, grad_fn=<AddBackward0>)
Gradients:
4.354250431060791
Gradient before update: tensor(-1.5485)
Gradient after update: tensor(-1.5485)
current Learning Rate:  0.00078125
Total Loss:  tensor(495.0057, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7435,  0.4507,  2.7587,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2028, -1.3232,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4897, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1827, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3014,  1.0442, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8392, -1.9981,  0.0000,  0.0000,  0.0000],
        [-0.3571, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9062,  0.9163, -1.1120,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4656,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5321,  0.0771, -1.4307,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4744, -1.1478, -0.7599,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8446, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7721,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1779, -1.4638,  1.3802,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4064, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5016,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2471,  0.0000,  0.0000,  0.0000],
        [ 0.1622, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0501,  0.0000,  0.0000,  0.0000],
        [ 0.5274, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0335, -1.7527, -2.9785,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1489, -0.5686, -1.9358,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9860, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4264, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  111
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0252, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9806, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0058, grad_fn=<AddBackward0>)
Gradients:
4.465830326080322
Gradient before update: tensor(-1.5327)
Gradient after update: tensor(-1.5327)
current Learning Rate:  0.00078125
------------------------------------------------------------------------------------------------------------------
Iteration:  112
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0251, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9806, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0057, grad_fn=<AddBackward0>)
Gradients:
4.5628461837768555
Gradient before update: tensor(-1.5185)
Gradient after update: tensor(-1.5185)
current Learning Rate:  0.00078125
Total Loss:  tensor(495.0057, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7435,  0.4507,  2.7587,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2028, -1.3232,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4897, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1827, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0442, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9981,  0.0000,  0.0000,  0.0000],
        [-0.3570, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9063,  0.9163, -1.1119,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4656,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5321,  0.0771, -1.4307,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4745, -1.1479, -0.7599,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8446, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7721,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1779, -1.4638,  1.3802,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4064, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1622, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0502,  0.0000,  0.0000,  0.0000],
        [ 0.5274, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0335, -1.7527, -2.9785,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1490, -0.5688, -1.9356,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9860, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4264, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  113
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0251, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9806, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0057, grad_fn=<AddBackward0>)
Gradients:
4.643822193145752
Gradient before update: tensor(-1.5062)
Gradient after update: tensor(-1.5062)
current Learning Rate:  0.00078125
------------------------------------------------------------------------------------------------------------------
Iteration:  114
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0251, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9806, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0057, grad_fn=<AddBackward0>)
Gradients:
4.710202693939209
Gradient before update: tensor(-1.4958)
Gradient after update: tensor(-1.4958)
current Learning Rate:  0.00078125
Total Loss:  tensor(495.0057, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7435,  0.4507,  2.7587,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2029, -1.3232,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1827, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0442, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9981,  0.0000,  0.0000,  0.0000],
        [-0.3570, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9064,  0.9163, -1.1118,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4657,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5321,  0.0771, -1.4307,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4746, -1.1479, -0.7600,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7721,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1779, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4064, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1622, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0502,  0.0000,  0.0000,  0.0000],
        [ 0.5274, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0335, -1.7527, -2.9785,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1491, -0.5689, -1.9355,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9860, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4263, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  115
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0251, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9806, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0056, grad_fn=<AddBackward0>)
Gradients:
4.763378620147705
Gradient before update: tensor(-1.4928)
Gradient after update: tensor(-1.4928)
current Learning Rate:  0.00078125
------------------------------------------------------------------------------------------------------------------
Iteration:  116
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0251, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9806, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0056, grad_fn=<AddBackward0>)
Gradients:
4.803369522094727
Gradient before update: tensor(-1.5079)
Gradient after update: tensor(-1.5079)
current Learning Rate:  0.00078125
Total Loss:  tensor(495.0056, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7435,  0.4507,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2029, -1.3232,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9980,  0.0000,  0.0000,  0.0000],
        [-0.3570, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9065,  0.9163, -1.1117,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4657,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5321,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4746, -1.1479, -0.7600,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1779, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4064, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1622, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0503,  0.0000,  0.0000,  0.0000],
        [ 0.5274, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9785,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1493, -0.5691, -1.9353,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9860, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4263, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  117
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0250, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9805, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0055, grad_fn=<AddBackward0>)
Gradients:
4.827422142028809
Gradient before update: tensor(-1.4953)
Gradient after update: tensor(-1.4953)
current Learning Rate:  0.00078125
------------------------------------------------------------------------------------------------------------------
Iteration:  118
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0250, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9805, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0055, grad_fn=<AddBackward0>)
Gradients:
4.8389177322387695
Gradient before update: tensor(-1.4846)
Gradient after update: tensor(-1.4846)
current Learning Rate:  0.00078125
Total Loss:  tensor(495.0055, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7435,  0.4507,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2029, -1.3232,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9980,  0.0000,  0.0000,  0.0000],
        [-0.3570, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9066,  0.9163, -1.1116,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4657,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5321,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4746, -1.1480, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4064, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1622, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0503,  0.0000,  0.0000,  0.0000],
        [ 0.5274, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9785,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1494, -0.5693, -1.9353,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9860, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4263, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  119
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0250, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9804, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0054, grad_fn=<AddBackward0>)
Gradients:
4.839234828948975
Gradient before update: tensor(-1.4761)
Gradient after update: tensor(-1.4761)
current Learning Rate:  0.00078125
------------------------------------------------------------------------------------------------------------------
Iteration:  120
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0250, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9804, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0054, grad_fn=<AddBackward0>)
Gradients:
4.8293375968933105
Gradient before update: tensor(-1.4698)
Gradient after update: tensor(-1.4698)
current Learning Rate:  0.000390625
Total Loss:  tensor(495.0054, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4507,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3232,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9980,  0.0000,  0.0000,  0.0000],
        [-0.3570, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9067,  0.9163, -1.1115,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4657,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1480, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1622, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0504,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9785,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1496, -0.5695, -1.9353,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9860, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4263, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  121
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0249, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9804, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0053, grad_fn=<AddBackward0>)
Gradients:
4.810276031494141
Gradient before update: tensor(-1.4657)
Gradient after update: tensor(-1.4657)
current Learning Rate:  0.000390625
------------------------------------------------------------------------------------------------------------------
Iteration:  122
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0249, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9803, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0053, grad_fn=<AddBackward0>)
Gradients:
4.796323299407959
Gradient before update: tensor(-1.4645)
Gradient after update: tensor(-1.4645)
current Learning Rate:  0.000390625
Total Loss:  tensor(495.0053, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4507,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3232,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9980,  0.0000,  0.0000,  0.0000],
        [-0.3570, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9068,  0.9163, -1.1115,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4657,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1480, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0504,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9785,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1496, -0.5696, -1.9353,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9860, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  123
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0249, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9803, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0053, grad_fn=<AddBackward0>)
Gradients:
4.779083728790283
Gradient before update: tensor(-1.4640)
Gradient after update: tensor(-1.4640)
current Learning Rate:  0.000390625
------------------------------------------------------------------------------------------------------------------
Iteration:  124
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0249, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9803, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0052, grad_fn=<AddBackward0>)
Gradients:
4.7585859298706055
Gradient before update: tensor(-1.4640)
Gradient after update: tensor(-1.4640)
current Learning Rate:  0.000390625
Total Loss:  tensor(495.0052, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4507,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3232,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2892,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9980,  0.0000,  0.0000,  0.0000],
        [-0.3570, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9068,  0.9163, -1.1114,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4657,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1480, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0504,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9785,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1497, -0.5697, -1.9353,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9860, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  125
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0249, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9803, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0052, grad_fn=<AddBackward0>)
Gradients:
4.7351603507995605
Gradient before update: tensor(-1.4647)
Gradient after update: tensor(-1.4647)
current Learning Rate:  0.000390625
------------------------------------------------------------------------------------------------------------------
Iteration:  126
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0249, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9803, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0052, grad_fn=<AddBackward0>)
Gradients:
4.7090983390808105
Gradient before update: tensor(-1.4659)
Gradient after update: tensor(-1.4659)
current Learning Rate:  0.000390625
Total Loss:  tensor(495.0052, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4507,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3232,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9980,  0.0000,  0.0000,  0.0000],
        [-0.3570, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9069,  0.9163, -1.1114,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4657,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1480, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0505,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9785,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1498, -0.5697, -1.9354,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9860, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  127
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0249, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9803, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0051, grad_fn=<AddBackward0>)
Gradients:
4.68115234375
Gradient before update: tensor(-1.4676)
Gradient after update: tensor(-1.4676)
current Learning Rate:  0.000390625
------------------------------------------------------------------------------------------------------------------
Iteration:  128
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0249, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9802, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0051, grad_fn=<AddBackward0>)
Gradients:
4.651195049285889
Gradient before update: tensor(-1.4697)
Gradient after update: tensor(-1.4697)
current Learning Rate:  0.000390625
Total Loss:  tensor(495.0051, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4507,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9980,  0.0000,  0.0000,  0.0000],
        [-0.3570, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9069,  0.9163, -1.1113,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4658,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1480, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0505,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9785,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1499, -0.5698, -1.9354,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9860, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  129
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0249, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9802, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0050, grad_fn=<AddBackward0>)
Gradients:
4.61969518661499
Gradient before update: tensor(-1.4723)
Gradient after update: tensor(-1.4723)
current Learning Rate:  0.000390625
------------------------------------------------------------------------------------------------------------------
Iteration:  130
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0248, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9802, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0050, grad_fn=<AddBackward0>)
Gradients:
4.586948394775391
Gradient before update: tensor(-1.4750)
Gradient after update: tensor(-1.4750)
current Learning Rate:  0.000390625
Total Loss:  tensor(495.0050, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4507,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9980,  0.0000,  0.0000,  0.0000],
        [-0.3570, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9070,  0.9163, -1.1113,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4658,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1480, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0505,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9785,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1499, -0.5699, -1.9355,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  131
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0248, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9801, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0050, grad_fn=<AddBackward0>)
Gradients:
4.552783012390137
Gradient before update: tensor(-1.4782)
Gradient after update: tensor(-1.4782)
current Learning Rate:  0.000390625
------------------------------------------------------------------------------------------------------------------
Iteration:  132
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0248, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9801, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0049, grad_fn=<AddBackward0>)
Gradients:
4.51792049407959
Gradient before update: tensor(-1.4815)
Gradient after update: tensor(-1.4815)
current Learning Rate:  0.000390625
Total Loss:  tensor(495.0049, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4507,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9980,  0.0000,  0.0000,  0.0000],
        [-0.3570, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9070,  0.9163, -1.1112,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4658,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1480, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0505,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1500, -0.5700, -1.9355,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  133
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0248, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9800, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0049, grad_fn=<AddBackward0>)
Gradients:
4.482609748840332
Gradient before update: tensor(-1.4851)
Gradient after update: tensor(-1.4851)
current Learning Rate:  0.000390625
------------------------------------------------------------------------------------------------------------------
Iteration:  134
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0248, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9800, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0048, grad_fn=<AddBackward0>)
Gradients:
4.446433067321777
Gradient before update: tensor(-1.4888)
Gradient after update: tensor(-1.4888)
current Learning Rate:  0.000390625
Total Loss:  tensor(495.0048, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4507,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9980,  0.0000,  0.0000,  0.0000],
        [-0.3570, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9070,  0.9163, -1.1112,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4658,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1480, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0506,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1501, -0.5701, -1.9356,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  135
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0248, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9800, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0048, grad_fn=<AddBackward0>)
Gradients:
4.409890651702881
Gradient before update: tensor(-1.4927)
Gradient after update: tensor(-1.4927)
current Learning Rate:  0.0001953125
------------------------------------------------------------------------------------------------------------------
Iteration:  136
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0248, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9800, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0048, grad_fn=<AddBackward0>)
Gradients:
4.373174667358398
Gradient before update: tensor(-1.4968)
Gradient after update: tensor(-1.4968)
current Learning Rate:  0.0001953125
Total Loss:  tensor(495.0048, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4507,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9980,  0.0000,  0.0000,  0.0000],
        [-0.3570, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9071,  0.9163, -1.1112,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4658,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1480, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0506,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1501, -0.5701, -1.9356,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  137
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0248, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9799, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0047, grad_fn=<AddBackward0>)
Gradients:
4.354494571685791
Gradient before update: tensor(-1.4989)
Gradient after update: tensor(-1.4989)
current Learning Rate:  0.0001953125
------------------------------------------------------------------------------------------------------------------
Iteration:  138
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0248, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9799, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0047, grad_fn=<AddBackward0>)
Gradients:
4.3361334800720215
Gradient before update: tensor(-1.5009)
Gradient after update: tensor(-1.5009)
current Learning Rate:  0.0001953125
Total Loss:  tensor(495.0047, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4507,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9980,  0.0000,  0.0000,  0.0000],
        [-0.3570, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9071,  0.9163, -1.1111,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4658,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0506,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1501, -0.5702, -1.9357,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  139
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0248, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9799, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0046, grad_fn=<AddBackward0>)
Gradients:
4.317493438720703
Gradient before update: tensor(-1.5031)
Gradient after update: tensor(-1.5031)
current Learning Rate:  0.0001953125
------------------------------------------------------------------------------------------------------------------
Iteration:  140
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0248, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9799, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0046, grad_fn=<AddBackward0>)
Gradients:
4.298361301422119
Gradient before update: tensor(-1.5053)
Gradient after update: tensor(-1.5053)
current Learning Rate:  0.0001953125
Total Loss:  tensor(495.0046, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4507,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9980,  0.0000,  0.0000,  0.0000],
        [-0.3570, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9071,  0.9163, -1.1111,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4658,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0506,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1502, -0.5702, -1.9357,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  141
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0247, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9799, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0046, grad_fn=<AddBackward0>)
Gradients:
4.27957820892334
Gradient before update: tensor(-1.5076)
Gradient after update: tensor(-1.5076)
current Learning Rate:  0.0001953125
------------------------------------------------------------------------------------------------------------------
Iteration:  142
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0247, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9799, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0046, grad_fn=<AddBackward0>)
Gradients:
4.2603302001953125
Gradient before update: tensor(-1.5100)
Gradient after update: tensor(-1.5100)
current Learning Rate:  0.0001953125
Total Loss:  tensor(495.0046, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4507,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9980,  0.0000,  0.0000,  0.0000],
        [-0.3570, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9072,  0.9163, -1.1111,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4658,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0506,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1502, -0.5702, -1.9357,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  143
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0247, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9798, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0046, grad_fn=<AddBackward0>)
Gradients:
4.241418361663818
Gradient before update: tensor(-1.5123)
Gradient after update: tensor(-1.5123)
current Learning Rate:  0.0001953125
------------------------------------------------------------------------------------------------------------------
Iteration:  144
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0247, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9798, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0045, grad_fn=<AddBackward0>)
Gradients:
4.222842693328857
Gradient before update: tensor(-1.5146)
Gradient after update: tensor(-1.5146)
current Learning Rate:  0.0001953125
Total Loss:  tensor(495.0045, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4507,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9980,  0.0000,  0.0000,  0.0000],
        [-0.3570, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9072,  0.9163, -1.1110,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4658,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0506,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1502, -0.5702, -1.9358,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  145
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0247, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9798, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0045, grad_fn=<AddBackward0>)
Gradients:
4.203981399536133
Gradient before update: tensor(-1.5169)
Gradient after update: tensor(-1.5169)
current Learning Rate:  0.0001953125
------------------------------------------------------------------------------------------------------------------
Iteration:  146
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0247, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9798, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0045, grad_fn=<AddBackward0>)
Gradients:
4.184676170349121
Gradient before update: tensor(-1.5192)
Gradient after update: tensor(-1.5192)
current Learning Rate:  0.0001953125
Total Loss:  tensor(495.0045, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4507,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9980,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9072,  0.9163, -1.1110,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4658,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0506,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1502, -0.5703, -1.9358,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  147
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0247, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9798, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0045, grad_fn=<AddBackward0>)
Gradients:
4.165530204772949
Gradient before update: tensor(-1.5216)
Gradient after update: tensor(-1.5216)
current Learning Rate:  0.0001953125
------------------------------------------------------------------------------------------------------------------
Iteration:  148
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0247, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9798, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0045, grad_fn=<AddBackward0>)
Gradients:
4.146325588226318
Gradient before update: tensor(-1.5240)
Gradient after update: tensor(-1.5240)
current Learning Rate:  0.0001953125
Total Loss:  tensor(495.0045, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4507,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9980,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9072,  0.9163, -1.1110,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4658,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0507,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1503, -0.5703, -1.9358,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  149
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0247, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9797, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0044, grad_fn=<AddBackward0>)
Gradients:
4.127451419830322
Gradient before update: tensor(-1.5264)
Gradient after update: tensor(-1.5264)
current Learning Rate:  0.0001953125
------------------------------------------------------------------------------------------------------------------
Iteration:  150
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0247, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9797, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0044, grad_fn=<AddBackward0>)
Gradients:
4.108534812927246
Gradient before update: tensor(-1.5288)
Gradient after update: tensor(-1.5288)
current Learning Rate:  9.765625e-05
Total Loss:  tensor(495.0044, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4507,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9980,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9073,  0.9163, -1.1110,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4658,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0507,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1503, -0.5703, -1.9358,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  151
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0247, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9797, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0044, grad_fn=<AddBackward0>)
Gradients:
4.089942932128906
Gradient before update: tensor(-1.5312)
Gradient after update: tensor(-1.5312)
current Learning Rate:  9.765625e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  152
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0247, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9797, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0044, grad_fn=<AddBackward0>)
Gradients:
4.080793380737305
Gradient before update: tensor(-1.5323)
Gradient after update: tensor(-1.5323)
current Learning Rate:  9.765625e-05
Total Loss:  tensor(495.0044, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4507,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9980,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9073,  0.9163, -1.1110,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4658,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0507,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1503, -0.5703, -1.9359,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  153
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0247, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9797, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0044, grad_fn=<AddBackward0>)
Gradients:
4.071675777435303
Gradient before update: tensor(-1.5334)
Gradient after update: tensor(-1.5334)
current Learning Rate:  9.765625e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  154
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0247, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9797, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0044, grad_fn=<AddBackward0>)
Gradients:
4.062025547027588
Gradient before update: tensor(-1.5346)
Gradient after update: tensor(-1.5346)
current Learning Rate:  9.765625e-05
Total Loss:  tensor(495.0044, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4507,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9980,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9073,  0.9163, -1.1109,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4658,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0507,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1503, -0.5704, -1.9359,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  155
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0247, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9797, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0044, grad_fn=<AddBackward0>)
Gradients:
4.052608966827393
Gradient before update: tensor(-1.5358)
Gradient after update: tensor(-1.5358)
current Learning Rate:  9.765625e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  156
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0247, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9797, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0044, grad_fn=<AddBackward0>)
Gradients:
4.043041706085205
Gradient before update: tensor(-1.5371)
Gradient after update: tensor(-1.5371)
current Learning Rate:  9.765625e-05
Total Loss:  tensor(495.0044, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4507,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9073,  0.9163, -1.1109,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4658,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0507,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1503, -0.5704, -1.9359,  0.0000,  0.0000,  0.0000],
        [-0.6713, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  157
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0247, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9797, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0044, grad_fn=<AddBackward0>)
Gradients:
4.033520221710205
Gradient before update: tensor(-1.5383)
Gradient after update: tensor(-1.5383)
current Learning Rate:  9.765625e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  158
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0247, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9797, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0043, grad_fn=<AddBackward0>)
Gradients:
4.0242109298706055
Gradient before update: tensor(-1.5395)
Gradient after update: tensor(-1.5395)
current Learning Rate:  9.765625e-05
Total Loss:  tensor(495.0043, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4507,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9073,  0.9163, -1.1109,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4658,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0507,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1503, -0.5704, -1.9359,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  159
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0247, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9797, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0043, grad_fn=<AddBackward0>)
Gradients:
4.014746189117432
Gradient before update: tensor(-1.5407)
Gradient after update: tensor(-1.5407)
current Learning Rate:  9.765625e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  160
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0247, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9797, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0043, grad_fn=<AddBackward0>)
Gradients:
4.005520343780518
Gradient before update: tensor(-1.5419)
Gradient after update: tensor(-1.5419)
current Learning Rate:  9.765625e-05
Total Loss:  tensor(495.0043, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4507,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9073,  0.9163, -1.1109,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4658,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5028,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0507,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1503, -0.5704, -1.9359,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  161
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0247, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9797, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0043, grad_fn=<AddBackward0>)
Gradients:
3.996131420135498
Gradient before update: tensor(-1.5431)
Gradient after update: tensor(-1.5431)
current Learning Rate:  9.765625e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  162
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0247, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9797, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0043, grad_fn=<AddBackward0>)
Gradients:
3.986776351928711
Gradient before update: tensor(-1.5443)
Gradient after update: tensor(-1.5443)
current Learning Rate:  9.765625e-05
Total Loss:  tensor(495.0043, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9073,  0.9163, -1.1109,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0507,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1503, -0.5704, -1.9359,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  163
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0247, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0043, grad_fn=<AddBackward0>)
Gradients:
3.9774773120880127
Gradient before update: tensor(-1.5456)
Gradient after update: tensor(-1.5456)
current Learning Rate:  9.765625e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  164
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0043, grad_fn=<AddBackward0>)
Gradients:
3.968374729156494
Gradient before update: tensor(-1.5467)
Gradient after update: tensor(-1.5467)
current Learning Rate:  9.765625e-05
Total Loss:  tensor(495.0043, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9074,  0.9163, -1.1109,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0507,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1503, -0.5704, -1.9359,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  165
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0043, grad_fn=<AddBackward0>)
Gradients:
3.9591407775878906
Gradient before update: tensor(-1.5480)
Gradient after update: tensor(-1.5480)
current Learning Rate:  4.8828125e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  166
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.9501125812530518
Gradient before update: tensor(-1.5491)
Gradient after update: tensor(-1.5491)
current Learning Rate:  4.8828125e-05
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9074,  0.9163, -1.1109,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4692,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0507,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5704, -1.9359,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  167
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.9456889629364014
Gradient before update: tensor(-1.5497)
Gradient after update: tensor(-1.5497)
current Learning Rate:  4.8828125e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  168
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.9412882328033447
Gradient before update: tensor(-1.5503)
Gradient after update: tensor(-1.5503)
current Learning Rate:  4.8828125e-05
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9074,  0.9163, -1.1109,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0507,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5704, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  169
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.9365413188934326
Gradient before update: tensor(-1.5509)
Gradient after update: tensor(-1.5509)
current Learning Rate:  4.8828125e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  170
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.9317879676818848
Gradient before update: tensor(-1.5515)
Gradient after update: tensor(-1.5515)
current Learning Rate:  4.8828125e-05
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9074,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0507,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5704, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  171
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.9272284507751465
Gradient before update: tensor(-1.5520)
Gradient after update: tensor(-1.5520)
current Learning Rate:  4.8828125e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  172
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.922508716583252
Gradient before update: tensor(-1.5527)
Gradient after update: tensor(-1.5527)
current Learning Rate:  4.8828125e-05
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9074,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0507,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5704, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  173
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.9179608821868896
Gradient before update: tensor(-1.5532)
Gradient after update: tensor(-1.5532)
current Learning Rate:  4.8828125e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  174
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.913257360458374
Gradient before update: tensor(-1.5539)
Gradient after update: tensor(-1.5539)
current Learning Rate:  4.8828125e-05
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3910,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9074,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0507,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  175
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.9085583686828613
Gradient before update: tensor(-1.5544)
Gradient after update: tensor(-1.5544)
current Learning Rate:  4.8828125e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  176
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.9038705825805664
Gradient before update: tensor(-1.5551)
Gradient after update: tensor(-1.5551)
current Learning Rate:  4.8828125e-05
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9074,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0507,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  177
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.899365186691284
Gradient before update: tensor(-1.5556)
Gradient after update: tensor(-1.5556)
current Learning Rate:  4.8828125e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  178
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8948750495910645
Gradient before update: tensor(-1.5562)
Gradient after update: tensor(-1.5562)
current Learning Rate:  4.8828125e-05
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9074,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7754, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  179
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8902108669281006
Gradient before update: tensor(-1.5568)
Gradient after update: tensor(-1.5568)
current Learning Rate:  4.8828125e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  180
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8857367038726807
Gradient before update: tensor(-1.5574)
Gradient after update: tensor(-1.5574)
current Learning Rate:  2.44140625e-05
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9074,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  181
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8809216022491455
Gradient before update: tensor(-1.5580)
Gradient after update: tensor(-1.5580)
current Learning Rate:  2.44140625e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  182
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8792026042938232
Gradient before update: tensor(-1.5582)
Gradient after update: tensor(-1.5582)
current Learning Rate:  2.44140625e-05
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9074,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  183
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8771419525146484
Gradient before update: tensor(-1.5585)
Gradient after update: tensor(-1.5585)
current Learning Rate:  2.44140625e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  184
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8752524852752686
Gradient before update: tensor(-1.5588)
Gradient after update: tensor(-1.5588)
current Learning Rate:  2.44140625e-05
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0558, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9074,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  185
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8733739852905273
Gradient before update: tensor(-1.5590)
Gradient after update: tensor(-1.5590)
current Learning Rate:  2.44140625e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  186
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.871324062347412
Gradient before update: tensor(-1.5593)
Gradient after update: tensor(-1.5593)
current Learning Rate:  2.44140625e-05
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9074,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  187
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8694353103637695
Gradient before update: tensor(-1.5595)
Gradient after update: tensor(-1.5595)
current Learning Rate:  2.44140625e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  188
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.867560625076294
Gradient before update: tensor(-1.5598)
Gradient after update: tensor(-1.5598)
current Learning Rate:  2.44140625e-05
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9074,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  189
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.865682363510132
Gradient before update: tensor(-1.5600)
Gradient after update: tensor(-1.5600)
current Learning Rate:  2.44140625e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  190
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.863291025161743
Gradient before update: tensor(-1.5603)
Gradient after update: tensor(-1.5603)
current Learning Rate:  2.44140625e-05
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9074,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  191
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8609113693237305
Gradient before update: tensor(-1.5606)
Gradient after update: tensor(-1.5606)
current Learning Rate:  2.44140625e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  192
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.858692169189453
Gradient before update: tensor(-1.5609)
Gradient after update: tensor(-1.5609)
current Learning Rate:  2.44140625e-05
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9074,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  193
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8563127517700195
Gradient before update: tensor(-1.5613)
Gradient after update: tensor(-1.5613)
current Learning Rate:  2.44140625e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  194
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8539373874664307
Gradient before update: tensor(-1.5616)
Gradient after update: tensor(-1.5616)
current Learning Rate:  2.44140625e-05
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9074,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  195
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.851558208465576
Gradient before update: tensor(-1.5619)
Gradient after update: tensor(-1.5619)
current Learning Rate:  1.220703125e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  196
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.849186897277832
Gradient before update: tensor(-1.5622)
Gradient after update: tensor(-1.5622)
current Learning Rate:  1.220703125e-05
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9074,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  197
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8481757640838623
Gradient before update: tensor(-1.5624)
Gradient after update: tensor(-1.5624)
current Learning Rate:  1.220703125e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  198
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.847320556640625
Gradient before update: tensor(-1.5625)
Gradient after update: tensor(-1.5625)
current Learning Rate:  1.220703125e-05
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9074,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  199
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8463094234466553
Gradient before update: tensor(-1.5626)
Gradient after update: tensor(-1.5626)
current Learning Rate:  1.220703125e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  200
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8454651832580566
Gradient before update: tensor(-1.5627)
Gradient after update: tensor(-1.5627)
current Learning Rate:  1.220703125e-05
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9074,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  201
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.844454050064087
Gradient before update: tensor(-1.5629)
Gradient after update: tensor(-1.5629)
current Learning Rate:  1.220703125e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  202
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8436028957366943
Gradient before update: tensor(-1.5630)
Gradient after update: tensor(-1.5630)
current Learning Rate:  1.220703125e-05
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  203
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.842421531677246
Gradient before update: tensor(-1.5631)
Gradient after update: tensor(-1.5631)
current Learning Rate:  1.220703125e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  204
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8415777683258057
Gradient before update: tensor(-1.5632)
Gradient after update: tensor(-1.5632)
current Learning Rate:  1.220703125e-05
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  205
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.840566873550415
Gradient before update: tensor(-1.5634)
Gradient after update: tensor(-1.5634)
current Learning Rate:  1.220703125e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  206
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8397226333618164
Gradient before update: tensor(-1.5635)
Gradient after update: tensor(-1.5635)
current Learning Rate:  1.220703125e-05
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  207
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8387081623077393
Gradient before update: tensor(-1.5636)
Gradient after update: tensor(-1.5636)
current Learning Rate:  1.220703125e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  208
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8378679752349854
Gradient before update: tensor(-1.5637)
Gradient after update: tensor(-1.5637)
current Learning Rate:  1.220703125e-05
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  209
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8368537425994873
Gradient before update: tensor(-1.5639)
Gradient after update: tensor(-1.5639)
current Learning Rate:  1.220703125e-05
------------------------------------------------------------------------------------------------------------------
Iteration:  210
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8358428478240967
Gradient before update: tensor(-1.5640)
Gradient after update: tensor(-1.5640)
current Learning Rate:  6.103515625e-06
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  211
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.834998846054077
Gradient before update: tensor(-1.5641)
Gradient after update: tensor(-1.5641)
current Learning Rate:  6.103515625e-06
------------------------------------------------------------------------------------------------------------------
Iteration:  212
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8341598510742188
Gradient before update: tensor(-1.5642)
Gradient after update: tensor(-1.5642)
current Learning Rate:  6.103515625e-06
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  213
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.833650588989258
Gradient before update: tensor(-1.5643)
Gradient after update: tensor(-1.5643)
current Learning Rate:  6.103515625e-06
------------------------------------------------------------------------------------------------------------------
Iteration:  214
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.832815170288086
Gradient before update: tensor(-1.5644)
Gradient after update: tensor(-1.5644)
current Learning Rate:  6.103515625e-06
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  215
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.832139015197754
Gradient before update: tensor(-1.5645)
Gradient after update: tensor(-1.5645)
current Learning Rate:  6.103515625e-06
------------------------------------------------------------------------------------------------------------------
Iteration:  216
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8314738273620605
Gradient before update: tensor(-1.5646)
Gradient after update: tensor(-1.5646)
current Learning Rate:  6.103515625e-06
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  217
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8307907581329346
Gradient before update: tensor(-1.5647)
Gradient after update: tensor(-1.5647)
current Learning Rate:  6.103515625e-06
------------------------------------------------------------------------------------------------------------------
Iteration:  218
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.830125570297241
Gradient before update: tensor(-1.5647)
Gradient after update: tensor(-1.5647)
current Learning Rate:  6.103515625e-06
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  219
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82944655418396
Gradient before update: tensor(-1.5648)
Gradient after update: tensor(-1.5648)
current Learning Rate:  6.103515625e-06
------------------------------------------------------------------------------------------------------------------
Iteration:  220
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.828784704208374
Gradient before update: tensor(-1.5649)
Gradient after update: tensor(-1.5649)
current Learning Rate:  6.103515625e-06
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  221
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8281092643737793
Gradient before update: tensor(-1.5650)
Gradient after update: tensor(-1.5650)
current Learning Rate:  6.103515625e-06
------------------------------------------------------------------------------------------------------------------
Iteration:  222
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.827436923980713
Gradient before update: tensor(-1.5651)
Gradient after update: tensor(-1.5651)
current Learning Rate:  6.103515625e-06
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  223
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8267717361450195
Gradient before update: tensor(-1.5652)
Gradient after update: tensor(-1.5652)
current Learning Rate:  6.103515625e-06
------------------------------------------------------------------------------------------------------------------
Iteration:  224
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.825932741165161
Gradient before update: tensor(-1.5653)
Gradient after update: tensor(-1.5653)
current Learning Rate:  6.103515625e-06
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  225
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.825427532196045
Gradient before update: tensor(-1.5654)
Gradient after update: tensor(-1.5654)
current Learning Rate:  3.0517578125e-06
------------------------------------------------------------------------------------------------------------------
Iteration:  226
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8245887756347656
Gradient before update: tensor(-1.5655)
Gradient after update: tensor(-1.5655)
current Learning Rate:  3.0517578125e-06
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  227
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8242578506469727
Gradient before update: tensor(-1.5655)
Gradient after update: tensor(-1.5655)
current Learning Rate:  3.0517578125e-06
------------------------------------------------------------------------------------------------------------------
Iteration:  228
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.824087142944336
Gradient before update: tensor(-1.5655)
Gradient after update: tensor(-1.5655)
current Learning Rate:  3.0517578125e-06
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  229
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.823916435241699
Gradient before update: tensor(-1.5656)
Gradient after update: tensor(-1.5656)
current Learning Rate:  3.0517578125e-06
------------------------------------------------------------------------------------------------------------------
Iteration:  230
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8235859870910645
Gradient before update: tensor(-1.5656)
Gradient after update: tensor(-1.5656)
current Learning Rate:  3.0517578125e-06
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  231
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8232555389404297
Gradient before update: tensor(-1.5657)
Gradient after update: tensor(-1.5657)
current Learning Rate:  3.0517578125e-06
------------------------------------------------------------------------------------------------------------------
Iteration:  232
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8230807781219482
Gradient before update: tensor(-1.5657)
Gradient after update: tensor(-1.5657)
current Learning Rate:  3.0517578125e-06
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  233
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.822913646697998
Gradient before update: tensor(-1.5657)
Gradient after update: tensor(-1.5657)
current Learning Rate:  3.0517578125e-06
------------------------------------------------------------------------------------------------------------------
Iteration:  234
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8225789070129395
Gradient before update: tensor(-1.5657)
Gradient after update: tensor(-1.5657)
current Learning Rate:  3.0517578125e-06
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  235
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.822249174118042
Gradient before update: tensor(-1.5658)
Gradient after update: tensor(-1.5658)
current Learning Rate:  3.0517578125e-06
------------------------------------------------------------------------------------------------------------------
Iteration:  236
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8220818042755127
Gradient before update: tensor(-1.5658)
Gradient after update: tensor(-1.5658)
current Learning Rate:  3.0517578125e-06
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  237
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.821747303009033
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  3.0517578125e-06
------------------------------------------------------------------------------------------------------------------
Iteration:  238
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8215768337249756
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  3.0517578125e-06
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  239
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8212459087371826
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  3.0517578125e-06
------------------------------------------------------------------------------------------------------------------
Iteration:  240
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.820908784866333
Gradient before update: tensor(-1.5660)
Gradient after update: tensor(-1.5660)
current Learning Rate:  1.52587890625e-06
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  241
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.820737838745117
Gradient before update: tensor(-1.5660)
Gradient after update: tensor(-1.5660)
current Learning Rate:  1.52587890625e-06
------------------------------------------------------------------------------------------------------------------
Iteration:  242
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.820737838745117
Gradient before update: tensor(-1.5660)
Gradient after update: tensor(-1.5660)
current Learning Rate:  1.52587890625e-06
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  243
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.820737838745117
Gradient before update: tensor(-1.5660)
Gradient after update: tensor(-1.5660)
current Learning Rate:  1.52587890625e-06
------------------------------------------------------------------------------------------------------------------
Iteration:  244
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.820737600326538
Gradient before update: tensor(-1.5660)
Gradient after update: tensor(-1.5660)
current Learning Rate:  1.52587890625e-06
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  245
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.820737361907959
Gradient before update: tensor(-1.5660)
Gradient after update: tensor(-1.5660)
current Learning Rate:  1.52587890625e-06
------------------------------------------------------------------------------------------------------------------
Iteration:  246
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.820737361907959
Gradient before update: tensor(-1.5660)
Gradient after update: tensor(-1.5660)
current Learning Rate:  1.52587890625e-06
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  247
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.820737361907959
Gradient before update: tensor(-1.5660)
Gradient after update: tensor(-1.5660)
current Learning Rate:  1.52587890625e-06
------------------------------------------------------------------------------------------------------------------
Iteration:  248
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.820737361907959
Gradient before update: tensor(-1.5660)
Gradient after update: tensor(-1.5660)
current Learning Rate:  1.52587890625e-06
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  249
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5660)
Gradient after update: tensor(-1.5660)
current Learning Rate:  1.52587890625e-06
------------------------------------------------------------------------------------------------------------------
Iteration:  250
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5660)
Gradient after update: tensor(-1.5660)
current Learning Rate:  1.52587890625e-06
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  251
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5660)
Gradient after update: tensor(-1.5660)
current Learning Rate:  1.52587890625e-06
------------------------------------------------------------------------------------------------------------------
Iteration:  252
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5660)
Gradient after update: tensor(-1.5660)
current Learning Rate:  1.52587890625e-06
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  253
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.820736885070801
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  1.52587890625e-06
------------------------------------------------------------------------------------------------------------------
Iteration:  254
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.820736885070801
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  1.52587890625e-06
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  255
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.820736885070801
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  7.62939453125e-07
------------------------------------------------------------------------------------------------------------------
Iteration:  256
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.820736885070801
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  7.62939453125e-07
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  257
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.820736885070801
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  7.62939453125e-07
------------------------------------------------------------------------------------------------------------------
Iteration:  258
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.820736885070801
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  7.62939453125e-07
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  259
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.820736885070801
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  7.62939453125e-07
------------------------------------------------------------------------------------------------------------------
Iteration:  260
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8207366466522217
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  7.62939453125e-07
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  261
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8207366466522217
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  7.62939453125e-07
------------------------------------------------------------------------------------------------------------------
Iteration:  262
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8207366466522217
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  7.62939453125e-07
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  263
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8207366466522217
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  7.62939453125e-07
------------------------------------------------------------------------------------------------------------------
Iteration:  264
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8207366466522217
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  7.62939453125e-07
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  265
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8207366466522217
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  7.62939453125e-07
------------------------------------------------------------------------------------------------------------------
Iteration:  266
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8207366466522217
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  7.62939453125e-07
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  267
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8207366466522217
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  7.62939453125e-07
------------------------------------------------------------------------------------------------------------------
Iteration:  268
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8207366466522217
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  7.62939453125e-07
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  269
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.8207366466522217
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  7.62939453125e-07
------------------------------------------------------------------------------------------------------------------
Iteration:  270
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  3.814697265625e-07
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  271
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  3.814697265625e-07
------------------------------------------------------------------------------------------------------------------
Iteration:  272
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  3.814697265625e-07
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  273
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  3.814697265625e-07
------------------------------------------------------------------------------------------------------------------
Iteration:  274
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  3.814697265625e-07
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  275
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  3.814697265625e-07
------------------------------------------------------------------------------------------------------------------
Iteration:  276
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  3.814697265625e-07
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  277
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  3.814697265625e-07
------------------------------------------------------------------------------------------------------------------
Iteration:  278
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  3.814697265625e-07
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  279
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  3.814697265625e-07
------------------------------------------------------------------------------------------------------------------
Iteration:  280
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  3.814697265625e-07
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  281
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  3.814697265625e-07
------------------------------------------------------------------------------------------------------------------
Iteration:  282
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  3.814697265625e-07
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  283
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  3.814697265625e-07
------------------------------------------------------------------------------------------------------------------
Iteration:  284
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  3.814697265625e-07
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  285
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  1.9073486328125e-07
------------------------------------------------------------------------------------------------------------------
Iteration:  286
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  1.9073486328125e-07
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  287
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  1.9073486328125e-07
------------------------------------------------------------------------------------------------------------------
Iteration:  288
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  1.9073486328125e-07
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  289
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  1.9073486328125e-07
------------------------------------------------------------------------------------------------------------------
Iteration:  290
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  1.9073486328125e-07
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  291
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  1.9073486328125e-07
------------------------------------------------------------------------------------------------------------------
Iteration:  292
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  1.9073486328125e-07
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  293
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  1.9073486328125e-07
------------------------------------------------------------------------------------------------------------------
Iteration:  294
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  1.9073486328125e-07
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  295
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  1.9073486328125e-07
------------------------------------------------------------------------------------------------------------------
Iteration:  296
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  1.9073486328125e-07
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  297
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  1.9073486328125e-07
------------------------------------------------------------------------------------------------------------------
Iteration:  298
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  1.9073486328125e-07
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  299
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  1.9073486328125e-07
------------------------------------------------------------------------------------------------------------------
Iteration:  300
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  9.5367431640625e-08
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  301
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  9.5367431640625e-08
------------------------------------------------------------------------------------------------------------------
Iteration:  302
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  9.5367431640625e-08
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  303
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  9.5367431640625e-08
------------------------------------------------------------------------------------------------------------------
Iteration:  304
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  9.5367431640625e-08
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  305
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  9.5367431640625e-08
------------------------------------------------------------------------------------------------------------------
Iteration:  306
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  9.5367431640625e-08
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  307
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  9.5367431640625e-08
------------------------------------------------------------------------------------------------------------------
Iteration:  308
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  9.5367431640625e-08
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  309
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  9.5367431640625e-08
------------------------------------------------------------------------------------------------------------------
Iteration:  310
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  9.5367431640625e-08
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  311
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  9.5367431640625e-08
------------------------------------------------------------------------------------------------------------------
Iteration:  312
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  9.5367431640625e-08
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  313
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  9.5367431640625e-08
------------------------------------------------------------------------------------------------------------------
Iteration:  314
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  9.5367431640625e-08
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  315
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  4.76837158203125e-08
------------------------------------------------------------------------------------------------------------------
Iteration:  316
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  4.76837158203125e-08
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  317
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  4.76837158203125e-08
------------------------------------------------------------------------------------------------------------------
Iteration:  318
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  4.76837158203125e-08
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  319
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  4.76837158203125e-08
------------------------------------------------------------------------------------------------------------------
Iteration:  320
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Gradients:
3.82073712348938
Gradient before update: tensor(-1.5659)
Gradient after update: tensor(-1.5659)
current Learning Rate:  4.76837158203125e-08
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4547,  0.3996, -3.6579,  0.0000,  0.0000,  0.0000],
        [-0.1202,  0.5797,  1.8029,  0.0000,  0.0000,  0.0000],
        [-1.7436,  0.4508,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8131,  0.2647,  2.7984,  0.0000,  0.0000,  0.0000],
        [ 0.0182, -0.0087,  0.7272,  0.0000,  0.0000,  0.0000],
        [ 1.1676,  0.2539, -0.8374,  0.0000,  0.0000,  0.0000],
        [ 0.4857,  0.5430, -0.5656,  0.0000,  0.0000,  0.0000],
        [ 1.2463,  0.3909,  0.7769,  0.0000,  0.0000,  0.0000],
        [-0.5909, -2.2030, -1.3233,  0.0000,  0.0000,  0.0000],
        [ 0.8827, -0.2891,  1.0703,  0.0000,  0.0000,  0.0000],
        [-1.5593, -1.4898, -3.4219,  0.0000,  0.0000,  0.0000],
        [-1.0559, -0.5240,  0.9651,  0.0000,  0.0000,  0.0000],
        [ 0.3487, -0.3511, -2.1698,  0.0000,  0.0000,  0.0000],
        [ 1.2697,  1.0407,  3.2901,  0.0000,  0.0000,  0.0000],
        [-1.1828, -0.8195, -3.2429,  0.0000,  0.0000,  0.0000],
        [-1.3013,  1.0443, -3.4218,  0.0000,  0.0000,  0.0000],
        [ 1.4910,  0.9298,  2.1463,  0.0000,  0.0000,  0.0000],
        [ 0.0899, -0.7354,  2.9311,  0.0000,  0.0000,  0.0000],
        [-0.7975,  0.8393, -1.9979,  0.0000,  0.0000,  0.0000],
        [-0.3569, -1.2146,  0.3834,  0.0000,  0.0000,  0.0000],
        [ 1.4416,  0.8824, -0.3424,  0.0000,  0.0000,  0.0000],
        [-1.2235,  0.9347,  1.6458,  0.0000,  0.0000,  0.0000],
        [ 0.9075,  0.9163, -1.1108,  0.0000,  0.0000,  0.0000],
        [ 0.4319,  1.0036, -1.4659,  0.0000,  0.0000,  0.0000],
        [-1.2738, -0.0982, -1.6145,  0.0000,  0.0000,  0.0000],
        [ 0.6404, -0.6109, -3.6108,  0.0000,  0.0000,  0.0000],
        [-1.8216, -0.1549, -0.5789,  0.0000,  0.0000,  0.0000],
        [-0.5320,  0.0771, -1.4306,  0.0000,  0.0000,  0.0000],
        [ 0.9141, -0.9163,  0.2389,  0.0000,  0.0000,  0.0000],
        [ 0.1964, -0.4224,  1.4304,  0.0000,  0.0000,  0.0000],
        [-0.6559, -0.4691,  2.3459,  0.0000,  0.0000,  0.0000],
        [ 0.4765,  0.6201, -2.8220,  0.0000,  0.0000,  0.0000],
        [ 1.4747, -1.1481, -0.7601,  0.0000,  0.0000,  0.0000],
        [ 1.0841,  0.4724, -2.3289,  0.0000,  0.0000,  0.0000],
        [-1.8445, -1.3116, -0.4925,  0.0000,  0.0000,  0.0000],
        [-1.4051,  0.6198, -2.6390,  0.0000,  0.0000,  0.0000],
        [ 0.7720,  1.0159,  1.3761,  0.0000,  0.0000,  0.0000],
        [ 1.1780, -1.4638,  1.3803,  0.0000,  0.0000,  0.0000],
        [-0.4810, -0.4065, -2.4920,  0.0000,  0.0000,  0.0000],
        [-0.7755, -1.5027,  3.5015,  0.0000,  0.0000,  0.0000],
        [ 0.5231,  0.0224, -1.2472,  0.0000,  0.0000,  0.0000],
        [ 0.1621, -2.2038,  0.2627,  0.0000,  0.0000,  0.0000],
        [-0.3830,  0.7269, -0.0508,  0.0000,  0.0000,  0.0000],
        [ 0.5273, -1.2651,  1.1168,  0.0000,  0.0000,  0.0000],
        [ 0.8305, -1.8443, -1.6036,  0.0000,  0.0000,  0.0000],
        [-1.2501, -1.6506,  1.7014,  0.0000,  0.0000,  0.0000],
        [ 0.3502,  0.5263,  0.1622,  0.0000,  0.0000,  0.0000],
        [-0.8053,  0.7567,  2.9295,  0.0000,  0.0000,  0.0000],
        [-0.0336, -1.7527, -2.9784,  0.0000,  0.0000,  0.0000],
        [ 0.1326, -0.2103, -0.0621,  0.0000,  0.0000,  0.0000],
        [-1.8166, -0.5823,  0.8297,  0.0000,  0.0000,  0.0000],
        [ 1.1504, -0.5705, -1.9360,  0.0000,  0.0000,  0.0000],
        [-0.6714, -0.9861, -0.8193,  0.0000,  0.0000,  0.0000],
        [ 0.8757, -2.4262, -2.2515,  0.0000,  0.0000,  0.0000],
        [-1.1232,  0.4173,  1.0679,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  321
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0246, grad_fn=<DivBackward0>)
Projection Loss:  tensor(494.9796, grad_fn=<AddBackward0>)
Total Loss:  tensor(495.0042, grad_fn=<AddBackward0>)


Restarted with the updated parameters:
lr=0.001
if i%15 == 0:
    optimizer.param_groups[0]['lr'] = optimizer.param_groups[0]['lr'] / 2  # Set the learning rate to 0.01 after 10 epochs


Gradients:
11208.7841796875
Gradient before update: tensor(-421.3188)
Gradient after update: tensor(-421.3188)
current Learning Rate:  0.001
------------------------------------------------------------------------------------------------------------------
Iteration:  4
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0219, grad_fn=<DivBackward0>)
Projection Loss:  tensor(491.9906, grad_fn=<AddBackward0>)
Total Loss:  tensor(492.0125, grad_fn=<AddBackward0>)
Gradients:
28.277631759643555
Gradient before update: tensor(0.5727)
Gradient after update: tensor(0.5727)
current Learning Rate:  0.001
Total Loss:  tensor(492.0125, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4509,  0.3958, -3.6541,  0.0000,  0.0000,  0.0000],
        [-0.1163,  0.5836,  1.7990,  0.0000,  0.0000,  0.0000],
        [-1.7468,  0.4539,  2.7594,  0.0000,  0.0000,  0.0000],
        [ 0.8169,  0.2608,  2.7970,  0.0000,  0.0000,  0.0000],
        [ 0.0142, -0.0047,  0.7245,  0.0000,  0.0000,  0.0000],
        [ 1.1715,  0.2500, -0.8338,  0.0000,  0.0000,  0.0000],
        [ 0.4823,  0.5393, -0.5681,  0.0000,  0.0000,  0.0000],
        [ 1.2503,  0.3870,  0.7744,  0.0000,  0.0000,  0.0000],
        [-0.5879, -2.2061, -1.3226,  0.0000,  0.0000,  0.0000],
        [ 0.8864, -0.2854,  1.0739,  0.0000,  0.0000,  0.0000],
        [-1.5565, -1.4937, -3.4257,  0.0000,  0.0000,  0.0000],
        [-1.0599, -0.5200,  0.9613,  0.0000,  0.0000,  0.0000],
        [ 0.3527, -0.3551, -2.1680,  0.0000,  0.0000,  0.0000],
        [ 1.2660,  1.0445,  3.2872,  0.0000,  0.0000,  0.0000],
        [-1.1867, -0.8234, -3.2391,  0.0000,  0.0000,  0.0000],
        [-1.2977,  1.0477, -3.4255,  0.0000,  0.0000,  0.0000],
        [ 1.4949,  0.9260,  2.1461,  0.0000,  0.0000,  0.0000],
        [ 0.0859, -0.7394,  2.9271,  0.0000,  0.0000,  0.0000],
        [-0.7939,  0.8429, -1.9954,  0.0000,  0.0000,  0.0000],
        [-0.3530, -1.2184,  0.3795,  0.0000,  0.0000,  0.0000],
        [ 1.4455,  0.8785, -0.3391,  0.0000,  0.0000,  0.0000],
        [-1.2195,  0.9387,  1.6464,  0.0000,  0.0000,  0.0000],
        [ 0.9115,  0.9123, -1.1068,  0.0000,  0.0000,  0.0000],
        [ 0.4279,  0.9996, -1.4699,  0.0000,  0.0000,  0.0000],
        [-1.2699, -0.0947, -1.6155,  0.0000,  0.0000,  0.0000],
        [ 0.6364, -0.6149, -3.6068,  0.0000,  0.0000,  0.0000],
        [-1.8253, -0.1585, -0.5823,  0.0000,  0.0000,  0.0000],
        [-0.5287,  0.0805, -1.4272,  0.0000,  0.0000,  0.0000],
        [ 0.9102, -0.9203,  0.2427,  0.0000,  0.0000,  0.0000],
        [ 0.1924, -0.4263,  1.4312,  0.0000,  0.0000,  0.0000],
        [-0.6599, -0.4651,  2.3420,  0.0000,  0.0000,  0.0000],
        [ 0.4726,  0.6240, -2.8234,  0.0000,  0.0000,  0.0000],
        [ 1.4785, -1.1448, -0.7567,  0.0000,  0.0000,  0.0000],
        [ 1.0804,  0.4763, -2.3304,  0.0000,  0.0000,  0.0000],
        [-1.8405, -1.3076, -0.4901,  0.0000,  0.0000,  0.0000],
        [-1.4091,  0.6238, -2.6350,  0.0000,  0.0000,  0.0000],
        [ 0.7754,  1.0193,  1.3736,  0.0000,  0.0000,  0.0000],
        [ 1.1812, -1.4669,  1.3834,  0.0000,  0.0000,  0.0000],
        [-0.4771, -0.4104, -2.4958,  0.0000,  0.0000,  0.0000],
        [-0.7785, -1.4997,  3.4988,  0.0000,  0.0000,  0.0000],
        [ 0.5193,  0.0259, -1.2481,  0.0000,  0.0000,  0.0000],
        [ 0.1601, -2.2076,  0.2664,  0.0000,  0.0000,  0.0000],
        [-0.3791,  0.7308, -0.0546,  0.0000,  0.0000,  0.0000],
        [ 0.5234, -1.2613,  1.1128,  0.0000,  0.0000,  0.0000],
        [ 0.8269, -1.8454, -1.6007,  0.0000,  0.0000,  0.0000],
        [-1.2504, -1.6545,  1.7052,  0.0000,  0.0000,  0.0000],
        [ 0.3462,  0.5224,  0.1648,  0.0000,  0.0000,  0.0000],
        [-0.8013,  0.7527,  2.9333,  0.0000,  0.0000,  0.0000],
        [-0.0374, -1.7514, -2.9746,  0.0000,  0.0000,  0.0000],
        [ 0.1286, -0.2141, -0.0587,  0.0000,  0.0000,  0.0000],
        [-1.8200, -0.5855,  0.8330,  0.0000,  0.0000,  0.0000],
        [ 1.1538, -0.5738, -1.9393,  0.0000,  0.0000,  0.0000],
        [-0.6750, -0.9898, -0.8232,  0.0000,  0.0000,  0.0000],
        [ 0.8797, -2.4222, -2.2554,  0.0000,  0.0000,  0.0000],
        [-1.1192,  0.4133,  1.0639,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  5
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0211, grad_fn=<DivBackward0>)
Projection Loss:  tensor(491.9677, grad_fn=<AddBackward0>)
Total Loss:  tensor(491.9888, grad_fn=<AddBackward0>)
Gradients:
8.268672943115234
Gradient before update: tensor(-3.4112)
Gradient after update: tensor(-3.4112)
current Learning Rate:  0.001
------------------------------------------------------------------------------------------------------------------
Iteration:  6
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0202, grad_fn=<DivBackward0>)
Projection Loss:  tensor(488.1075, grad_fn=<AddBackward0>)
Total Loss:  tensor(488.1277, grad_fn=<AddBackward0>)
Gradients:
457.4787292480469
Gradient before update: tensor(-974.1962)
Gradient after update: tensor(-974.1962)
current Learning Rate:  0.001
Total Loss:  tensor(488.1277, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 4.4901e-01,  3.9393e-01, -3.6521e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1437e-01,  5.8555e-01,  1.7973e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.7476e+00,  4.5470e-01,  2.7586e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.1879e-01,  2.5884e-01,  2.7963e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2244e-02, -2.7398e-03,  7.2305e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1733e+00,  2.4816e-01, -8.3247e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.8083e-01,  5.3753e-01, -5.6930e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2518e+00,  3.8548e-01,  7.7440e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.8712e-01, -2.2069e+00, -1.3234e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.8795e-01, -2.8386e-01,  1.0754e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.5549e+00, -1.4951e+00, -3.4277e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0618e+00, -5.1812e-01,  9.5962e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.5465e-01, -3.5704e-01, -2.1674e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2645e+00,  1.0462e+00,  3.2865e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1886e+00, -8.2530e-01, -3.2375e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2961e+00,  1.0490e+00, -3.4272e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4966e+00,  9.2438e-01,  2.1470e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.4034e-02, -7.4132e-01,  2.9252e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.9262e-01,  8.4418e-01, -1.9948e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.5120e-01, -1.2199e+00,  3.7772e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4474e+00,  8.7675e-01, -3.3796e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2176e+00,  9.4061e-01,  1.6479e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.1347e-01,  9.1028e-01, -1.1049e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.2591e-01,  9.9763e-01, -1.4718e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2680e+00, -9.2852e-02, -1.6152e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.3448e-01, -6.1682e-01, -3.6049e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8268e+00, -1.5984e-01, -5.8349e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.2784e-01,  8.1521e-02, -1.4262e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.0850e-01, -9.2228e-01,  2.4453e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.9047e-01, -4.2834e-01,  1.4327e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.6182e-01, -4.6317e-01,  2.3405e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.7078e-01,  6.2587e-01, -2.8233e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4801e+00, -1.1438e+00, -7.5537e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0786e+00,  4.7821e-01, -2.3307e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8390e+00, -1.3061e+00, -4.9002e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.4111e+00,  6.2579e-01, -2.6331e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.7549e-01,  1.0204e+00,  1.3739e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1820e+00, -1.4677e+00,  1.3843e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.7521e-01, -4.1228e-01, -2.4975e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.7942e-01, -1.4988e+00,  3.4981e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.1751e-01,  2.7348e-02, -1.2486e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.6057e-01, -2.2092e+00,  2.6788e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.7775e-01,  7.3220e-01, -5.6014e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.2167e-01, -1.2596e+00,  1.1109e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.2547e-01, -1.8471e+00, -1.5989e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2503e+00, -1.6563e+00,  1.7067e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.4427e-01,  5.2048e-01,  1.6584e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.9941e-01,  7.5081e-01,  2.9351e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.9019e-02, -1.7496e+00, -2.9731e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2667e-01, -2.1596e-01, -5.7179e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8213e+00, -5.8630e-01,  8.3428e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1551e+00, -5.7491e-01, -1.9404e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.7594e-01, -9.9098e-01, -8.2513e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.8157e-01, -2.4203e+00, -2.2543e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1173e+00,  4.1139e-01,  1.0623e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00]], requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  7
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0194, grad_fn=<DivBackward0>)
Projection Loss:  tensor(487.9668, grad_fn=<AddBackward0>)
Total Loss:  tensor(487.9862, grad_fn=<AddBackward0>)
Gradients:
20.42758560180664
Gradient before update: tensor(-49.4988)
Gradient after update: tensor(-49.4988)
current Learning Rate:  0.001
------------------------------------------------------------------------------------------------------------------
Iteration:  8
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0187, grad_fn=<DivBackward0>)
Projection Loss:  tensor(487.9438, grad_fn=<AddBackward0>)
Total Loss:  tensor(487.9624, grad_fn=<AddBackward0>)
Gradients:
10.389049530029297
Gradient before update: tensor(-22.8161)
Gradient after update: tensor(-22.8161)
current Learning Rate:  0.001
Total Loss:  tensor(487.9624, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 4.4709e-01,  3.9205e-01, -3.6502e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1256e-01,  5.8737e-01,  1.7956e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.7482e+00,  4.5533e-01,  2.7580e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.2062e-01,  2.5691e-01,  2.7959e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0276e-02, -7.7147e-04,  7.2211e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1746e+00,  2.4695e-01, -8.3130e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.7969e-01,  5.3613e-01, -5.6935e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2529e+00,  3.8436e-01,  7.7329e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.8649e-01, -2.2075e+00, -1.3240e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.8931e-01, -2.8251e-01,  1.0766e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.5532e+00, -1.4961e+00, -3.4295e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0637e+00, -5.1622e-01,  9.5919e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.5664e-01, -3.5904e-01, -2.1668e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2633e+00,  1.0476e+00,  3.2861e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1904e+00, -8.2710e-01, -3.2366e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2948e+00,  1.0498e+00, -3.4291e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4982e+00,  9.2309e-01,  2.1480e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.2230e-02, -7.4321e-01,  2.9233e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.9154e-01,  8.4527e-01, -1.9944e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.4951e-01, -1.2209e+00,  3.7612e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4492e+00,  8.7509e-01, -3.3729e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2158e+00,  9.4246e-01,  1.6494e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.1545e-01,  9.0835e-01, -1.1029e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.2405e-01,  9.9562e-01, -1.4738e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2661e+00, -9.1017e-02, -1.6154e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.3256e-01, -6.1874e-01, -3.6029e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8281e+00, -1.6097e-01, -5.8437e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.2723e-01,  8.2290e-02, -1.4254e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.0708e-01, -9.2428e-01,  2.4622e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.8854e-01, -4.3032e-01,  1.4344e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.6378e-01, -4.6122e-01,  2.3399e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.6895e-01,  6.2776e-01, -2.8228e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4816e+00, -1.1430e+00, -7.5429e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0767e+00,  4.8016e-01, -2.3310e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8381e+00, -1.3051e+00, -4.9093e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.4130e+00,  6.2771e-01, -2.6313e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.7459e-01,  1.0213e+00,  1.3748e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1826e+00, -1.4684e+00,  1.3849e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.7345e-01, -4.1404e-01, -2.4989e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8014e-01, -1.4981e+00,  3.4976e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.1572e-01,  2.8505e-02, -1.2492e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.6136e-01, -2.2106e+00,  2.6925e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.7685e-01,  7.3310e-01, -5.6913e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.1992e-01, -1.2578e+00,  1.1089e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.2459e-01, -1.8490e+00, -1.5970e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2498e+00, -1.6580e+00,  1.7080e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.4233e-01,  5.1853e-01,  1.6671e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.9750e-01,  7.4892e-01,  2.9366e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.0419e-02, -1.7479e+00, -2.9718e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2471e-01, -2.1776e-01, -5.5679e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8225e+00, -5.8680e-01,  8.3515e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1561e+00, -5.7578e-01, -1.9413e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.7587e-01, -9.9136e-01, -8.2698e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.8351e-01, -2.4184e+00, -2.2535e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1155e+00,  4.0957e-01,  1.0616e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00]], requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  9
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0179, grad_fn=<DivBackward0>)
Projection Loss:  tensor(487.3248, grad_fn=<AddBackward0>)
Total Loss:  tensor(487.3427, grad_fn=<AddBackward0>)
Gradients:
5094.09765625
Gradient before update: tensor(-2135.8767)
Gradient after update: tensor(-2135.8767)
current Learning Rate:  0.001
------------------------------------------------------------------------------------------------------------------
Iteration:  10
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0171, grad_fn=<DivBackward0>)
Projection Loss:  tensor(486.9049, grad_fn=<AddBackward0>)
Total Loss:  tensor(486.9220, grad_fn=<AddBackward0>)
Gradients:
48.50068283081055
Gradient before update: tensor(-62.7956)
Gradient after update: tensor(-62.7956)
current Learning Rate:  0.001
Total Loss:  tensor(486.9220, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 4.4517e-01,  3.9016e-01, -3.6483e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1085e-01,  5.8910e-01,  1.7942e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.7487e+00,  4.5583e-01,  2.7575e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.2239e-01,  2.5500e-01,  2.7958e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.3196e-03,  1.1819e-03,  7.2192e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1762e+00,  2.4535e-01, -8.2970e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.7845e-01,  5.3489e-01, -5.6811e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2538e+00,  3.8339e-01,  7.7236e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.8600e-01, -2.2080e+00, -1.3245e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.9050e-01, -2.8133e-01,  1.0776e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.5516e+00, -1.4971e+00, -3.4313e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0656e+00, -5.1432e-01,  9.5902e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.5863e-01, -3.6104e-01, -2.1664e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2623e+00,  1.0490e+00,  3.2856e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1921e+00, -8.2882e-01, -3.2356e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2936e+00,  1.0505e+00, -3.4310e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4996e+00,  9.2207e-01,  2.1488e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.0537e-02, -7.4503e-01,  2.9216e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.9063e-01,  8.4617e-01, -1.9941e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.4792e-01, -1.2214e+00,  3.7476e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4509e+00,  8.7351e-01, -3.3772e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2142e+00,  9.4424e-01,  1.6507e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.1743e-01,  9.0635e-01, -1.1010e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.2246e-01,  9.9358e-01, -1.4757e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2643e+00, -8.9258e-02, -1.6158e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.3069e-01, -6.2061e-01, -3.6010e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8293e+00, -1.6190e-01, -5.8502e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.2677e-01,  8.2898e-02, -1.4248e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.0608e-01, -9.2626e-01,  2.4777e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.8664e-01, -4.3231e-01,  1.4360e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.6572e-01, -4.5929e-01,  2.3390e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.6715e-01,  6.2966e-01, -2.8219e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4826e+00, -1.1439e+00, -7.5337e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0748e+00,  4.8209e-01, -2.3314e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8373e+00, -1.3044e+00, -4.9165e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.4149e+00,  6.2954e-01, -2.6298e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.7388e-01,  1.0221e+00,  1.3755e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1832e+00, -1.4689e+00,  1.3854e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.7173e-01, -4.1576e-01, -2.4988e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8074e-01, -1.4975e+00,  3.4971e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.1399e-01,  2.9318e-02, -1.2496e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.6240e-01, -2.2117e+00,  2.7045e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.7613e-01,  7.3381e-01, -5.7630e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.1808e-01, -1.2560e+00,  1.1069e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.2344e-01, -1.8502e+00, -1.5958e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2491e+00, -1.6596e+00,  1.7092e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.4041e-01,  5.1656e-01,  1.6734e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.9562e-01,  7.4708e-01,  2.9380e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.1559e-02, -1.7463e+00, -2.9708e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2277e-01, -2.1948e-01, -5.4280e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8236e+00, -5.8710e-01,  8.3555e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1570e+00, -5.7648e-01, -1.9420e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.7513e-01, -9.9106e-01, -8.2875e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.8532e-01, -2.4166e+00, -2.2530e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1138e+00,  4.0792e-01,  1.0612e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00]], requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  11
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0164, grad_fn=<DivBackward0>)
Projection Loss:  tensor(485.8944, grad_fn=<AddBackward0>)
Total Loss:  tensor(485.9108, grad_fn=<AddBackward0>)
Gradients:
389.2067565917969
Gradient before update: tensor(396.2578)
Gradient after update: tensor(396.2578)
current Learning Rate:  0.001
------------------------------------------------------------------------------------------------------------------
Iteration:  12
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0157, grad_fn=<DivBackward0>)
Projection Loss:  tensor(484.3553, grad_fn=<AddBackward0>)
Total Loss:  tensor(484.3710, grad_fn=<AddBackward0>)
Gradients:
9906.2060546875
Gradient before update: tensor(-16939.6699)
Gradient after update: tensor(-16939.6699)
current Learning Rate:  0.001
Total Loss:  tensor(484.3710, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 4.4325e-01,  3.8830e-01, -3.6463e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0923e-01,  5.9075e-01,  1.7931e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.7491e+00,  4.5623e-01,  2.7571e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.2409e-01,  2.5311e-01,  2.7958e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.3776e-03,  3.1192e-03,  7.2177e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1780e+00,  2.4354e-01, -8.2789e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.7745e-01,  5.3389e-01, -5.6711e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2547e+00,  3.8256e-01,  7.7164e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.8560e-01, -2.2084e+00, -1.3249e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.9155e-01, -2.8030e-01,  1.0785e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.5502e+00, -1.4981e+00, -3.4329e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0674e+00, -5.1247e-01,  9.5882e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.6061e-01, -3.6304e-01, -2.1659e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2623e+00,  1.0501e+00,  3.2848e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1930e+00, -8.2976e-01, -3.2366e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2926e+00,  1.0509e+00, -3.4329e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.5009e+00,  9.2131e-01,  2.1494e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.8961e-02, -7.4678e-01,  2.9200e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8987e-01,  8.4694e-01, -1.9938e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.4644e-01, -1.2214e+00,  3.7369e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4525e+00,  8.7201e-01, -3.3858e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2126e+00,  9.4594e-01,  1.6520e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.1940e-01,  9.0430e-01, -1.0990e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.2133e-01,  9.9150e-01, -1.4775e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2626e+00, -8.7630e-02, -1.6163e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.2886e-01, -6.2243e-01, -3.5992e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8303e+00, -1.6267e-01, -5.8549e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.2642e-01,  8.3388e-02, -1.4243e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.0559e-01, -9.2824e-01,  2.4914e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.8476e-01, -4.3429e-01,  1.4375e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.6761e-01, -4.5742e-01,  2.3381e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.6539e-01,  6.3153e-01, -2.8207e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4833e+00, -1.1446e+00, -7.5262e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0729e+00,  4.8403e-01, -2.3317e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8367e+00, -1.3038e+00, -4.9224e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.4166e+00,  6.3125e-01, -2.6287e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.7331e-01,  1.0226e+00,  1.3761e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1836e+00, -1.4693e+00,  1.3858e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.7006e-01, -4.1743e-01, -2.4988e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8123e-01, -1.4970e+00,  3.4961e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.1234e-01,  2.9698e-02, -1.2499e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.6356e-01, -2.2126e+00,  2.7159e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.7555e-01,  7.3439e-01, -5.8204e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.1615e-01, -1.2541e+00,  1.1048e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.2191e-01, -1.8517e+00, -1.5942e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2488e+00, -1.6611e+00,  1.7103e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.3850e-01,  5.1456e-01,  1.6774e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.9376e-01,  7.4528e-01,  2.9394e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.2460e-02, -1.7448e+00, -2.9701e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2085e-01, -2.2110e-01, -5.2914e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8246e+00, -5.8731e-01,  8.3554e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1579e+00, -5.7707e-01, -1.9424e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.7404e-01, -9.9039e-01, -8.3040e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.8654e-01, -2.4154e+00, -2.2528e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1123e+00,  4.0644e-01,  1.0610e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00]], requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  13
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0150, grad_fn=<DivBackward0>)
Projection Loss:  tensor(482.2153, grad_fn=<AddBackward0>)
Total Loss:  tensor(482.2304, grad_fn=<AddBackward0>)
Gradients:
2183.663330078125
Gradient before update: tensor(828.8797)
Gradient after update: tensor(828.8797)
current Learning Rate:  0.001
------------------------------------------------------------------------------------------------------------------
Iteration:  14
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0145, grad_fn=<DivBackward0>)
Projection Loss:  tensor(481.0087, grad_fn=<AddBackward0>)
Total Loss:  tensor(481.0232, grad_fn=<AddBackward0>)
Gradients:
136.2922821044922
Gradient before update: tensor(151.2601)
Gradient after update: tensor(151.2601)
current Learning Rate:  0.001
Total Loss:  tensor(481.0232, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4414,  0.3864, -3.6444,  0.0000,  0.0000,  0.0000],
        [-0.1077,  0.5923,  1.7922,  0.0000,  0.0000,  0.0000],
        [-1.7494,  0.4565,  2.7567,  0.0000,  0.0000,  0.0000],
        [ 0.8257,  0.2512,  2.7959,  0.0000,  0.0000,  0.0000],
        [ 0.0045,  0.0050,  0.7211,  0.0000,  0.0000,  0.0000],
        [ 1.1799,  0.2416, -0.8259,  0.0000,  0.0000,  0.0000],
        [ 0.4766,  0.5331, -0.5663,  0.0000,  0.0000,  0.0000],
        [ 1.2554,  0.3819,  0.7711,  0.0000,  0.0000,  0.0000],
        [-0.5853, -2.2087, -1.3252,  0.0000,  0.0000,  0.0000],
        [ 0.8925, -0.2794,  1.0792,  0.0000,  0.0000,  0.0000],
        [-1.5491, -1.4991, -3.4344,  0.0000,  0.0000,  0.0000],
        [-1.0691, -0.5107,  0.9586,  0.0000,  0.0000,  0.0000],
        [ 0.3626, -0.3651, -2.1655,  0.0000,  0.0000,  0.0000],
        [ 1.2631,  1.0510,  3.2839,  0.0000,  0.0000,  0.0000],
        [-1.1940, -0.8306, -3.2375,  0.0000,  0.0000,  0.0000],
        [-1.2918,  1.0511, -3.4349,  0.0000,  0.0000,  0.0000],
        [ 1.5021,  0.9208,  2.1498,  0.0000,  0.0000,  0.0000],
        [ 0.0775, -0.7484,  2.9185,  0.0000,  0.0000,  0.0000],
        [-0.7892,  0.8476, -1.9936,  0.0000,  0.0000,  0.0000],
        [-0.3451, -1.2213,  0.3729,  0.0000,  0.0000,  0.0000],
        [ 1.4543,  0.8705, -0.3391,  0.0000,  0.0000,  0.0000],
        [-1.2111,  0.9476,  1.6530,  0.0000,  0.0000,  0.0000],
        [ 0.9214,  0.9023, -1.0971,  0.0000,  0.0000,  0.0000],
        [ 0.4210,  0.9894, -1.4793,  0.0000,  0.0000,  0.0000],
        [-1.2611, -0.0861, -1.6168,  0.0000,  0.0000,  0.0000],
        [ 0.6271, -0.6242, -3.5973,  0.0000,  0.0000,  0.0000],
        [-1.8313, -0.1633, -0.5858,  0.0000,  0.0000,  0.0000],
        [-0.5261,  0.0838, -1.4239,  0.0000,  0.0000,  0.0000],
        [ 0.9056, -0.9302,  0.2503,  0.0000,  0.0000,  0.0000],
        [ 0.1829, -0.4362,  1.4387,  0.0000,  0.0000,  0.0000],
        [-0.6694, -0.4556,  2.3372,  0.0000,  0.0000,  0.0000],
        [ 0.4637,  0.6334, -2.8195,  0.0000,  0.0000,  0.0000],
        [ 1.4841, -1.1457, -0.7518,  0.0000,  0.0000,  0.0000],
        [ 1.0711,  0.4859, -2.3321,  0.0000,  0.0000,  0.0000],
        [-1.8363, -1.3033, -0.4927,  0.0000,  0.0000,  0.0000],
        [-1.4183,  0.6329, -2.6284,  0.0000,  0.0000,  0.0000],
        [ 0.7728,  1.0231,  1.3765,  0.0000,  0.0000,  0.0000],
        [ 1.1839, -1.4696,  1.3861,  0.0000,  0.0000,  0.0000],
        [-0.4685, -0.4190, -2.4988,  0.0000,  0.0000,  0.0000],
        [-0.7816, -1.4965,  3.4951,  0.0000,  0.0000,  0.0000],
        [ 0.5108,  0.0296, -1.2502,  0.0000,  0.0000,  0.0000],
        [ 0.1647, -2.2134,  0.2727,  0.0000,  0.0000,  0.0000],
        [-0.3751,  0.7349, -0.0587,  0.0000,  0.0000,  0.0000],
        [ 0.5142, -1.2521,  1.1028,  0.0000,  0.0000,  0.0000],
        [ 0.8203, -1.8533, -1.5926,  0.0000,  0.0000,  0.0000],
        [-1.2489, -1.6626,  1.7112,  0.0000,  0.0000,  0.0000],
        [ 0.3366,  0.5125,  0.1683,  0.0000,  0.0000,  0.0000],
        [-0.7919,  0.7435,  2.9405,  0.0000,  0.0000,  0.0000],
        [-0.0431, -1.7436, -2.9694,  0.0000,  0.0000,  0.0000],
        [ 0.1189, -0.2226, -0.0517,  0.0000,  0.0000,  0.0000],
        [-1.8255, -0.5875,  0.8353,  0.0000,  0.0000,  0.0000],
        [ 1.1586, -0.5776, -1.9427,  0.0000,  0.0000,  0.0000],
        [-0.6728, -0.9896, -0.8319,  0.0000,  0.0000,  0.0000],
        [ 0.8874, -2.4145, -2.2519,  0.0000,  0.0000,  0.0000],
        [-1.1110,  0.4051,  1.0610,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  15
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0140, grad_fn=<DivBackward0>)
Projection Loss:  tensor(480.9207, grad_fn=<AddBackward0>)
Total Loss:  tensor(480.9347, grad_fn=<AddBackward0>)
Gradients:
18754.173828125
Gradient before update: tensor(-9167.2910)
Gradient after update: tensor(-9167.2910)
current Learning Rate:  0.0005
------------------------------------------------------------------------------------------------------------------
Iteration:  16
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0135, grad_fn=<DivBackward0>)
Projection Loss:  tensor(479.0341, grad_fn=<AddBackward0>)
Total Loss:  tensor(479.0476, grad_fn=<AddBackward0>)
Gradients:
322.8108825683594
Gradient before update: tensor(-75.6770)
Gradient after update: tensor(-75.6770)
current Learning Rate:  0.0005
Total Loss:  tensor(479.0476, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 4.3995e-01,  3.8506e-01, -3.6430e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0654e-01,  5.9350e-01,  1.7921e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.7496e+00,  4.5675e-01,  2.7565e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.2690e-01,  2.4984e-01,  2.7958e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.0178e-03,  6.4700e-03,  7.2035e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1812e+00,  2.4034e-01, -8.2518e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.7613e-01,  5.3258e-01, -5.6579e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2558e+00,  3.8144e-01,  7.7072e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.8508e-01, -2.2089e+00, -1.3254e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.9310e-01, -2.7877e-01,  1.0797e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.5484e+00, -1.4999e+00, -3.4355e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0704e+00, -5.0940e-01,  9.5850e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.6408e-01, -3.6660e-01, -2.1651e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2636e+00,  1.0515e+00,  3.2834e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1947e+00, -8.3118e-01, -3.2382e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2915e+00,  1.0512e+00, -3.4365e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.5029e+00,  9.2048e-01,  2.1501e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.6477e-02, -7.4963e-01,  2.9176e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8879e-01,  8.4802e-01, -1.9935e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.4409e-01, -1.2212e+00,  3.7252e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4557e+00,  8.6925e-01, -3.3925e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2101e+00,  9.4877e-01,  1.6534e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.2282e-01,  9.0070e-01, -1.0957e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.2145e-01,  9.8775e-01, -1.4806e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2601e+00, -8.5138e-02, -1.6171e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.2578e-01, -6.2550e-01, -3.5959e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8319e+00, -1.6368e-01, -5.8598e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.2597e-01,  8.4037e-02, -1.4237e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.0592e-01, -9.3166e-01,  2.5103e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.8157e-01, -4.3769e-01,  1.4395e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.7071e-01, -4.5434e-01,  2.3365e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.6240e-01,  6.3476e-01, -2.8185e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4846e+00, -1.1463e+00, -7.5128e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0697e+00,  4.8738e-01, -2.3324e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8360e+00, -1.3031e+00, -4.9306e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.4194e+00,  6.3400e-01, -2.6282e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.7255e-01,  1.0234e+00,  1.3768e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1841e+00, -1.4699e+00,  1.3863e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.6735e-01, -4.2013e-01, -2.4989e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8192e-01, -1.4963e+00,  3.4943e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.0975e-01,  2.9204e-02, -1.2503e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.6552e-01, -2.2139e+00,  2.7353e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.7478e-01,  7.3516e-01, -5.8959e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.1280e-01, -1.2505e+00,  1.1014e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.1905e-01, -1.8546e+00, -1.5923e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2491e+00, -1.6637e+00,  1.7116e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.3524e-01,  5.1101e-01,  1.6891e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.9057e-01,  7.4221e-01,  2.9409e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.3463e-02, -1.7430e+00, -2.9690e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1748e-01, -2.2365e-01, -5.1001e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8261e+00, -5.8758e-01,  8.3494e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1591e+00, -5.7787e-01, -1.9428e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.7195e-01, -9.8901e-01, -8.3284e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.8825e-01, -2.4149e+00, -2.2511e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1102e+00,  4.0427e-01,  1.0610e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00]], requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  17
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0133, grad_fn=<DivBackward0>)
Projection Loss:  tensor(478.3522, grad_fn=<AddBackward0>)
Total Loss:  tensor(478.3655, grad_fn=<AddBackward0>)
Gradients:
4585.5986328125
Gradient before update: tensor(-5674.1631)
Gradient after update: tensor(-5674.1631)
current Learning Rate:  0.0005
------------------------------------------------------------------------------------------------------------------
Iteration:  18
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0132, grad_fn=<DivBackward0>)
Projection Loss:  tensor(478.0074, grad_fn=<AddBackward0>)
Total Loss:  tensor(478.0205, grad_fn=<AddBackward0>)
Gradients:
192.79168701171875
Gradient before update: tensor(-233.8591)
Gradient after update: tensor(-233.8591)
current Learning Rate:  0.0005
Total Loss:  tensor(478.0205, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 4.3904e-01,  3.8415e-01, -3.6420e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0580e-01,  5.9425e-01,  1.7921e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.7497e+00,  4.5686e-01,  2.7564e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.2766e-01,  2.4892e-01,  2.7957e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 2.0707e-03,  7.4118e-03,  7.1972e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1817e+00,  2.3984e-01, -8.2568e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.7586e-01,  5.3230e-01, -5.6552e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2560e+00,  3.8121e-01,  7.7054e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.8497e-01, -2.2091e+00, -1.3255e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.9347e-01, -2.7841e-01,  1.0800e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.5479e+00, -1.5004e+00, -3.4361e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0712e+00, -5.0859e-01,  9.5843e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.6506e-01, -3.6763e-01, -2.1650e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2639e+00,  1.0518e+00,  3.2831e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1951e+00, -8.3149e-01, -3.2385e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2915e+00,  1.0512e+00, -3.4375e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.5035e+00,  9.2038e-01,  2.1502e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.5843e-02, -7.5038e-01,  2.9170e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8855e-01,  8.4827e-01, -1.9934e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.4349e-01, -1.2211e+00,  3.7239e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4566e+00,  8.6845e-01, -3.3928e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2094e+00,  9.4956e-01,  1.6535e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.2379e-01,  8.9976e-01, -1.0948e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.2215e-01,  9.8663e-01, -1.4814e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2600e+00, -8.5060e-02, -1.6175e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.2493e-01, -6.2635e-01, -3.5951e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8323e+00, -1.6389e-01, -5.8604e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.2588e-01,  8.4172e-02, -1.4235e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.0630e-01, -9.3262e-01,  2.5138e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.8070e-01, -4.3865e-01,  1.4400e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.7152e-01, -4.5353e-01,  2.3361e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.6155e-01,  6.3568e-01, -2.8180e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4849e+00, -1.1467e+00, -7.5100e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0688e+00,  4.8833e-01, -2.3326e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8359e+00, -1.3030e+00, -4.9327e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.4202e+00,  6.3468e-01, -2.6281e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.7302e-01,  1.0239e+00,  1.3773e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1842e+00, -1.4700e+00,  1.3864e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.6665e-01, -4.2082e-01, -2.4989e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8206e-01, -1.4961e+00,  3.4938e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.0912e-01,  2.8755e-02, -1.2504e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.6594e-01, -2.2142e+00,  2.7408e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.7462e-01,  7.3532e-01, -5.9116e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.1191e-01, -1.2495e+00,  1.1005e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.1823e-01, -1.8554e+00, -1.5924e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2492e+00, -1.6643e+00,  1.7118e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.3433e-01,  5.0998e-01,  1.6948e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8968e-01,  7.4136e-01,  2.9410e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.3564e-02, -1.7428e+00, -2.9687e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1652e-01, -2.2436e-01, -5.0624e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8264e+00, -5.8766e-01,  8.3468e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1594e+00, -5.7804e-01, -1.9429e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.7144e-01, -9.8872e-01, -8.3338e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.8871e-01, -2.4151e+00, -2.2506e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1097e+00,  4.0376e-01,  1.0611e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00]], requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  19
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0130, grad_fn=<DivBackward0>)
Projection Loss:  tensor(477.0172, grad_fn=<AddBackward0>)
Total Loss:  tensor(477.0302, grad_fn=<AddBackward0>)
Gradients:
239.49786376953125
Gradient before update: tensor(9.5835)
Gradient after update: tensor(9.5835)
current Learning Rate:  0.0005
------------------------------------------------------------------------------------------------------------------
Iteration:  20
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0129, grad_fn=<DivBackward0>)
Projection Loss:  tensor(476.9676, grad_fn=<AddBackward0>)
Total Loss:  tensor(476.9804, grad_fn=<AddBackward0>)
Gradients:
38.509849548339844
Gradient before update: tensor(1.2972)
Gradient after update: tensor(1.2972)
current Learning Rate:  0.0005
Total Loss:  tensor(476.9804, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 4.3815e-01,  3.8326e-01, -3.6411e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0508e-01,  5.9499e-01,  1.7920e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.7498e+00,  4.5695e-01,  2.7563e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.2837e-01,  2.4800e-01,  2.7955e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1309e-03,  8.3440e-03,  7.1905e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1823e+00,  2.3918e-01, -8.2630e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.7563e-01,  5.3208e-01, -5.6530e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2562e+00,  3.8101e-01,  7.7038e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.8488e-01, -2.2091e+00, -1.3256e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.9380e-01, -2.7808e-01,  1.0802e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.5475e+00, -1.5009e+00, -3.4367e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0721e+00, -5.0782e-01,  9.5836e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.6605e-01, -3.6866e-01, -2.1648e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2642e+00,  1.0520e+00,  3.2829e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1955e+00, -8.3176e-01, -3.2388e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2916e+00,  1.0511e+00, -3.4386e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.5039e+00,  9.2035e-01,  2.1503e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.5246e-02, -7.5109e-01,  2.9166e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8834e-01,  8.4848e-01, -1.9934e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.4292e-01, -1.2210e+00,  3.7236e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4576e+00,  8.6765e-01, -3.3919e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2087e+00,  9.5034e-01,  1.6533e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.2475e-01,  8.9888e-01, -1.0939e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.2303e-01,  9.8549e-01, -1.4823e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2604e+00, -8.5460e-02, -1.6179e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.2410e-01, -6.2718e-01, -3.5942e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8327e+00, -1.6406e-01, -5.8606e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.2581e-01,  8.4283e-02, -1.4234e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.0681e-01, -9.3357e-01,  2.5163e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.7985e-01, -4.3959e-01,  1.4403e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.7230e-01, -4.5276e-01,  2.3358e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.6070e-01,  6.3660e-01, -2.8177e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4851e+00, -1.1470e+00, -7.5077e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0679e+00,  4.8927e-01, -2.3328e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8358e+00, -1.3030e+00, -4.9350e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.4208e+00,  6.3530e-01, -2.6280e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.7343e-01,  1.0243e+00,  1.3777e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1843e+00, -1.4701e+00,  1.3865e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.6600e-01, -4.2147e-01, -2.4989e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8219e-01, -1.4960e+00,  3.4932e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.0854e-01,  2.8182e-02, -1.2504e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.6623e-01, -2.2145e+00,  2.7463e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.7449e-01,  7.3546e-01, -5.9245e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.1104e-01, -1.2485e+00,  1.0996e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.1745e-01, -1.8562e+00, -1.5927e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2493e+00, -1.6649e+00,  1.7120e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.3342e-01,  5.0892e-01,  1.6999e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8880e-01,  7.4052e-01,  2.9409e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.3564e-02, -1.7427e+00, -2.9684e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1557e-01, -2.2509e-01, -5.0349e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8267e+00, -5.8773e-01,  8.3441e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1597e+00, -5.7818e-01, -1.9429e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.7102e-01, -9.8853e-01, -8.3382e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.8910e-01, -2.4152e+00, -2.2502e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1092e+00,  4.0331e-01,  1.0611e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00]], requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  21
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0127, grad_fn=<DivBackward0>)
Projection Loss:  tensor(476.9551, grad_fn=<AddBackward0>)
Total Loss:  tensor(476.9678, grad_fn=<AddBackward0>)
Gradients:
22.647491455078125
Gradient before update: tensor(5.2427)
Gradient after update: tensor(5.2427)
current Learning Rate:  0.0005
------------------------------------------------------------------------------------------------------------------
Iteration:  22
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0126, grad_fn=<DivBackward0>)
Projection Loss:  tensor(476.9485, grad_fn=<AddBackward0>)
Total Loss:  tensor(476.9611, grad_fn=<AddBackward0>)
Gradients:
18.70294189453125
Gradient before update: tensor(5.7408)
Gradient after update: tensor(5.7408)
current Learning Rate:  0.0005
Total Loss:  tensor(476.9611, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 4.3727e-01,  3.8237e-01, -3.6402e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0439e-01,  5.9572e-01,  1.7919e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.7499e+00,  4.5702e-01,  2.7563e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.2906e-01,  2.4709e-01,  2.7953e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.9786e-04,  9.2671e-03,  7.1834e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1828e+00,  2.3860e-01, -8.2685e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.7545e-01,  5.3189e-01, -5.6511e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2564e+00,  3.8084e-01,  7.7026e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.8481e-01, -2.2092e+00, -1.3257e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.9410e-01, -2.7779e-01,  1.0804e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.5472e+00, -1.5014e+00, -3.4373e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0728e+00, -5.0707e-01,  9.5831e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.6703e-01, -3.6968e-01, -2.1646e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2643e+00,  1.0522e+00,  3.2827e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1958e+00, -8.3197e-01, -3.2391e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2918e+00,  1.0511e+00, -3.4396e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.5044e+00,  9.2037e-01,  2.1503e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.4677e-02, -7.5177e-01,  2.9162e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8815e-01,  8.4867e-01, -1.9933e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.4239e-01, -1.2210e+00,  3.7241e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4586e+00,  8.6687e-01, -3.3900e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2081e+00,  9.5111e-01,  1.6531e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.2571e-01,  8.9804e-01, -1.0929e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.2403e-01,  9.8433e-01, -1.4832e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2607e+00, -8.5788e-02, -1.6182e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.2327e-01, -6.2800e-01, -3.5933e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8330e+00, -1.6419e-01, -5.8604e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.2576e-01,  8.4376e-02, -1.4233e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.0740e-01, -9.3452e-01,  2.5176e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.7902e-01, -4.4051e-01,  1.4405e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.7305e-01, -4.5202e-01,  2.3354e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.5985e-01,  6.3752e-01, -2.8174e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4853e+00, -1.1472e+00, -7.5058e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0670e+00,  4.9020e-01, -2.3330e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8358e+00, -1.3031e+00, -4.9372e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.4214e+00,  6.3586e-01, -2.6279e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.7377e-01,  1.0246e+00,  1.3780e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1844e+00, -1.4701e+00,  1.3866e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.6538e-01, -4.2207e-01, -2.4989e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8230e-01, -1.4959e+00,  3.4927e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.0803e-01,  2.7520e-02, -1.2504e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.6642e-01, -2.2147e+00,  2.7519e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.7438e-01,  7.3557e-01, -5.9352e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.1019e-01, -1.2475e+00,  1.0988e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.1671e-01, -1.8570e+00, -1.5930e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2494e+00, -1.6654e+00,  1.7121e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.3253e-01,  5.0787e-01,  1.7043e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8794e-01,  7.3968e-01,  2.9406e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.3482e-02, -1.7428e+00, -2.9682e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1461e-01, -2.2581e-01, -5.0190e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8270e+00, -5.8781e-01,  8.3412e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1600e+00, -5.7830e-01, -1.9428e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.7071e-01, -9.8844e-01, -8.3418e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.8942e-01, -2.4154e+00, -2.2499e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1088e+00,  4.0290e-01,  1.0612e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00]], requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  23
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0124, grad_fn=<DivBackward0>)
Projection Loss:  tensor(476.9435, grad_fn=<AddBackward0>)
Total Loss:  tensor(476.9559, grad_fn=<AddBackward0>)
Gradients:
15.978089332580566
Gradient before update: tensor(4.8139)
Gradient after update: tensor(4.8139)
current Learning Rate:  0.0005
------------------------------------------------------------------------------------------------------------------
Iteration:  24
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0123, grad_fn=<DivBackward0>)
Projection Loss:  tensor(476.9391, grad_fn=<AddBackward0>)
Total Loss:  tensor(476.9514, grad_fn=<AddBackward0>)
Gradients:
13.586577415466309
Gradient before update: tensor(3.8006)
Gradient after update: tensor(3.8006)
current Learning Rate:  0.0005
Total Loss:  tensor(476.9514, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 4.3641e-01,  3.8149e-01, -3.6393e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0371e-01,  5.9642e-01,  1.7919e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.7500e+00,  4.5709e-01,  2.7562e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.2971e-01,  2.4618e-01,  2.7951e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.3348e-04,  1.0187e-02,  7.1776e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1833e+00,  2.3811e-01, -8.2731e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.7529e-01,  5.3174e-01, -5.6495e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2565e+00,  3.8070e-01,  7.7016e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.8474e-01, -2.2093e+00, -1.3258e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.9438e-01, -2.7752e-01,  1.0805e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.5468e+00, -1.5018e+00, -3.4378e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0736e+00, -5.0636e-01,  9.5826e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.6801e-01, -3.7069e-01, -2.1645e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2645e+00,  1.0523e+00,  3.2826e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1960e+00, -8.3215e-01, -3.2393e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2920e+00,  1.0509e+00, -3.4407e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.5048e+00,  9.2043e-01,  2.1502e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.4130e-02, -7.5243e-01,  2.9159e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8799e-01,  8.4883e-01, -1.9933e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.4188e-01, -1.2210e+00,  3.7252e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4596e+00,  8.6608e-01, -3.3895e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2075e+00,  9.5186e-01,  1.6528e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.2667e-01,  8.9723e-01, -1.0920e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.2511e-01,  9.8313e-01, -1.4842e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2609e+00, -8.6056e-02, -1.6185e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.2245e-01, -6.2882e-01, -3.5924e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8333e+00, -1.6429e-01, -5.8600e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.2572e-01,  8.4452e-02, -1.4233e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.0806e-01, -9.3547e-01,  2.5182e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.7819e-01, -4.4143e-01,  1.4406e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.7378e-01, -4.5130e-01,  2.3351e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.5900e-01,  6.3844e-01, -2.8172e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4854e+00, -1.1474e+00, -7.5043e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0661e+00,  4.9113e-01, -2.3331e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8359e+00, -1.3032e+00, -4.9395e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.4219e+00,  6.3636e-01, -2.6278e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.7405e-01,  1.0249e+00,  1.3783e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1845e+00, -1.4702e+00,  1.3867e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.6480e-01, -4.2264e-01, -2.4990e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8239e-01, -1.4958e+00,  3.4922e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.0756e-01,  2.6789e-02, -1.2504e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.6651e-01, -2.2149e+00,  2.7574e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.7429e-01,  7.3566e-01, -5.9440e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.0936e-01, -1.2465e+00,  1.0980e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.1602e-01, -1.8577e+00, -1.5931e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2494e+00, -1.6659e+00,  1.7121e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.3164e-01,  5.0682e-01,  1.7075e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8709e-01,  7.3885e-01,  2.9401e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.3336e-02, -1.7430e+00, -2.9679e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1366e-01, -2.2652e-01, -5.0183e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8273e+00, -5.8789e-01,  8.3385e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1603e+00, -5.7839e-01, -1.9428e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.7050e-01, -9.8847e-01, -8.3445e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.8969e-01, -2.4155e+00, -2.2496e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1084e+00,  4.0252e-01,  1.0613e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00]], requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  25
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0122, grad_fn=<DivBackward0>)
Projection Loss:  tensor(476.9349, grad_fn=<AddBackward0>)
Total Loss:  tensor(476.9471, grad_fn=<AddBackward0>)
Gradients:
11.594313621520996
Gradient before update: tensor(3.4803)
Gradient after update: tensor(3.4803)
current Learning Rate:  0.0005
------------------------------------------------------------------------------------------------------------------
Iteration:  26
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0120, grad_fn=<DivBackward0>)
Projection Loss:  tensor(476.2419, grad_fn=<AddBackward0>)
Total Loss:  tensor(476.2539, grad_fn=<AddBackward0>)
Gradients:
3476.391845703125
Gradient before update: tensor(3172.3989)
Gradient after update: tensor(3172.3989)
current Learning Rate:  0.0005
Total Loss:  tensor(476.2539, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 4.3557e-01,  3.8063e-01, -3.6383e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0306e-01,  5.9711e-01,  1.7918e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.7500e+00,  4.5714e-01,  2.7562e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.3032e-01,  2.4528e-01,  2.7949e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.6645e-03,  1.1102e-02,  7.1733e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1836e+00,  2.3770e-01, -8.2769e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.7485e-01,  5.3114e-01, -5.6444e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2566e+00,  3.8058e-01,  7.7008e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.8469e-01, -2.2093e+00, -1.3258e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.9463e-01, -2.7728e-01,  1.0807e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.5464e+00, -1.5021e+00, -3.4383e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0744e+00, -5.0568e-01,  9.5823e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.6897e-01, -3.7170e-01, -2.1643e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2646e+00,  1.0525e+00,  3.2824e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1962e+00, -8.3230e-01, -3.2395e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2922e+00,  1.0507e+00, -3.4418e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.5052e+00,  9.2054e-01,  2.1501e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.3597e-02, -7.5305e-01,  2.9157e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8784e-01,  8.4898e-01, -1.9933e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.4139e-01, -1.2211e+00,  3.7265e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4606e+00,  8.6529e-01, -3.3943e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2069e+00,  9.5261e-01,  1.6524e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.2762e-01,  8.9646e-01, -1.0911e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.2623e-01,  9.8193e-01, -1.4853e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2612e+00, -8.6275e-02, -1.6188e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.2164e-01, -6.2962e-01, -3.5915e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8336e+00, -1.6436e-01, -5.8594e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.2569e-01,  8.4516e-02, -1.4232e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.0874e-01, -9.3641e-01,  2.5182e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.7737e-01, -4.4235e-01,  1.4406e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.7449e-01, -4.5060e-01,  2.3349e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.5815e-01,  6.3935e-01, -2.8170e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4856e+00, -1.1476e+00, -7.5029e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0652e+00,  4.9204e-01, -2.3332e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8359e+00, -1.3034e+00, -4.9416e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.4224e+00,  6.3683e-01, -2.6277e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.7429e-01,  1.0252e+00,  1.3785e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1845e+00, -1.4703e+00,  1.3867e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.6425e-01, -4.2317e-01, -2.4990e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8247e-01, -1.4957e+00,  3.4918e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.0715e-01,  2.6010e-02, -1.2504e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.6655e-01, -2.2151e+00,  2.7629e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.7421e-01,  7.3573e-01, -5.9513e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.0853e-01, -1.2456e+00,  1.0972e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.1543e-01, -1.8578e+00, -1.5929e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2493e+00, -1.6663e+00,  1.7121e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.3077e-01,  5.0576e-01,  1.7087e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8625e-01,  7.3804e-01,  2.9396e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.3144e-02, -1.7433e+00, -2.9677e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1272e-01, -2.2721e-01, -5.0319e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8276e+00, -5.8798e-01,  8.3361e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1605e+00, -5.7847e-01, -1.9427e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.7038e-01, -9.8860e-01, -8.3465e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.8991e-01, -2.4156e+00, -2.2494e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1081e+00,  4.0216e-01,  1.0613e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00]], requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  27
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0119, grad_fn=<DivBackward0>)
Projection Loss:  tensor(475.9698, grad_fn=<AddBackward0>)
Total Loss:  tensor(475.9818, grad_fn=<AddBackward0>)
Gradients:
189.63522338867188
Gradient before update: tensor(179.3617)
Gradient after update: tensor(179.3617)
current Learning Rate:  0.0005
------------------------------------------------------------------------------------------------------------------
Iteration:  28
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0117, grad_fn=<DivBackward0>)
Projection Loss:  tensor(475.9353, grad_fn=<AddBackward0>)
Total Loss:  tensor(475.9471, grad_fn=<AddBackward0>)
Gradients:
48.322654724121094
Gradient before update: tensor(53.3627)
Gradient after update: tensor(53.3627)
current Learning Rate:  0.0005
Total Loss:  tensor(475.9471, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 4.3473e-01,  3.7977e-01, -3.6374e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0243e-01,  5.9777e-01,  1.7918e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.7501e+00,  4.5718e-01,  2.7561e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.3090e-01,  2.4439e-01,  2.7946e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-2.5938e-03,  1.2012e-02,  7.1700e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1840e+00,  2.3736e-01, -8.2801e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.7413e-01,  5.3029e-01, -5.6411e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2567e+00,  3.8048e-01,  7.7001e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.8465e-01, -2.2094e+00, -1.3259e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.9487e-01, -2.7705e-01,  1.0808e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.5460e+00, -1.5025e+00, -3.4387e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0751e+00, -5.0502e-01,  9.5819e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.6994e-01, -3.7270e-01, -2.1640e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2648e+00,  1.0526e+00,  3.2823e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1964e+00, -8.3243e-01, -3.2397e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2924e+00,  1.0505e+00, -3.4429e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.5055e+00,  9.2067e-01,  2.1500e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.3072e-02, -7.5366e-01,  2.9155e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8771e-01,  8.4911e-01, -1.9932e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.4093e-01, -1.2212e+00,  3.7274e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4616e+00,  8.6449e-01, -3.4004e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2064e+00,  9.5335e-01,  1.6519e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.2855e-01,  8.9571e-01, -1.0901e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.2733e-01,  9.8077e-01, -1.4865e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2613e+00, -8.6453e-02, -1.6190e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.2085e-01, -6.3041e-01, -3.5907e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8339e+00, -1.6442e-01, -5.8586e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.2567e-01,  8.4569e-02, -1.4232e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.0944e-01, -9.3736e-01,  2.5191e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.7656e-01, -4.4325e-01,  1.4406e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.7518e-01, -4.4991e-01,  2.3346e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.5730e-01,  6.4026e-01, -2.8169e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4857e+00, -1.1478e+00, -7.5019e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0643e+00,  4.9295e-01, -2.3333e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8360e+00, -1.3035e+00, -4.9435e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.4228e+00,  6.3724e-01, -2.6276e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.7448e-01,  1.0254e+00,  1.3787e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1846e+00, -1.4703e+00,  1.3868e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.6373e-01, -4.2368e-01, -2.4990e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8254e-01, -1.4957e+00,  3.4913e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.0677e-01,  2.5191e-02, -1.2503e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.6656e-01, -2.2153e+00,  2.7685e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.7415e-01,  7.3580e-01, -5.9574e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.0771e-01, -1.2446e+00,  1.0964e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.1493e-01, -1.8573e+00, -1.5924e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2493e+00, -1.6668e+00,  1.7121e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.2991e-01,  5.0471e-01,  1.7083e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8542e-01,  7.3723e-01,  2.9391e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.2920e-02, -1.7436e+00, -2.9674e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1178e-01, -2.2789e-01, -5.0558e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8278e+00, -5.8807e-01,  8.3339e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1607e+00, -5.7854e-01, -1.9426e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.7034e-01, -9.8881e-01, -8.3478e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.9009e-01, -2.4156e+00, -2.2492e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1078e+00,  4.0182e-01,  1.0613e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00]], requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  29
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0116, grad_fn=<DivBackward0>)
Projection Loss:  tensor(475.9225, grad_fn=<AddBackward0>)
Total Loss:  tensor(475.9341, grad_fn=<AddBackward0>)
Gradients:
22.792821884155273
Gradient before update: tensor(29.4254)
Gradient after update: tensor(29.4254)
current Learning Rate:  0.0005
------------------------------------------------------------------------------------------------------------------
Iteration:  30
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0115, grad_fn=<DivBackward0>)
Projection Loss:  tensor(475.9131, grad_fn=<AddBackward0>)
Total Loss:  tensor(475.9246, grad_fn=<AddBackward0>)
Gradients:
20.054582595825195
Gradient before update: tensor(27.3700)
Gradient after update: tensor(27.3700)
current Learning Rate:  0.00025
Total Loss:  tensor(475.9246, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 4.3390e-01,  3.7890e-01, -3.6365e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0181e-01,  5.9842e-01,  1.7917e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.7501e+00,  4.5722e-01,  2.7561e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.3144e-01,  2.4351e-01,  2.7943e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.5199e-03,  1.2914e-02,  7.1678e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1842e+00,  2.3707e-01, -8.2827e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.7323e-01,  5.2928e-01, -5.6409e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2568e+00,  3.8040e-01,  7.6996e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.8461e-01, -2.2094e+00, -1.3259e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.9509e-01, -2.7684e-01,  1.0809e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.5457e+00, -1.5028e+00, -3.4392e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.0758e+00, -5.0439e-01,  9.5817e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.7091e-01, -3.7371e-01, -2.1635e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.2648e+00,  1.0527e+00,  3.2822e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1965e+00, -8.3254e-01, -3.2398e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2926e+00,  1.0503e+00, -3.4438e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.5059e+00,  9.2083e-01,  2.1498e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.2555e-02, -7.5424e-01,  2.9154e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8759e-01,  8.4923e-01, -1.9932e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.4048e-01, -1.2213e+00,  3.7278e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4626e+00,  8.6368e-01, -3.4042e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2058e+00,  9.5415e-01,  1.6515e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.2946e-01,  8.9504e-01, -1.0892e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.2848e-01,  9.7958e-01, -1.4874e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2615e+00, -8.6596e-02, -1.6192e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 6.2008e-01, -6.3118e-01, -3.5898e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8342e+00, -1.6446e-01, -5.8577e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-5.2565e-01,  8.4613e-02, -1.4231e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 9.1013e-01, -9.3831e-01,  2.5211e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.7576e-01, -4.4415e-01,  1.4406e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.7590e-01, -4.4918e-01,  2.3344e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 4.5646e-01,  6.4117e-01, -2.8169e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.4858e+00, -1.1479e+00, -7.5010e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.0633e+00,  4.9385e-01, -2.3334e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8361e+00, -1.3037e+00, -4.9452e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.4232e+00,  6.3762e-01, -2.6275e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 7.7464e-01,  1.0255e+00,  1.3789e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1846e+00, -1.4703e+00,  1.3868e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.6323e-01, -4.2416e-01, -2.4991e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8260e-01, -1.4956e+00,  3.4908e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.0642e-01,  2.4345e-02, -1.2503e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.6658e-01, -2.2155e+00,  2.7739e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-3.7410e-01,  7.3585e-01, -5.9624e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 5.0689e-01, -1.2436e+00,  1.0957e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.1450e-01, -1.8569e+00, -1.5920e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.2492e+00, -1.6672e+00,  1.7121e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 3.2907e-01,  5.0367e-01,  1.7066e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-7.8461e-01,  7.3644e-01,  2.9385e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-4.2682e-02, -1.7440e+00, -2.9672e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1085e-01, -2.2855e-01, -5.0830e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.8280e+00, -5.8816e-01,  8.3320e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 1.1610e+00, -5.7859e-01, -1.9425e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-6.7036e-01, -9.8909e-01, -8.3485e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [ 8.9025e-01, -2.4157e+00, -2.2491e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00],
        [-1.1074e+00,  4.0150e-01,  1.0612e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00]], requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  31
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0114, grad_fn=<DivBackward0>)
Projection Loss:  tensor(475.9028, grad_fn=<AddBackward0>)
Total Loss:  tensor(475.9142, grad_fn=<AddBackward0>)
Gradients:
25.383874893188477
Gradient before update: tensor(32.3782)
Gradient after update: tensor(32.3782)
current Learning Rate:  0.00025
------------------------------------------------------------------------------------------------------------------
Iteration:  32
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0113, grad_fn=<DivBackward0>)
Projection Loss:  tensor(475.8963, grad_fn=<AddBackward0>)
Total Loss:  tensor(475.9076, grad_fn=<AddBackward0>)
Gradients:
29.956071853637695
Gradient before update: tensor(36.8047)
Gradient after update: tensor(36.8047)
current Learning Rate:  0.00025
Total Loss:  tensor(475.9076, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4335,  0.3785, -3.6361,  0.0000,  0.0000,  0.0000],
        [-0.1015,  0.5987,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7501,  0.4572,  2.7561,  0.0000,  0.0000,  0.0000],
        [ 0.8317,  0.2431,  2.7942,  0.0000,  0.0000,  0.0000],
        [-0.0040,  0.0134,  0.7167,  0.0000,  0.0000,  0.0000],
        [ 1.1843,  0.2370, -0.8284,  0.0000,  0.0000,  0.0000],
        [ 0.4727,  0.5287, -0.5642,  0.0000,  0.0000,  0.0000],
        [ 1.2569,  0.3804,  0.7699,  0.0000,  0.0000,  0.0000],
        [-0.5846, -2.2094, -1.3259,  0.0000,  0.0000,  0.0000],
        [ 0.8952, -0.2767,  1.0810,  0.0000,  0.0000,  0.0000],
        [-1.5455, -1.5029, -3.4394,  0.0000,  0.0000,  0.0000],
        [-1.0762, -0.5041,  0.9582,  0.0000,  0.0000,  0.0000],
        [ 0.3714, -0.3742, -2.1632,  0.0000,  0.0000,  0.0000],
        [ 1.2649,  1.0527,  3.2822,  0.0000,  0.0000,  0.0000],
        [-1.1966, -0.8326, -3.2398,  0.0000,  0.0000,  0.0000],
        [-1.2927,  1.0501, -3.4443,  0.0000,  0.0000,  0.0000],
        [ 1.5060,  0.9209,  2.1497,  0.0000,  0.0000,  0.0000],
        [ 0.0723, -0.7545,  2.9153,  0.0000,  0.0000,  0.0000],
        [-0.7875,  0.8493, -1.9932,  0.0000,  0.0000,  0.0000],
        [-0.3403, -1.2213,  0.3728,  0.0000,  0.0000,  0.0000],
        [ 1.4632,  0.8633, -0.3405,  0.0000,  0.0000,  0.0000],
        [-1.2055,  0.9546,  1.6513,  0.0000,  0.0000,  0.0000],
        [ 0.9299,  0.8947, -1.0887,  0.0000,  0.0000,  0.0000],
        [ 0.4291,  0.9790, -1.4876,  0.0000,  0.0000,  0.0000],
        [-1.2615, -0.0867, -1.6192,  0.0000,  0.0000,  0.0000],
        [ 0.6197, -0.6316, -3.5894,  0.0000,  0.0000,  0.0000],
        [-1.8343, -0.1645, -0.5857,  0.0000,  0.0000,  0.0000],
        [-0.5256,  0.0846, -1.4231,  0.0000,  0.0000,  0.0000],
        [ 0.9105, -0.9388,  0.2522,  0.0000,  0.0000,  0.0000],
        [ 0.1754, -0.4446,  1.4405,  0.0000,  0.0000,  0.0000],
        [-0.6763, -0.4488,  2.3343,  0.0000,  0.0000,  0.0000],
        [ 0.4560,  0.6416, -2.8168,  0.0000,  0.0000,  0.0000],
        [ 1.4858, -1.1479, -0.7501,  0.0000,  0.0000,  0.0000],
        [ 1.0629,  0.4943, -2.3334,  0.0000,  0.0000,  0.0000],
        [-1.8361, -1.3038, -0.4946,  0.0000,  0.0000,  0.0000],
        [-1.4234,  0.6378, -2.6275,  0.0000,  0.0000,  0.0000],
        [ 0.7747,  1.0256,  1.3789,  0.0000,  0.0000,  0.0000],
        [ 1.1846, -1.4703,  1.3868,  0.0000,  0.0000,  0.0000],
        [-0.4630, -0.4244, -2.4991,  0.0000,  0.0000,  0.0000],
        [-0.7826, -1.4956,  3.4906,  0.0000,  0.0000,  0.0000],
        [ 0.5063,  0.0239, -1.2502,  0.0000,  0.0000,  0.0000],
        [ 0.1666, -2.2156,  0.2777,  0.0000,  0.0000,  0.0000],
        [-0.3741,  0.7359, -0.0596,  0.0000,  0.0000,  0.0000],
        [ 0.5065, -1.2432,  1.0953,  0.0000,  0.0000,  0.0000],
        [ 0.8143, -1.8567, -1.5918,  0.0000,  0.0000,  0.0000],
        [-1.2491, -1.6674,  1.7121,  0.0000,  0.0000,  0.0000],
        [ 0.3287,  0.5032,  0.1705,  0.0000,  0.0000,  0.0000],
        [-0.7842,  0.7361,  2.9382,  0.0000,  0.0000,  0.0000],
        [-0.0426, -1.7442, -2.9671,  0.0000,  0.0000,  0.0000],
        [ 0.1104, -0.2289, -0.0509,  0.0000,  0.0000,  0.0000],
        [-1.8281, -0.5882,  0.8331,  0.0000,  0.0000,  0.0000],
        [ 1.1611, -0.5786, -1.9424,  0.0000,  0.0000,  0.0000],
        [-0.6704, -0.9892, -0.8349,  0.0000,  0.0000,  0.0000],
        [ 0.8903, -2.4157, -2.2490,  0.0000,  0.0000,  0.0000],
        [-1.1073,  0.4013,  1.0612,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  33
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0113, grad_fn=<DivBackward0>)
Projection Loss:  tensor(475.8879, grad_fn=<AddBackward0>)
Total Loss:  tensor(475.8992, grad_fn=<AddBackward0>)
Gradients:
36.01136016845703
Gradient before update: tensor(42.4668)
Gradient after update: tensor(42.4668)
current Learning Rate:  0.00025
------------------------------------------------------------------------------------------------------------------
Iteration:  34
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0113, grad_fn=<DivBackward0>)
Projection Loss:  tensor(475.8766, grad_fn=<AddBackward0>)
Total Loss:  tensor(475.8878, grad_fn=<AddBackward0>)
Gradients:
44.604705810546875
Gradient before update: tensor(49.7003)
Gradient after update: tensor(49.7003)
current Learning Rate:  0.00025
Total Loss:  tensor(475.8878, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4331,  0.3780, -3.6356,  0.0000,  0.0000,  0.0000],
        [-0.1012,  0.5990,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7501,  0.4572,  2.7561,  0.0000,  0.0000,  0.0000],
        [ 0.8319,  0.2426,  2.7941,  0.0000,  0.0000,  0.0000],
        [-0.0044,  0.0138,  0.7166,  0.0000,  0.0000,  0.0000],
        [ 1.1844,  0.2369, -0.8285,  0.0000,  0.0000,  0.0000],
        [ 0.4722,  0.5281, -0.5644,  0.0000,  0.0000,  0.0000],
        [ 1.2569,  0.3803,  0.7699,  0.0000,  0.0000,  0.0000],
        [-0.5846, -2.2094, -1.3259,  0.0000,  0.0000,  0.0000],
        [ 0.8953, -0.2766,  1.0810,  0.0000,  0.0000,  0.0000],
        [-1.5453, -1.5030, -3.4396,  0.0000,  0.0000,  0.0000],
        [-1.0765, -0.5038,  0.9582,  0.0000,  0.0000,  0.0000],
        [ 0.3719, -0.3747, -2.1630,  0.0000,  0.0000,  0.0000],
        [ 1.2649,  1.0528,  3.2822,  0.0000,  0.0000,  0.0000],
        [-1.1966, -0.8326, -3.2399,  0.0000,  0.0000,  0.0000],
        [-1.2928,  1.0500, -3.4447,  0.0000,  0.0000,  0.0000],
        [ 1.5062,  0.9210,  2.1496,  0.0000,  0.0000,  0.0000],
        [ 0.0720, -0.7548,  2.9153,  0.0000,  0.0000,  0.0000],
        [-0.7875,  0.8493, -1.9932,  0.0000,  0.0000,  0.0000],
        [-0.3401, -1.2214,  0.3728,  0.0000,  0.0000,  0.0000],
        [ 1.4637,  0.8629, -0.3405,  0.0000,  0.0000,  0.0000],
        [-1.2051,  0.9550,  1.6511,  0.0000,  0.0000,  0.0000],
        [ 0.9304,  0.8945, -1.0882,  0.0000,  0.0000,  0.0000],
        [ 0.4297,  0.9783, -1.4876,  0.0000,  0.0000,  0.0000],
        [-1.2616, -0.0867, -1.6193,  0.0000,  0.0000,  0.0000],
        [ 0.6193, -0.6319, -3.5890,  0.0000,  0.0000,  0.0000],
        [-1.8344, -0.1645, -0.5857,  0.0000,  0.0000,  0.0000],
        [-0.5256,  0.0846, -1.4231,  0.0000,  0.0000,  0.0000],
        [ 0.9108, -0.9393,  0.2524,  0.0000,  0.0000,  0.0000],
        [ 0.1750, -0.4450,  1.4405,  0.0000,  0.0000,  0.0000],
        [-0.6766, -0.4484,  2.3342,  0.0000,  0.0000,  0.0000],
        [ 0.4556,  0.6421, -2.8168,  0.0000,  0.0000,  0.0000],
        [ 1.4858, -1.1480, -0.7500,  0.0000,  0.0000,  0.0000],
        [ 1.0624,  0.4947, -2.3334,  0.0000,  0.0000,  0.0000],
        [-1.8362, -1.3038, -0.4947,  0.0000,  0.0000,  0.0000],
        [-1.4236,  0.6380, -2.6275,  0.0000,  0.0000,  0.0000],
        [ 0.7748,  1.0257,  1.3790,  0.0000,  0.0000,  0.0000],
        [ 1.1846, -1.4704,  1.3868,  0.0000,  0.0000,  0.0000],
        [-0.4628, -0.4246, -2.4991,  0.0000,  0.0000,  0.0000],
        [-0.7826, -1.4956,  3.4904,  0.0000,  0.0000,  0.0000],
        [ 0.5061,  0.0235, -1.2502,  0.0000,  0.0000,  0.0000],
        [ 0.1666, -2.2156,  0.2779,  0.0000,  0.0000,  0.0000],
        [-0.3741,  0.7359, -0.0597,  0.0000,  0.0000,  0.0000],
        [ 0.5062, -1.2428,  1.0950,  0.0000,  0.0000,  0.0000],
        [ 0.8142, -1.8565, -1.5917,  0.0000,  0.0000,  0.0000],
        [-1.2490, -1.6675,  1.7120,  0.0000,  0.0000,  0.0000],
        [ 0.3282,  0.5027,  0.1704,  0.0000,  0.0000,  0.0000],
        [-0.7838,  0.7357,  2.9379,  0.0000,  0.0000,  0.0000],
        [-0.0424, -1.7444, -2.9670,  0.0000,  0.0000,  0.0000],
        [ 0.1099, -0.2292, -0.0510,  0.0000,  0.0000,  0.0000],
        [-1.8282, -0.5883,  0.8331,  0.0000,  0.0000,  0.0000],
        [ 1.1612, -0.5786, -1.9424,  0.0000,  0.0000,  0.0000],
        [-0.6704, -0.9894, -0.8348,  0.0000,  0.0000,  0.0000],
        [ 0.8904, -2.4157, -2.2489,  0.0000,  0.0000,  0.0000],
        [-1.1071,  0.4012,  1.0611,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  35
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0113, grad_fn=<DivBackward0>)
Projection Loss:  tensor(475.8605, grad_fn=<AddBackward0>)
Total Loss:  tensor(475.8718, grad_fn=<AddBackward0>)
Gradients:
58.19682312011719
Gradient before update: tensor(59.5994)
Gradient after update: tensor(59.5994)
current Learning Rate:  0.00025
------------------------------------------------------------------------------------------------------------------
Iteration:  36
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0113, grad_fn=<DivBackward0>)
Projection Loss:  tensor(475.0805, grad_fn=<AddBackward0>)
Total Loss:  tensor(475.0918, grad_fn=<AddBackward0>)
Gradients:
2418.86181640625
Gradient before update: tensor(-9.4292)
Gradient after update: tensor(-9.4292)
current Learning Rate:  0.00025
Total Loss:  tensor(475.0918, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4326,  0.3776, -3.6352,  0.0000,  0.0000,  0.0000],
        [-0.1009,  0.5994,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7501,  0.4573,  2.7560,  0.0000,  0.0000,  0.0000],
        [ 0.8321,  0.2422,  2.7940,  0.0000,  0.0000,  0.0000],
        [-0.0049,  0.0142,  0.7165,  0.0000,  0.0000,  0.0000],
        [ 1.1845,  0.2368, -0.8285,  0.0000,  0.0000,  0.0000],
        [ 0.4716,  0.5275, -0.5647,  0.0000,  0.0000,  0.0000],
        [ 1.2569,  0.3803,  0.7699,  0.0000,  0.0000,  0.0000],
        [-0.5846, -2.2094, -1.3259,  0.0000,  0.0000,  0.0000],
        [ 0.8954, -0.2766,  1.0811,  0.0000,  0.0000,  0.0000],
        [-1.5451, -1.5032, -3.4397,  0.0000,  0.0000,  0.0000],
        [-1.0769, -0.5035,  0.9582,  0.0000,  0.0000,  0.0000],
        [ 0.3724, -0.3753, -2.1630,  0.0000,  0.0000,  0.0000],
        [ 1.2649,  1.0528,  3.2821,  0.0000,  0.0000,  0.0000],
        [-1.1967, -0.8326, -3.2399,  0.0000,  0.0000,  0.0000],
        [-1.2929,  1.0499, -3.4451,  0.0000,  0.0000,  0.0000],
        [ 1.5064,  0.9211,  2.1495,  0.0000,  0.0000,  0.0000],
        [ 0.0718, -0.7551,  2.9152,  0.0000,  0.0000,  0.0000],
        [-0.7874,  0.8494, -1.9932,  0.0000,  0.0000,  0.0000],
        [-0.3398, -1.2215,  0.3728,  0.0000,  0.0000,  0.0000],
        [ 1.4641,  0.8625, -0.3404,  0.0000,  0.0000,  0.0000],
        [-1.2048,  0.9555,  1.6510,  0.0000,  0.0000,  0.0000],
        [ 0.9308,  0.8943, -1.0878,  0.0000,  0.0000,  0.0000],
        [ 0.4303,  0.9777, -1.4873,  0.0000,  0.0000,  0.0000],
        [-1.2616, -0.0867, -1.6193,  0.0000,  0.0000,  0.0000],
        [ 0.6190, -0.6323, -3.5886,  0.0000,  0.0000,  0.0000],
        [-1.8345, -0.1645, -0.5856,  0.0000,  0.0000,  0.0000],
        [-0.5256,  0.0847, -1.4231,  0.0000,  0.0000,  0.0000],
        [ 0.9112, -0.9397,  0.2526,  0.0000,  0.0000,  0.0000],
        [ 0.1746, -0.4455,  1.4404,  0.0000,  0.0000,  0.0000],
        [-0.6770, -0.4480,  2.3341,  0.0000,  0.0000,  0.0000],
        [ 0.4552,  0.6426, -2.8169,  0.0000,  0.0000,  0.0000],
        [ 1.4859, -1.1480, -0.7500,  0.0000,  0.0000,  0.0000],
        [ 1.0619,  0.4952, -2.3335,  0.0000,  0.0000,  0.0000],
        [-1.8362, -1.3039, -0.4947,  0.0000,  0.0000,  0.0000],
        [-1.4238,  0.6381, -2.6275,  0.0000,  0.0000,  0.0000],
        [ 0.7748,  1.0257,  1.3790,  0.0000,  0.0000,  0.0000],
        [ 1.1846, -1.4704,  1.3868,  0.0000,  0.0000,  0.0000],
        [-0.4625, -0.4248, -2.4991,  0.0000,  0.0000,  0.0000],
        [-0.7827, -1.4955,  3.4902,  0.0000,  0.0000,  0.0000],
        [ 0.5060,  0.0230, -1.2502,  0.0000,  0.0000,  0.0000],
        [ 0.1667, -2.2157,  0.2782,  0.0000,  0.0000,  0.0000],
        [-0.3740,  0.7359, -0.0597,  0.0000,  0.0000,  0.0000],
        [ 0.5060, -1.2426,  1.0948,  0.0000,  0.0000,  0.0000],
        [ 0.8141, -1.8564, -1.5915,  0.0000,  0.0000,  0.0000],
        [-1.2489, -1.6677,  1.7120,  0.0000,  0.0000,  0.0000],
        [ 0.3278,  0.5022,  0.1702,  0.0000,  0.0000,  0.0000],
        [-0.7834,  0.7353,  2.9375,  0.0000,  0.0000,  0.0000],
        [-0.0423, -1.7446, -2.9669,  0.0000,  0.0000,  0.0000],
        [ 0.1095, -0.2296, -0.0510,  0.0000,  0.0000,  0.0000],
        [-1.8283, -0.5883,  0.8330,  0.0000,  0.0000,  0.0000],
        [ 1.1613, -0.5786, -1.9423,  0.0000,  0.0000,  0.0000],
        [-0.6705, -0.9896, -0.8348,  0.0000,  0.0000,  0.0000],
        [ 0.8904, -2.4158, -2.2489,  0.0000,  0.0000,  0.0000],
        [-1.1070,  0.4010,  1.0611,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  37
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0113, grad_fn=<DivBackward0>)
Projection Loss:  tensor(474.8522, grad_fn=<AddBackward0>)
Total Loss:  tensor(474.8635, grad_fn=<AddBackward0>)
Gradients:
303.5301818847656
Gradient before update: tensor(93.2538)
Gradient after update: tensor(93.2538)
current Learning Rate:  0.00025
------------------------------------------------------------------------------------------------------------------
Iteration:  38
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0113, grad_fn=<DivBackward0>)
Projection Loss:  tensor(474.7429, grad_fn=<AddBackward0>)
Total Loss:  tensor(474.7542, grad_fn=<AddBackward0>)
Gradients:
300.8124694824219
Gradient before update: tensor(167.0304)
Gradient after update: tensor(167.0304)
current Learning Rate:  0.00025
Total Loss:  tensor(474.7542, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4322,  0.3772, -3.6347,  0.0000,  0.0000,  0.0000],
        [-0.1007,  0.5997,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7501,  0.4573,  2.7560,  0.0000,  0.0000,  0.0000],
        [ 0.8323,  0.2418,  2.7939,  0.0000,  0.0000,  0.0000],
        [-0.0054,  0.0147,  0.7164,  0.0000,  0.0000,  0.0000],
        [ 1.1846,  0.2367, -0.8286,  0.0000,  0.0000,  0.0000],
        [ 0.4710,  0.5269, -0.5649,  0.0000,  0.0000,  0.0000],
        [ 1.2570,  0.3803,  0.7699,  0.0000,  0.0000,  0.0000],
        [-0.5846, -2.2095, -1.3259,  0.0000,  0.0000,  0.0000],
        [ 0.8955, -0.2765,  1.0811,  0.0000,  0.0000,  0.0000],
        [-1.5449, -1.5033, -3.4399,  0.0000,  0.0000,  0.0000],
        [-1.0773, -0.5032,  0.9582,  0.0000,  0.0000,  0.0000],
        [ 0.3729, -0.3758, -2.1630,  0.0000,  0.0000,  0.0000],
        [ 1.2650,  1.0528,  3.2821,  0.0000,  0.0000,  0.0000],
        [-1.1967, -0.8327, -3.2400,  0.0000,  0.0000,  0.0000],
        [-1.2929,  1.0497, -3.4455,  0.0000,  0.0000,  0.0000],
        [ 1.5065,  0.9212,  2.1493,  0.0000,  0.0000,  0.0000],
        [ 0.0716, -0.7553,  2.9152,  0.0000,  0.0000,  0.0000],
        [-0.7874,  0.8494, -1.9932,  0.0000,  0.0000,  0.0000],
        [-0.3396, -1.2215,  0.3727,  0.0000,  0.0000,  0.0000],
        [ 1.4644,  0.8622, -0.3401,  0.0000,  0.0000,  0.0000],
        [-1.2045,  0.9560,  1.6508,  0.0000,  0.0000,  0.0000],
        [ 0.9312,  0.8941, -1.0873,  0.0000,  0.0000,  0.0000],
        [ 0.4309,  0.9772, -1.4868,  0.0000,  0.0000,  0.0000],
        [-1.2616, -0.0868, -1.6194,  0.0000,  0.0000,  0.0000],
        [ 0.6186, -0.6327, -3.5881,  0.0000,  0.0000,  0.0000],
        [-1.8346, -0.1645, -0.5856,  0.0000,  0.0000,  0.0000],
        [-0.5256,  0.0847, -1.4231,  0.0000,  0.0000,  0.0000],
        [ 0.9115, -0.9402,  0.2527,  0.0000,  0.0000,  0.0000],
        [ 0.1742, -0.4459,  1.4404,  0.0000,  0.0000,  0.0000],
        [-0.6774, -0.4476,  2.3341,  0.0000,  0.0000,  0.0000],
        [ 0.4547,  0.6431, -2.8170,  0.0000,  0.0000,  0.0000],
        [ 1.4859, -1.1480, -0.7500,  0.0000,  0.0000,  0.0000],
        [ 1.0615,  0.4956, -2.3335,  0.0000,  0.0000,  0.0000],
        [-1.8362, -1.3039, -0.4948,  0.0000,  0.0000,  0.0000],
        [-1.4239,  0.6382, -2.6275,  0.0000,  0.0000,  0.0000],
        [ 0.7749,  1.0258,  1.3791,  0.0000,  0.0000,  0.0000],
        [ 1.1846, -1.4704,  1.3868,  0.0000,  0.0000,  0.0000],
        [-0.4623, -0.4250, -2.4991,  0.0000,  0.0000,  0.0000],
        [-0.7827, -1.4955,  3.4900,  0.0000,  0.0000,  0.0000],
        [ 0.5059,  0.0226, -1.2501,  0.0000,  0.0000,  0.0000],
        [ 0.1667, -2.2157,  0.2785,  0.0000,  0.0000,  0.0000],
        [-0.3740,  0.7359, -0.0597,  0.0000,  0.0000,  0.0000],
        [ 0.5058, -1.2424,  1.0946,  0.0000,  0.0000,  0.0000],
        [ 0.8140, -1.8563, -1.5914,  0.0000,  0.0000,  0.0000],
        [-1.2489, -1.6679,  1.7120,  0.0000,  0.0000,  0.0000],
        [ 0.3274,  0.5017,  0.1700,  0.0000,  0.0000,  0.0000],
        [-0.7831,  0.7349,  2.9372,  0.0000,  0.0000,  0.0000],
        [-0.0422, -1.7448, -2.9668,  0.0000,  0.0000,  0.0000],
        [ 0.1090, -0.2299, -0.0510,  0.0000,  0.0000,  0.0000],
        [-1.8284, -0.5884,  0.8330,  0.0000,  0.0000,  0.0000],
        [ 1.1614, -0.5786, -1.9422,  0.0000,  0.0000,  0.0000],
        [-0.6705, -0.9898, -0.8348,  0.0000,  0.0000,  0.0000],
        [ 0.8904, -2.4158, -2.2489,  0.0000,  0.0000,  0.0000],
        [-1.1069,  0.4009,  1.0610,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  39
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0113, grad_fn=<DivBackward0>)
Projection Loss:  tensor(474.5471, grad_fn=<AddBackward0>)
Total Loss:  tensor(474.5584, grad_fn=<AddBackward0>)
Gradients:
893.2484130859375
Gradient before update: tensor(417.1810)
Gradient after update: tensor(417.1810)
current Learning Rate:  0.00025
------------------------------------------------------------------------------------------------------------------
Iteration:  40
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0113, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9694, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9807, grad_fn=<AddBackward0>)
Gradients:
55.31373977661133
Gradient before update: tensor(59.8746)
Gradient after update: tensor(59.8746)
current Learning Rate:  0.00025
Total Loss:  tensor(473.9807, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4318,  0.3767, -3.6343,  0.0000,  0.0000,  0.0000],
        [-0.1004,  0.5999,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7501,  0.4573,  2.7560,  0.0000,  0.0000,  0.0000],
        [ 0.8325,  0.2413,  2.7938,  0.0000,  0.0000,  0.0000],
        [-0.0058,  0.0151,  0.7163,  0.0000,  0.0000,  0.0000],
        [ 1.1846,  0.2366, -0.8287,  0.0000,  0.0000,  0.0000],
        [ 0.4705,  0.5264, -0.5650,  0.0000,  0.0000,  0.0000],
        [ 1.2570,  0.3803,  0.7699,  0.0000,  0.0000,  0.0000],
        [-0.5846, -2.2095, -1.3259,  0.0000,  0.0000,  0.0000],
        [ 0.8956, -0.2764,  1.0811,  0.0000,  0.0000,  0.0000],
        [-1.5448, -1.5034, -3.4401,  0.0000,  0.0000,  0.0000],
        [-1.0776, -0.5029,  0.9582,  0.0000,  0.0000,  0.0000],
        [ 0.3734, -0.3763, -2.1632,  0.0000,  0.0000,  0.0000],
        [ 1.2650,  1.0528,  3.2821,  0.0000,  0.0000,  0.0000],
        [-1.1967, -0.8327, -3.2400,  0.0000,  0.0000,  0.0000],
        [-1.2930,  1.0496, -3.4458,  0.0000,  0.0000,  0.0000],
        [ 1.5066,  0.9214,  2.1492,  0.0000,  0.0000,  0.0000],
        [ 0.0713, -0.7556,  2.9152,  0.0000,  0.0000,  0.0000],
        [-0.7874,  0.8495, -1.9932,  0.0000,  0.0000,  0.0000],
        [-0.3395, -1.2216,  0.3727,  0.0000,  0.0000,  0.0000],
        [ 1.4646,  0.8620, -0.3398,  0.0000,  0.0000,  0.0000],
        [-1.2041,  0.9565,  1.6507,  0.0000,  0.0000,  0.0000],
        [ 0.9317,  0.8940, -1.0868,  0.0000,  0.0000,  0.0000],
        [ 0.4313,  0.9767, -1.4864,  0.0000,  0.0000,  0.0000],
        [-1.2616, -0.0868, -1.6194,  0.0000,  0.0000,  0.0000],
        [ 0.6182, -0.6330, -3.5877,  0.0000,  0.0000,  0.0000],
        [-1.8347, -0.1645, -0.5855,  0.0000,  0.0000,  0.0000],
        [-0.5256,  0.0847, -1.4231,  0.0000,  0.0000,  0.0000],
        [ 0.9118, -0.9407,  0.2528,  0.0000,  0.0000,  0.0000],
        [ 0.1738, -0.4463,  1.4403,  0.0000,  0.0000,  0.0000],
        [-0.6778, -0.4472,  2.3340,  0.0000,  0.0000,  0.0000],
        [ 0.4542,  0.6436, -2.8171,  0.0000,  0.0000,  0.0000],
        [ 1.4859, -1.1480, -0.7500,  0.0000,  0.0000,  0.0000],
        [ 1.0610,  0.4961, -2.3335,  0.0000,  0.0000,  0.0000],
        [-1.8362, -1.3040, -0.4948,  0.0000,  0.0000,  0.0000],
        [-1.4241,  0.6384, -2.6275,  0.0000,  0.0000,  0.0000],
        [ 0.7749,  1.0258,  1.3791,  0.0000,  0.0000,  0.0000],
        [ 1.1846, -1.4704,  1.3869,  0.0000,  0.0000,  0.0000],
        [-0.4621, -0.4252, -2.4992,  0.0000,  0.0000,  0.0000],
        [-0.7827, -1.4955,  3.4898,  0.0000,  0.0000,  0.0000],
        [ 0.5058,  0.0221, -1.2501,  0.0000,  0.0000,  0.0000],
        [ 0.1668, -2.2157,  0.2787,  0.0000,  0.0000,  0.0000],
        [-0.3740,  0.7359, -0.0597,  0.0000,  0.0000,  0.0000],
        [ 0.5056, -1.2423,  1.0945,  0.0000,  0.0000,  0.0000],
        [ 0.8139, -1.8562, -1.5914,  0.0000,  0.0000,  0.0000],
        [-1.2488, -1.6680,  1.7120,  0.0000,  0.0000,  0.0000],
        [ 0.3270,  0.5012,  0.1698,  0.0000,  0.0000,  0.0000],
        [-0.7827,  0.7346,  2.9369,  0.0000,  0.0000,  0.0000],
        [-0.0421, -1.7449, -2.9667,  0.0000,  0.0000,  0.0000],
        [ 0.1085, -0.2303, -0.0510,  0.0000,  0.0000,  0.0000],
        [-1.8285, -0.5884,  0.8330,  0.0000,  0.0000,  0.0000],
        [ 1.1615, -0.5787, -1.9421,  0.0000,  0.0000,  0.0000],
        [-0.6706, -0.9899, -0.8347,  0.0000,  0.0000,  0.0000],
        [ 0.8905, -2.4158, -2.2488,  0.0000,  0.0000,  0.0000],
        [-1.1067,  0.4008,  1.0609,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  41
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0113, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9675, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9788, grad_fn=<AddBackward0>)
Gradients:
56.66376876831055
Gradient before update: tensor(63.7129)
Gradient after update: tensor(63.7129)
current Learning Rate:  0.00025
------------------------------------------------------------------------------------------------------------------
Iteration:  42
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0113, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9666, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9779, grad_fn=<AddBackward0>)
Gradients:
58.96992492675781
Gradient before update: tensor(67.1700)
Gradient after update: tensor(67.1700)
current Learning Rate:  0.00025
Total Loss:  tensor(473.9779, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4314,  0.3763, -3.6338,  0.0000,  0.0000,  0.0000],
        [-0.1001,  0.6002,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7501,  0.4573,  2.7560,  0.0000,  0.0000,  0.0000],
        [ 0.8327,  0.2409,  2.7938,  0.0000,  0.0000,  0.0000],
        [-0.0063,  0.0156,  0.7161,  0.0000,  0.0000,  0.0000],
        [ 1.1847,  0.2366, -0.8287,  0.0000,  0.0000,  0.0000],
        [ 0.4701,  0.5259, -0.5651,  0.0000,  0.0000,  0.0000],
        [ 1.2570,  0.3802,  0.7699,  0.0000,  0.0000,  0.0000],
        [-0.5846, -2.2095, -1.3259,  0.0000,  0.0000,  0.0000],
        [ 0.8956, -0.2763,  1.0811,  0.0000,  0.0000,  0.0000],
        [-1.5446, -1.5035, -3.4402,  0.0000,  0.0000,  0.0000],
        [-1.0780, -0.5027,  0.9582,  0.0000,  0.0000,  0.0000],
        [ 0.3739, -0.3768, -2.1633,  0.0000,  0.0000,  0.0000],
        [ 1.2650,  1.0528,  3.2821,  0.0000,  0.0000,  0.0000],
        [-1.1968, -0.8327, -3.2400,  0.0000,  0.0000,  0.0000],
        [-1.2930,  1.0495, -3.4462,  0.0000,  0.0000,  0.0000],
        [ 1.5068,  0.9215,  2.1491,  0.0000,  0.0000,  0.0000],
        [ 0.0711, -0.7558,  2.9153,  0.0000,  0.0000,  0.0000],
        [-0.7873,  0.8495, -1.9932,  0.0000,  0.0000,  0.0000],
        [-0.3393, -1.2216,  0.3727,  0.0000,  0.0000,  0.0000],
        [ 1.4649,  0.8617, -0.3396,  0.0000,  0.0000,  0.0000],
        [-1.2038,  0.9570,  1.6506,  0.0000,  0.0000,  0.0000],
        [ 0.9321,  0.8940, -1.0864,  0.0000,  0.0000,  0.0000],
        [ 0.4317,  0.9763, -1.4860,  0.0000,  0.0000,  0.0000],
        [-1.2616, -0.0868, -1.6194,  0.0000,  0.0000,  0.0000],
        [ 0.6179, -0.6334, -3.5873,  0.0000,  0.0000,  0.0000],
        [-1.8349, -0.1644, -0.5854,  0.0000,  0.0000,  0.0000],
        [-0.5257,  0.0847, -1.4231,  0.0000,  0.0000,  0.0000],
        [ 0.9121, -0.9411,  0.2529,  0.0000,  0.0000,  0.0000],
        [ 0.1735, -0.4468,  1.4402,  0.0000,  0.0000,  0.0000],
        [-0.6781, -0.4468,  2.3339,  0.0000,  0.0000,  0.0000],
        [ 0.4537,  0.6441, -2.8172,  0.0000,  0.0000,  0.0000],
        [ 1.4859, -1.1481, -0.7499,  0.0000,  0.0000,  0.0000],
        [ 1.0605,  0.4965, -2.3335,  0.0000,  0.0000,  0.0000],
        [-1.8363, -1.3040, -0.4949,  0.0000,  0.0000,  0.0000],
        [-1.4242,  0.6385, -2.6276,  0.0000,  0.0000,  0.0000],
        [ 0.7749,  1.0258,  1.3791,  0.0000,  0.0000,  0.0000],
        [ 1.1846, -1.4704,  1.3869,  0.0000,  0.0000,  0.0000],
        [-0.4619, -0.4254, -2.4992,  0.0000,  0.0000,  0.0000],
        [-0.7827, -1.4955,  3.4896,  0.0000,  0.0000,  0.0000],
        [ 0.5057,  0.0216, -1.2501,  0.0000,  0.0000,  0.0000],
        [ 0.1669, -2.2157,  0.2790,  0.0000,  0.0000,  0.0000],
        [-0.3740,  0.7359, -0.0597,  0.0000,  0.0000,  0.0000],
        [ 0.5054, -1.2422,  1.0943,  0.0000,  0.0000,  0.0000],
        [ 0.8138, -1.8562, -1.5913,  0.0000,  0.0000,  0.0000],
        [-1.2487, -1.6682,  1.7119,  0.0000,  0.0000,  0.0000],
        [ 0.3266,  0.5007,  0.1696,  0.0000,  0.0000,  0.0000],
        [-0.7823,  0.7342,  2.9366,  0.0000,  0.0000,  0.0000],
        [-0.0421, -1.7451, -2.9667,  0.0000,  0.0000,  0.0000],
        [ 0.1081, -0.2306, -0.0509,  0.0000,  0.0000,  0.0000],
        [-1.8286, -0.5885,  0.8330,  0.0000,  0.0000,  0.0000],
        [ 1.1616, -0.5787, -1.9421,  0.0000,  0.0000,  0.0000],
        [-0.6706, -0.9901, -0.8346,  0.0000,  0.0000,  0.0000],
        [ 0.8905, -2.4158, -2.2488,  0.0000,  0.0000,  0.0000],
        [-1.1066,  0.4006,  1.0609,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  43
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0113, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9661, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9774, grad_fn=<AddBackward0>)
Gradients:
61.36225891113281
Gradient before update: tensor(70.2469)
Gradient after update: tensor(70.2469)
current Learning Rate:  0.00025
------------------------------------------------------------------------------------------------------------------
Iteration:  44
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0113, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9659, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9772, grad_fn=<AddBackward0>)
Gradients:
63.54410171508789
Gradient before update: tensor(72.9714)
Gradient after update: tensor(72.9714)
current Learning Rate:  0.00025
Total Loss:  tensor(473.9772, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4310,  0.3759, -3.6334,  0.0000,  0.0000,  0.0000],
        [-0.0998,  0.6005,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7502,  0.4573,  2.7560,  0.0000,  0.0000,  0.0000],
        [ 0.8329,  0.2405,  2.7938,  0.0000,  0.0000,  0.0000],
        [-0.0067,  0.0160,  0.7160,  0.0000,  0.0000,  0.0000],
        [ 1.1847,  0.2366, -0.8287,  0.0000,  0.0000,  0.0000],
        [ 0.4697,  0.5255, -0.5652,  0.0000,  0.0000,  0.0000],
        [ 1.2570,  0.3802,  0.7699,  0.0000,  0.0000,  0.0000],
        [-0.5846, -2.2095, -1.3260,  0.0000,  0.0000,  0.0000],
        [ 0.8957, -0.2762,  1.0812,  0.0000,  0.0000,  0.0000],
        [-1.5445, -1.5036, -3.4404,  0.0000,  0.0000,  0.0000],
        [-1.0783, -0.5024,  0.9582,  0.0000,  0.0000,  0.0000],
        [ 0.3744, -0.3773, -2.1636,  0.0000,  0.0000,  0.0000],
        [ 1.2650,  1.0528,  3.2821,  0.0000,  0.0000,  0.0000],
        [-1.1968, -0.8327, -3.2400,  0.0000,  0.0000,  0.0000],
        [-1.2930,  1.0493, -3.4465,  0.0000,  0.0000,  0.0000],
        [ 1.5069,  0.9216,  2.1489,  0.0000,  0.0000,  0.0000],
        [ 0.0708, -0.7561,  2.9153,  0.0000,  0.0000,  0.0000],
        [-0.7873,  0.8496, -1.9932,  0.0000,  0.0000,  0.0000],
        [-0.3391, -1.2217,  0.3726,  0.0000,  0.0000,  0.0000],
        [ 1.4650,  0.8616, -0.3394,  0.0000,  0.0000,  0.0000],
        [-1.2034,  0.9575,  1.6506,  0.0000,  0.0000,  0.0000],
        [ 0.9325,  0.8941, -1.0859,  0.0000,  0.0000,  0.0000],
        [ 0.4320,  0.9760, -1.4858,  0.0000,  0.0000,  0.0000],
        [-1.2617, -0.0868, -1.6195,  0.0000,  0.0000,  0.0000],
        [ 0.6175, -0.6338, -3.5869,  0.0000,  0.0000,  0.0000],
        [-1.8350, -0.1644, -0.5854,  0.0000,  0.0000,  0.0000],
        [-0.5257,  0.0847, -1.4231,  0.0000,  0.0000,  0.0000],
        [ 0.9124, -0.9416,  0.2530,  0.0000,  0.0000,  0.0000],
        [ 0.1731, -0.4472,  1.4401,  0.0000,  0.0000,  0.0000],
        [-0.6785, -0.4464,  2.3339,  0.0000,  0.0000,  0.0000],
        [ 0.4533,  0.6446, -2.8174,  0.0000,  0.0000,  0.0000],
        [ 1.4859, -1.1481, -0.7499,  0.0000,  0.0000,  0.0000],
        [ 1.0600,  0.4969, -2.3335,  0.0000,  0.0000,  0.0000],
        [-1.8363, -1.3041, -0.4949,  0.0000,  0.0000,  0.0000],
        [-1.4244,  0.6386, -2.6276,  0.0000,  0.0000,  0.0000],
        [ 0.7749,  1.0258,  1.3792,  0.0000,  0.0000,  0.0000],
        [ 1.1847, -1.4704,  1.3869,  0.0000,  0.0000,  0.0000],
        [-0.4617, -0.4256, -2.4992,  0.0000,  0.0000,  0.0000],
        [-0.7827, -1.4955,  3.4894,  0.0000,  0.0000,  0.0000],
        [ 0.5056,  0.0211, -1.2501,  0.0000,  0.0000,  0.0000],
        [ 0.1669, -2.2158,  0.2792,  0.0000,  0.0000,  0.0000],
        [-0.3740,  0.7359, -0.0597,  0.0000,  0.0000,  0.0000],
        [ 0.5053, -1.2421,  1.0942,  0.0000,  0.0000,  0.0000],
        [ 0.8137, -1.8561, -1.5912,  0.0000,  0.0000,  0.0000],
        [-1.2486, -1.6683,  1.7119,  0.0000,  0.0000,  0.0000],
        [ 0.3263,  0.5002,  0.1693,  0.0000,  0.0000,  0.0000],
        [-0.7819,  0.7339,  2.9363,  0.0000,  0.0000,  0.0000],
        [-0.0420, -1.7453, -2.9666,  0.0000,  0.0000,  0.0000],
        [ 0.1076, -0.2310, -0.0509,  0.0000,  0.0000,  0.0000],
        [-1.8287, -0.5885,  0.8330,  0.0000,  0.0000,  0.0000],
        [ 1.1617, -0.5787, -1.9420,  0.0000,  0.0000,  0.0000],
        [-0.6706, -0.9902, -0.8345,  0.0000,  0.0000,  0.0000],
        [ 0.8905, -2.4158, -2.2488,  0.0000,  0.0000,  0.0000],
        [-1.1065,  0.4005,  1.0608,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  45
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0113, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9660, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9772, grad_fn=<AddBackward0>)
Gradients:
65.4652099609375
Gradient before update: tensor(75.3623)
Gradient after update: tensor(75.3623)
current Learning Rate:  0.000125
------------------------------------------------------------------------------------------------------------------
Iteration:  46
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0112, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9661, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9773, grad_fn=<AddBackward0>)
Gradients:
67.0821762084961
Gradient before update: tensor(77.3721)
Gradient after update: tensor(77.3721)
current Learning Rate:  0.000125
Total Loss:  tensor(473.9773, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4307,  0.3755, -3.6330,  0.0000,  0.0000,  0.0000],
        [-0.0996,  0.6007,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7502,  0.4573,  2.7560,  0.0000,  0.0000,  0.0000],
        [ 0.8330,  0.2402,  2.7938,  0.0000,  0.0000,  0.0000],
        [-0.0070,  0.0163,  0.7159,  0.0000,  0.0000,  0.0000],
        [ 1.1847,  0.2365, -0.8288,  0.0000,  0.0000,  0.0000],
        [ 0.4695,  0.5253, -0.5653,  0.0000,  0.0000,  0.0000],
        [ 1.2570,  0.3802,  0.7699,  0.0000,  0.0000,  0.0000],
        [-0.5845, -2.2095, -1.3260,  0.0000,  0.0000,  0.0000],
        [ 0.8958, -0.2762,  1.0812,  0.0000,  0.0000,  0.0000],
        [-1.5443, -1.5037, -3.4405,  0.0000,  0.0000,  0.0000],
        [-1.0786, -0.5022,  0.9582,  0.0000,  0.0000,  0.0000],
        [ 0.3748, -0.3777, -2.1637,  0.0000,  0.0000,  0.0000],
        [ 1.2650,  1.0529,  3.2821,  0.0000,  0.0000,  0.0000],
        [-1.1968, -0.8327, -3.2400,  0.0000,  0.0000,  0.0000],
        [-1.2931,  1.0492, -3.4468,  0.0000,  0.0000,  0.0000],
        [ 1.5070,  0.9217,  2.1489,  0.0000,  0.0000,  0.0000],
        [ 0.0706, -0.7563,  2.9153,  0.0000,  0.0000,  0.0000],
        [-0.7872,  0.8496, -1.9932,  0.0000,  0.0000,  0.0000],
        [-0.3389, -1.2217,  0.3726,  0.0000,  0.0000,  0.0000],
        [ 1.4652,  0.8615, -0.3393,  0.0000,  0.0000,  0.0000],
        [-1.2032,  0.9579,  1.6506,  0.0000,  0.0000,  0.0000],
        [ 0.9328,  0.8942, -1.0856,  0.0000,  0.0000,  0.0000],
        [ 0.4322,  0.9759, -1.4856,  0.0000,  0.0000,  0.0000],
        [-1.2617, -0.0868, -1.6195,  0.0000,  0.0000,  0.0000],
        [ 0.6173, -0.6341, -3.5866,  0.0000,  0.0000,  0.0000],
        [-1.8350, -0.1644, -0.5853,  0.0000,  0.0000,  0.0000],
        [-0.5257,  0.0847, -1.4231,  0.0000,  0.0000,  0.0000],
        [ 0.9126, -0.9420,  0.2530,  0.0000,  0.0000,  0.0000],
        [ 0.1728, -0.4475,  1.4400,  0.0000,  0.0000,  0.0000],
        [-0.6788, -0.4461,  2.3338,  0.0000,  0.0000,  0.0000],
        [ 0.4529,  0.6449, -2.8176,  0.0000,  0.0000,  0.0000],
        [ 1.4859, -1.1481, -0.7499,  0.0000,  0.0000,  0.0000],
        [ 1.0597,  0.4972, -2.3335,  0.0000,  0.0000,  0.0000],
        [-1.8363, -1.3041, -0.4949,  0.0000,  0.0000,  0.0000],
        [-1.4245,  0.6387, -2.6277,  0.0000,  0.0000,  0.0000],
        [ 0.7749,  1.0258,  1.3792,  0.0000,  0.0000,  0.0000],
        [ 1.1847, -1.4704,  1.3869,  0.0000,  0.0000,  0.0000],
        [-0.4615, -0.4258, -2.4992,  0.0000,  0.0000,  0.0000],
        [-0.7827, -1.4955,  3.4893,  0.0000,  0.0000,  0.0000],
        [ 0.5055,  0.0208, -1.2501,  0.0000,  0.0000,  0.0000],
        [ 0.1670, -2.2158,  0.2794,  0.0000,  0.0000,  0.0000],
        [-0.3740,  0.7359, -0.0597,  0.0000,  0.0000,  0.0000],
        [ 0.5052, -1.2421,  1.0942,  0.0000,  0.0000,  0.0000],
        [ 0.8137, -1.8561, -1.5912,  0.0000,  0.0000,  0.0000],
        [-1.2486, -1.6684,  1.7119,  0.0000,  0.0000,  0.0000],
        [ 0.3260,  0.4999,  0.1692,  0.0000,  0.0000,  0.0000],
        [-0.7817,  0.7336,  2.9361,  0.0000,  0.0000,  0.0000],
        [-0.0419, -1.7454, -2.9665,  0.0000,  0.0000,  0.0000],
        [ 0.1073, -0.2312, -0.0509,  0.0000,  0.0000,  0.0000],
        [-1.8288, -0.5886,  0.8330,  0.0000,  0.0000,  0.0000],
        [ 1.1617, -0.5787, -1.9419,  0.0000,  0.0000,  0.0000],
        [-0.6706, -0.9903, -0.8345,  0.0000,  0.0000,  0.0000],
        [ 0.8905, -2.4158, -2.2488,  0.0000,  0.0000,  0.0000],
        [-1.1064,  0.4004,  1.0607,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  47
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0112, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9662, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9774, grad_fn=<AddBackward0>)
Gradients:
67.71246337890625
Gradient before update: tensor(78.1693)
Gradient after update: tensor(78.1693)
current Learning Rate:  0.000125
------------------------------------------------------------------------------------------------------------------
Iteration:  48
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0112, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9662, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9774, grad_fn=<AddBackward0>)
Gradients:
68.14433288574219
Gradient before update: tensor(78.7544)
Gradient after update: tensor(78.7544)
current Learning Rate:  0.000125
Total Loss:  tensor(473.9774, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4305,  0.3753, -3.6328,  0.0000,  0.0000,  0.0000],
        [-0.0995,  0.6009,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7502,  0.4573,  2.7560,  0.0000,  0.0000,  0.0000],
        [ 0.8330,  0.2400,  2.7938,  0.0000,  0.0000,  0.0000],
        [-0.0073,  0.0165,  0.7159,  0.0000,  0.0000,  0.0000],
        [ 1.1847,  0.2365, -0.8288,  0.0000,  0.0000,  0.0000],
        [ 0.4694,  0.5252, -0.5653,  0.0000,  0.0000,  0.0000],
        [ 1.2570,  0.3802,  0.7699,  0.0000,  0.0000,  0.0000],
        [-0.5845, -2.2095, -1.3260,  0.0000,  0.0000,  0.0000],
        [ 0.8958, -0.2761,  1.0812,  0.0000,  0.0000,  0.0000],
        [-1.5443, -1.5038, -3.4406,  0.0000,  0.0000,  0.0000],
        [-1.0788, -0.5021,  0.9582,  0.0000,  0.0000,  0.0000],
        [ 0.3750, -0.3779, -2.1639,  0.0000,  0.0000,  0.0000],
        [ 1.2650,  1.0529,  3.2821,  0.0000,  0.0000,  0.0000],
        [-1.1968, -0.8327, -3.2400,  0.0000,  0.0000,  0.0000],
        [-1.2931,  1.0491, -3.4469,  0.0000,  0.0000,  0.0000],
        [ 1.5071,  0.9218,  2.1488,  0.0000,  0.0000,  0.0000],
        [ 0.0705, -0.7564,  2.9153,  0.0000,  0.0000,  0.0000],
        [-0.7872,  0.8496, -1.9932,  0.0000,  0.0000,  0.0000],
        [-0.3388, -1.2217,  0.3726,  0.0000,  0.0000,  0.0000],
        [ 1.4652,  0.8614, -0.3393,  0.0000,  0.0000,  0.0000],
        [-1.2030,  0.9582,  1.6505,  0.0000,  0.0000,  0.0000],
        [ 0.9330,  0.8943, -1.0853,  0.0000,  0.0000,  0.0000],
        [ 0.4323,  0.9757, -1.4855,  0.0000,  0.0000,  0.0000],
        [-1.2617, -0.0868, -1.6195,  0.0000,  0.0000,  0.0000],
        [ 0.6171, -0.6342, -3.5864,  0.0000,  0.0000,  0.0000],
        [-1.8351, -0.1644, -0.5853,  0.0000,  0.0000,  0.0000],
        [-0.5257,  0.0847, -1.4231,  0.0000,  0.0000,  0.0000],
        [ 0.9127, -0.9423,  0.2530,  0.0000,  0.0000,  0.0000],
        [ 0.1726, -0.4477,  1.4400,  0.0000,  0.0000,  0.0000],
        [-0.6790, -0.4458,  2.3338,  0.0000,  0.0000,  0.0000],
        [ 0.4527,  0.6452, -2.8177,  0.0000,  0.0000,  0.0000],
        [ 1.4859, -1.1481, -0.7499,  0.0000,  0.0000,  0.0000],
        [ 1.0594,  0.4975, -2.3335,  0.0000,  0.0000,  0.0000],
        [-1.8363, -1.3041, -0.4949,  0.0000,  0.0000,  0.0000],
        [-1.4245,  0.6388, -2.6277,  0.0000,  0.0000,  0.0000],
        [ 0.7750,  1.0259,  1.3792,  0.0000,  0.0000,  0.0000],
        [ 1.1847, -1.4704,  1.3869,  0.0000,  0.0000,  0.0000],
        [-0.4614, -0.4259, -2.4992,  0.0000,  0.0000,  0.0000],
        [-0.7827, -1.4955,  3.4892,  0.0000,  0.0000,  0.0000],
        [ 0.5055,  0.0205, -1.2501,  0.0000,  0.0000,  0.0000],
        [ 0.1670, -2.2158,  0.2796,  0.0000,  0.0000,  0.0000],
        [-0.3740,  0.7360, -0.0597,  0.0000,  0.0000,  0.0000],
        [ 0.5051, -1.2421,  1.0941,  0.0000,  0.0000,  0.0000],
        [ 0.8137, -1.8560, -1.5912,  0.0000,  0.0000,  0.0000],
        [-1.2486, -1.6685,  1.7119,  0.0000,  0.0000,  0.0000],
        [ 0.3258,  0.4996,  0.1691,  0.0000,  0.0000,  0.0000],
        [-0.7815,  0.7334,  2.9360,  0.0000,  0.0000,  0.0000],
        [-0.0419, -1.7455, -2.9664,  0.0000,  0.0000,  0.0000],
        [ 0.1071, -0.2313, -0.0509,  0.0000,  0.0000,  0.0000],
        [-1.8288, -0.5886,  0.8330,  0.0000,  0.0000,  0.0000],
        [ 1.1618, -0.5787, -1.9419,  0.0000,  0.0000,  0.0000],
        [-0.6706, -0.9904, -0.8344,  0.0000,  0.0000,  0.0000],
        [ 0.8905, -2.4158, -2.2488,  0.0000,  0.0000,  0.0000],
        [-1.1063,  0.4003,  1.0607,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  49
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0112, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9663, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9775, grad_fn=<AddBackward0>)
Gradients:
68.45230865478516
Gradient before update: tensor(79.1723)
Gradient after update: tensor(79.1723)
current Learning Rate:  0.000125
------------------------------------------------------------------------------------------------------------------
Iteration:  50
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0112, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9664, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9775, grad_fn=<AddBackward0>)
Gradients:
68.58870697021484
Gradient before update: tensor(79.3876)
Gradient after update: tensor(79.3876)
current Learning Rate:  0.000125
Total Loss:  tensor(473.9775, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4303,  0.3751, -3.6326,  0.0000,  0.0000,  0.0000],
        [-0.0994,  0.6010,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7502,  0.4573,  2.7560,  0.0000,  0.0000,  0.0000],
        [ 0.8331,  0.2398,  2.7938,  0.0000,  0.0000,  0.0000],
        [-0.0075,  0.0167,  0.7158,  0.0000,  0.0000,  0.0000],
        [ 1.1847,  0.2365, -0.8288,  0.0000,  0.0000,  0.0000],
        [ 0.4693,  0.5251, -0.5653,  0.0000,  0.0000,  0.0000],
        [ 1.2570,  0.3802,  0.7699,  0.0000,  0.0000,  0.0000],
        [-0.5845, -2.2095, -1.3260,  0.0000,  0.0000,  0.0000],
        [ 0.8959, -0.2761,  1.0812,  0.0000,  0.0000,  0.0000],
        [-1.5442, -1.5038, -3.4407,  0.0000,  0.0000,  0.0000],
        [-1.0790, -0.5019,  0.9582,  0.0000,  0.0000,  0.0000],
        [ 0.3752, -0.3782, -2.1640,  0.0000,  0.0000,  0.0000],
        [ 1.2650,  1.0529,  3.2820,  0.0000,  0.0000,  0.0000],
        [-1.1968, -0.8327, -3.2400,  0.0000,  0.0000,  0.0000],
        [-1.2931,  1.0490, -3.4471,  0.0000,  0.0000,  0.0000],
        [ 1.5071,  0.9219,  2.1487,  0.0000,  0.0000,  0.0000],
        [ 0.0704, -0.7565,  2.9153,  0.0000,  0.0000,  0.0000],
        [-0.7872,  0.8496, -1.9932,  0.0000,  0.0000,  0.0000],
        [-0.3387, -1.2217,  0.3725,  0.0000,  0.0000,  0.0000],
        [ 1.4653,  0.8613, -0.3392,  0.0000,  0.0000,  0.0000],
        [-1.2028,  0.9584,  1.6503,  0.0000,  0.0000,  0.0000],
        [ 0.9332,  0.8945, -1.0851,  0.0000,  0.0000,  0.0000],
        [ 0.4324,  0.9757, -1.4854,  0.0000,  0.0000,  0.0000],
        [-1.2617, -0.0868, -1.6195,  0.0000,  0.0000,  0.0000],
        [ 0.6169, -0.6344, -3.5862,  0.0000,  0.0000,  0.0000],
        [-1.8352, -0.1644, -0.5853,  0.0000,  0.0000,  0.0000],
        [-0.5257,  0.0847, -1.4231,  0.0000,  0.0000,  0.0000],
        [ 0.9127, -0.9426,  0.2531,  0.0000,  0.0000,  0.0000],
        [ 0.1725, -0.4479,  1.4399,  0.0000,  0.0000,  0.0000],
        [-0.6792, -0.4456,  2.3338,  0.0000,  0.0000,  0.0000],
        [ 0.4524,  0.6455, -2.8178,  0.0000,  0.0000,  0.0000],
        [ 1.4859, -1.1481, -0.7499,  0.0000,  0.0000,  0.0000],
        [ 1.0592,  0.4977, -2.3335,  0.0000,  0.0000,  0.0000],
        [-1.8363, -1.3041, -0.4949,  0.0000,  0.0000,  0.0000],
        [-1.4246,  0.6388, -2.6278,  0.0000,  0.0000,  0.0000],
        [ 0.7750,  1.0259,  1.3792,  0.0000,  0.0000,  0.0000],
        [ 1.1847, -1.4704,  1.3869,  0.0000,  0.0000,  0.0000],
        [-0.4613, -0.4259, -2.4992,  0.0000,  0.0000,  0.0000],
        [-0.7827, -1.4955,  3.4891,  0.0000,  0.0000,  0.0000],
        [ 0.5055,  0.0203, -1.2501,  0.0000,  0.0000,  0.0000],
        [ 0.1670, -2.2158,  0.2797,  0.0000,  0.0000,  0.0000],
        [-0.3740,  0.7360, -0.0597,  0.0000,  0.0000,  0.0000],
        [ 0.5051, -1.2422,  1.0941,  0.0000,  0.0000,  0.0000],
        [ 0.8137, -1.8560, -1.5911,  0.0000,  0.0000,  0.0000],
        [-1.2485, -1.6686,  1.7118,  0.0000,  0.0000,  0.0000],
        [ 0.3256,  0.4994,  0.1690,  0.0000,  0.0000,  0.0000],
        [-0.7813,  0.7332,  2.9359,  0.0000,  0.0000,  0.0000],
        [-0.0419, -1.7456, -2.9663,  0.0000,  0.0000,  0.0000],
        [ 0.1069, -0.2315, -0.0509,  0.0000,  0.0000,  0.0000],
        [-1.8288, -0.5886,  0.8330,  0.0000,  0.0000,  0.0000],
        [ 1.1618, -0.5787, -1.9418,  0.0000,  0.0000,  0.0000],
        [-0.6706, -0.9904, -0.8344,  0.0000,  0.0000,  0.0000],
        [ 0.8905, -2.4158, -2.2488,  0.0000,  0.0000,  0.0000],
        [-1.1063,  0.4003,  1.0606,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Rerun:

lr=0.001 without schedular:
Gradients:
68.16996002197266
Gradient before update: tensor(79.1374)
Gradient after update: tensor(79.1374)
current Learning Rate:  0.0001
------------------------------------------------------------------------------------------------------------------
Iteration:  372
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0111, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9600, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9711, grad_fn=<AddBackward0>)
Gradients:
35.79093933105469
Gradient before update: tensor(39.8519)
Gradient after update: tensor(39.8519)
current Learning Rate:  0.0001
Total Loss:  tensor(473.9711, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4301,  0.3749, -3.6324,  0.0000,  0.0000,  0.0000],
        [-0.0992,  0.6012,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7504,  0.4572,  2.7562,  0.0000,  0.0000,  0.0000],
        [ 0.8332,  0.2396,  2.7938,  0.0000,  0.0000,  0.0000],
        [-0.0077,  0.0169,  0.7156,  0.0000,  0.0000,  0.0000],
        [ 1.1849,  0.2363, -0.8287,  0.0000,  0.0000,  0.0000],
        [ 0.4695,  0.5249, -0.5652,  0.0000,  0.0000,  0.0000],
        [ 1.2572,  0.3800,  0.7701,  0.0000,  0.0000,  0.0000],
        [-0.5847, -2.2097, -1.3258,  0.0000,  0.0000,  0.0000],
        [ 0.8961, -0.2759,  1.0814,  0.0000,  0.0000,  0.0000],
        [-1.5440, -1.5040, -3.4409,  0.0000,  0.0000,  0.0000],
        [-1.0792, -0.5017,  0.9583,  0.0000,  0.0000,  0.0000],
        [ 0.3754, -0.3784, -2.1640,  0.0000,  0.0000,  0.0000],
        [ 1.2652,  1.0531,  3.2822,  0.0000,  0.0000,  0.0000],
        [-1.1970, -0.8329, -3.2402,  0.0000,  0.0000,  0.0000],
        [-1.2929,  1.0488, -3.4473,  0.0000,  0.0000,  0.0000],
        [ 1.5073,  0.9221,  2.1485,  0.0000,  0.0000,  0.0000],
        [ 0.0702, -0.7567,  2.9155,  0.0000,  0.0000,  0.0000],
        [-0.7870,  0.8498, -1.9934,  0.0000,  0.0000,  0.0000],
        [-0.3385, -1.2216,  0.3727,  0.0000,  0.0000,  0.0000],
        [ 1.4655,  0.8611, -0.3390,  0.0000,  0.0000,  0.0000],
        [-1.2026,  0.9586,  1.6501,  0.0000,  0.0000,  0.0000],
        [ 0.9334,  0.8947, -1.0849,  0.0000,  0.0000,  0.0000],
        [ 0.4322,  0.9759, -1.4856,  0.0000,  0.0000,  0.0000],
        [-1.2615, -0.0866, -1.6197,  0.0000,  0.0000,  0.0000],
        [ 0.6167, -0.6346, -3.5860,  0.0000,  0.0000,  0.0000],
        [-1.8354, -0.1642, -0.5851,  0.0000,  0.0000,  0.0000],
        [-0.5259,  0.0849, -1.4233,  0.0000,  0.0000,  0.0000],
        [ 0.9125, -0.9428,  0.2533,  0.0000,  0.0000,  0.0000],
        [ 0.1723, -0.4481,  1.4398,  0.0000,  0.0000,  0.0000],
        [-0.6794, -0.4454,  2.3338,  0.0000,  0.0000,  0.0000],
        [ 0.4522,  0.6457, -2.8177,  0.0000,  0.0000,  0.0000],
        [ 1.4861, -1.1483, -0.7501,  0.0000,  0.0000,  0.0000],
        [ 1.0590,  0.4979, -2.3335,  0.0000,  0.0000,  0.0000],
        [-1.8365, -1.3043, -0.4951,  0.0000,  0.0000,  0.0000],
        [-1.4248,  0.6390, -2.6279,  0.0000,  0.0000,  0.0000],
        [ 0.7752,  1.0261,  1.3790,  0.0000,  0.0000,  0.0000],
        [ 1.1849, -1.4706,  1.3867,  0.0000,  0.0000,  0.0000],
        [-0.4611, -0.4261, -2.4994,  0.0000,  0.0000,  0.0000],
        [-0.7829, -1.4953,  3.4889,  0.0000,  0.0000,  0.0000],
        [ 0.5054,  0.0201, -1.2501,  0.0000,  0.0000,  0.0000],
        [ 0.1670, -2.2159,  0.2799,  0.0000,  0.0000,  0.0000],
        [-0.3738,  0.7362, -0.0595,  0.0000,  0.0000,  0.0000],
        [ 0.5049, -1.2424,  1.0939,  0.0000,  0.0000,  0.0000],
        [ 0.8135, -1.8558, -1.5909,  0.0000,  0.0000,  0.0000],
        [-1.2483, -1.6688,  1.7116,  0.0000,  0.0000,  0.0000],
        [ 0.3254,  0.4992,  0.1689,  0.0000,  0.0000,  0.0000],
        [-0.7811,  0.7330,  2.9357,  0.0000,  0.0000,  0.0000],
        [-0.0417, -1.7458, -2.9661,  0.0000,  0.0000,  0.0000],
        [ 0.1067, -0.2317, -0.0508,  0.0000,  0.0000,  0.0000],
        [-1.8290, -0.5888,  0.8332,  0.0000,  0.0000,  0.0000],
        [ 1.1620, -0.5785, -1.9416,  0.0000,  0.0000,  0.0000],
        [-0.6704, -0.9906, -0.8342,  0.0000,  0.0000,  0.0000],
        [ 0.8903, -2.4160, -2.2490,  0.0000,  0.0000,  0.0000],
        [-1.1061,  0.4001,  1.0604,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  373
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0111, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9565, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9676, grad_fn=<AddBackward0>)
Gradients:
20.569231033325195
Gradient before update: tensor(21.0545)
Gradient after update: tensor(21.0545)
current Learning Rate:  0.0001
------------------------------------------------------------------------------------------------------------------
Iteration:  374
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0110, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9546, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9656, grad_fn=<AddBackward0>)
Gradients:
12.87231731414795
Gradient before update: tensor(11.0674)
Gradient after update: tensor(11.0674)
current Learning Rate:  0.0001
Total Loss:  tensor(473.9656, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4299,  0.3747, -3.6322,  0.0000,  0.0000,  0.0000],
        [-0.0990,  0.6014,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7506,  0.4573,  2.7564,  0.0000,  0.0000,  0.0000],
        [ 0.8333,  0.2394,  2.7938,  0.0000,  0.0000,  0.0000],
        [-0.0079,  0.0171,  0.7155,  0.0000,  0.0000,  0.0000],
        [ 1.1851,  0.2361, -0.8287,  0.0000,  0.0000,  0.0000],
        [ 0.4697,  0.5247, -0.5651,  0.0000,  0.0000,  0.0000],
        [ 1.2574,  0.3798,  0.7703,  0.0000,  0.0000,  0.0000],
        [-0.5849, -2.2098, -1.3256,  0.0000,  0.0000,  0.0000],
        [ 0.8963, -0.2757,  1.0816,  0.0000,  0.0000,  0.0000],
        [-1.5438, -1.5042, -3.4411,  0.0000,  0.0000,  0.0000],
        [-1.0794, -0.5015,  0.9584,  0.0000,  0.0000,  0.0000],
        [ 0.3756, -0.3786, -2.1640,  0.0000,  0.0000,  0.0000],
        [ 1.2654,  1.0533,  3.2824,  0.0000,  0.0000,  0.0000],
        [-1.1972, -0.8331, -3.2403,  0.0000,  0.0000,  0.0000],
        [-1.2930,  1.0486, -3.4475,  0.0000,  0.0000,  0.0000],
        [ 1.5075,  0.9223,  2.1483,  0.0000,  0.0000,  0.0000],
        [ 0.0700, -0.7569,  2.9157,  0.0000,  0.0000,  0.0000],
        [-0.7868,  0.8500, -1.9936,  0.0000,  0.0000,  0.0000],
        [-0.3383, -1.2217,  0.3729,  0.0000,  0.0000,  0.0000],
        [ 1.4657,  0.8609, -0.3388,  0.0000,  0.0000,  0.0000],
        [-1.2024,  0.9588,  1.6499,  0.0000,  0.0000,  0.0000],
        [ 0.9336,  0.8949, -1.0847,  0.0000,  0.0000,  0.0000],
        [ 0.4320,  0.9761, -1.4858,  0.0000,  0.0000,  0.0000],
        [-1.2613, -0.0864, -1.6199,  0.0000,  0.0000,  0.0000],
        [ 0.6165, -0.6348, -3.5858,  0.0000,  0.0000,  0.0000],
        [-1.8356, -0.1640, -0.5849,  0.0000,  0.0000,  0.0000],
        [-0.5261,  0.0849, -1.4235,  0.0000,  0.0000,  0.0000],
        [ 0.9124, -0.9430,  0.2534,  0.0000,  0.0000,  0.0000],
        [ 0.1721, -0.4483,  1.4397,  0.0000,  0.0000,  0.0000],
        [-0.6796, -0.4452,  2.3338,  0.0000,  0.0000,  0.0000],
        [ 0.4520,  0.6459, -2.8177,  0.0000,  0.0000,  0.0000],
        [ 1.4863, -1.1485, -0.7501,  0.0000,  0.0000,  0.0000],
        [ 1.0588,  0.4981, -2.3336,  0.0000,  0.0000,  0.0000],
        [-1.8367, -1.3044, -0.4953,  0.0000,  0.0000,  0.0000],
        [-1.4250,  0.6392, -2.6280,  0.0000,  0.0000,  0.0000],
        [ 0.7754,  1.0263,  1.3788,  0.0000,  0.0000,  0.0000],
        [ 1.1851, -1.4708,  1.3865,  0.0000,  0.0000,  0.0000],
        [-0.4609, -0.4263, -2.4995,  0.0000,  0.0000,  0.0000],
        [-0.7831, -1.4951,  3.4887,  0.0000,  0.0000,  0.0000],
        [ 0.5053,  0.0199, -1.2501,  0.0000,  0.0000,  0.0000],
        [ 0.1671, -2.2159,  0.2801,  0.0000,  0.0000,  0.0000],
        [-0.3736,  0.7364, -0.0593,  0.0000,  0.0000,  0.0000],
        [ 0.5047, -1.2426,  1.0937,  0.0000,  0.0000,  0.0000],
        [ 0.8133, -1.8556, -1.5907,  0.0000,  0.0000,  0.0000],
        [-1.2482, -1.6690,  1.7114,  0.0000,  0.0000,  0.0000],
        [ 0.3252,  0.4990,  0.1688,  0.0000,  0.0000,  0.0000],
        [-0.7809,  0.7328,  2.9355,  0.0000,  0.0000,  0.0000],
        [-0.0415, -1.7460, -2.9659,  0.0000,  0.0000,  0.0000],
        [ 0.1065, -0.2318, -0.0508,  0.0000,  0.0000,  0.0000],
        [-1.8292, -0.5890,  0.8334,  0.0000,  0.0000,  0.0000],
        [ 1.1622, -0.5783, -1.9414,  0.0000,  0.0000,  0.0000],
        [-0.6702, -0.9908, -0.8340,  0.0000,  0.0000,  0.0000],
        [ 0.8901, -2.4160, -2.2492,  0.0000,  0.0000,  0.0000],
        [-1.1059,  0.3999,  1.0602,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  375
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0110, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9533, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9642, grad_fn=<AddBackward0>)
Gradients:
8.80696964263916
Gradient before update: tensor(5.2391)
Gradient after update: tensor(5.2391)
current Learning Rate:  0.0001
------------------------------------------------------------------------------------------------------------------
Iteration:  376
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0109, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9522, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9631, grad_fn=<AddBackward0>)
Gradients:
6.702733039855957
Gradient before update: tensor(1.5243)
Gradient after update: tensor(1.5243)
current Learning Rate:  0.0001
Total Loss:  tensor(473.9631, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4297,  0.3745, -3.6320,  0.0000,  0.0000,  0.0000],
        [-0.0988,  0.6016,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7508,  0.4575,  2.7566,  0.0000,  0.0000,  0.0000],
        [ 0.8334,  0.2392,  2.7938,  0.0000,  0.0000,  0.0000],
        [-0.0081,  0.0173,  0.7153,  0.0000,  0.0000,  0.0000],
        [ 1.1853,  0.2359, -0.8288,  0.0000,  0.0000,  0.0000],
        [ 0.4699,  0.5246, -0.5650,  0.0000,  0.0000,  0.0000],
        [ 1.2576,  0.3796,  0.7705,  0.0000,  0.0000,  0.0000],
        [-0.5851, -2.2100, -1.3254,  0.0000,  0.0000,  0.0000],
        [ 0.8965, -0.2755,  1.0818,  0.0000,  0.0000,  0.0000],
        [-1.5436, -1.5044, -3.4413,  0.0000,  0.0000,  0.0000],
        [-1.0796, -0.5013,  0.9584,  0.0000,  0.0000,  0.0000],
        [ 0.3758, -0.3788, -2.1639,  0.0000,  0.0000,  0.0000],
        [ 1.2656,  1.0535,  3.2826,  0.0000,  0.0000,  0.0000],
        [-1.1974, -0.8333, -3.2402,  0.0000,  0.0000,  0.0000],
        [-1.2931,  1.0484, -3.4477,  0.0000,  0.0000,  0.0000],
        [ 1.5077,  0.9225,  2.1481,  0.0000,  0.0000,  0.0000],
        [ 0.0698, -0.7571,  2.9158,  0.0000,  0.0000,  0.0000],
        [-0.7866,  0.8502, -1.9938,  0.0000,  0.0000,  0.0000],
        [-0.3381, -1.2219,  0.3731,  0.0000,  0.0000,  0.0000],
        [ 1.4659,  0.8607, -0.3386,  0.0000,  0.0000,  0.0000],
        [-1.2022,  0.9590,  1.6497,  0.0000,  0.0000,  0.0000],
        [ 0.9338,  0.8951, -1.0845,  0.0000,  0.0000,  0.0000],
        [ 0.4318,  0.9763, -1.4860,  0.0000,  0.0000,  0.0000],
        [-1.2611, -0.0862, -1.6201,  0.0000,  0.0000,  0.0000],
        [ 0.6163, -0.6350, -3.5856,  0.0000,  0.0000,  0.0000],
        [-1.8358, -0.1638, -0.5847,  0.0000,  0.0000,  0.0000],
        [-0.5263,  0.0849, -1.4237,  0.0000,  0.0000,  0.0000],
        [ 0.9122, -0.9432,  0.2534,  0.0000,  0.0000,  0.0000],
        [ 0.1719, -0.4485,  1.4395,  0.0000,  0.0000,  0.0000],
        [-0.6798, -0.4450,  2.3337,  0.0000,  0.0000,  0.0000],
        [ 0.4518,  0.6461, -2.8176,  0.0000,  0.0000,  0.0000],
        [ 1.4865, -1.1487, -0.7500,  0.0000,  0.0000,  0.0000],
        [ 1.0586,  0.4983, -2.3336,  0.0000,  0.0000,  0.0000],
        [-1.8369, -1.3043, -0.4955,  0.0000,  0.0000,  0.0000],
        [-1.4252,  0.6394, -2.6279,  0.0000,  0.0000,  0.0000],
        [ 0.7756,  1.0265,  1.3786,  0.0000,  0.0000,  0.0000],
        [ 1.1853, -1.4710,  1.3863,  0.0000,  0.0000,  0.0000],
        [-0.4607, -0.4265, -2.4997,  0.0000,  0.0000,  0.0000],
        [-0.7833, -1.4949,  3.4885,  0.0000,  0.0000,  0.0000],
        [ 0.5052,  0.0198, -1.2501,  0.0000,  0.0000,  0.0000],
        [ 0.1671, -2.2160,  0.2803,  0.0000,  0.0000,  0.0000],
        [-0.3734,  0.7366, -0.0591,  0.0000,  0.0000,  0.0000],
        [ 0.5045, -1.2428,  1.0935,  0.0000,  0.0000,  0.0000],
        [ 0.8131, -1.8554, -1.5905,  0.0000,  0.0000,  0.0000],
        [-1.2481, -1.6692,  1.7112,  0.0000,  0.0000,  0.0000],
        [ 0.3250,  0.4988,  0.1687,  0.0000,  0.0000,  0.0000],
        [-0.7807,  0.7326,  2.9353,  0.0000,  0.0000,  0.0000],
        [-0.0415, -1.7462, -2.9657,  0.0000,  0.0000,  0.0000],
        [ 0.1063, -0.2320, -0.0508,  0.0000,  0.0000,  0.0000],
        [-1.8294, -0.5892,  0.8335,  0.0000,  0.0000,  0.0000],
        [ 1.1624, -0.5781, -1.9412,  0.0000,  0.0000,  0.0000],
        [-0.6700, -0.9910, -0.8338,  0.0000,  0.0000,  0.0000],
        [ 0.8900, -2.4160, -2.2493,  0.0000,  0.0000,  0.0000],
        [-1.1057,  0.3997,  1.0600,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  377
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0109, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9514, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9622, grad_fn=<AddBackward0>)
Gradients:
5.749466419219971
Gradient before update: tensor(-1.0163)
Gradient after update: tensor(-1.0163)
current Learning Rate:  0.0001
------------------------------------------------------------------------------------------------------------------
Iteration:  378
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0108, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9507, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9615, grad_fn=<AddBackward0>)
Gradients:
5.454943656921387
Gradient before update: tensor(-2.8539)
Gradient after update: tensor(-2.8539)
current Learning Rate:  0.0001
Total Loss:  tensor(473.9615, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4296,  0.3744, -3.6318,  0.0000,  0.0000,  0.0000],
        [-0.0986,  0.6018,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7510,  0.4576,  2.7568,  0.0000,  0.0000,  0.0000],
        [ 0.8336,  0.2390,  2.7938,  0.0000,  0.0000,  0.0000],
        [-0.0083,  0.0175,  0.7151,  0.0000,  0.0000,  0.0000],
        [ 1.1855,  0.2357, -0.8289,  0.0000,  0.0000,  0.0000],
        [ 0.4700,  0.5244, -0.5649,  0.0000,  0.0000,  0.0000],
        [ 1.2578,  0.3794,  0.7707,  0.0000,  0.0000,  0.0000],
        [-0.5853, -2.2101, -1.3253,  0.0000,  0.0000,  0.0000],
        [ 0.8967, -0.2753,  1.0820,  0.0000,  0.0000,  0.0000],
        [-1.5434, -1.5046, -3.4415,  0.0000,  0.0000,  0.0000],
        [-1.0798, -0.5011,  0.9584,  0.0000,  0.0000,  0.0000],
        [ 0.3760, -0.3790, -2.1638,  0.0000,  0.0000,  0.0000],
        [ 1.2658,  1.0537,  3.2828,  0.0000,  0.0000,  0.0000],
        [-1.1976, -0.8335, -3.2402,  0.0000,  0.0000,  0.0000],
        [-1.2932,  1.0482, -3.4479,  0.0000,  0.0000,  0.0000],
        [ 1.5079,  0.9227,  2.1479,  0.0000,  0.0000,  0.0000],
        [ 0.0696, -0.7573,  2.9160,  0.0000,  0.0000,  0.0000],
        [-0.7864,  0.8504, -1.9940,  0.0000,  0.0000,  0.0000],
        [-0.3379, -1.2220,  0.3731,  0.0000,  0.0000,  0.0000],
        [ 1.4661,  0.8605, -0.3385,  0.0000,  0.0000,  0.0000],
        [-1.2020,  0.9592,  1.6495,  0.0000,  0.0000,  0.0000],
        [ 0.9340,  0.8953, -1.0843,  0.0000,  0.0000,  0.0000],
        [ 0.4316,  0.9764, -1.4862,  0.0000,  0.0000,  0.0000],
        [-1.2609, -0.0860, -1.6202,  0.0000,  0.0000,  0.0000],
        [ 0.6161, -0.6352, -3.5854,  0.0000,  0.0000,  0.0000],
        [-1.8360, -0.1636, -0.5845,  0.0000,  0.0000,  0.0000],
        [-0.5265,  0.0848, -1.4239,  0.0000,  0.0000,  0.0000],
        [ 0.9121, -0.9434,  0.2533,  0.0000,  0.0000,  0.0000],
        [ 0.1717, -0.4487,  1.4394,  0.0000,  0.0000,  0.0000],
        [-0.6800, -0.4448,  2.3336,  0.0000,  0.0000,  0.0000],
        [ 0.4516,  0.6463, -2.8175,  0.0000,  0.0000,  0.0000],
        [ 1.4867, -1.1489, -0.7499,  0.0000,  0.0000,  0.0000],
        [ 1.0585,  0.4985, -2.3336,  0.0000,  0.0000,  0.0000],
        [-1.8370, -1.3043, -0.4957,  0.0000,  0.0000,  0.0000],
        [-1.4254,  0.6396, -2.6279,  0.0000,  0.0000,  0.0000],
        [ 0.7758,  1.0267,  1.3784,  0.0000,  0.0000,  0.0000],
        [ 1.1855, -1.4712,  1.3861,  0.0000,  0.0000,  0.0000],
        [-0.4605, -0.4267, -2.4998,  0.0000,  0.0000,  0.0000],
        [-0.7835, -1.4947,  3.4883,  0.0000,  0.0000,  0.0000],
        [ 0.5051,  0.0196, -1.2501,  0.0000,  0.0000,  0.0000],
        [ 0.1671, -2.2161,  0.2805,  0.0000,  0.0000,  0.0000],
        [-0.3732,  0.7368, -0.0589,  0.0000,  0.0000,  0.0000],
        [ 0.5043, -1.2430,  1.0933,  0.0000,  0.0000,  0.0000],
        [ 0.8129, -1.8552, -1.5903,  0.0000,  0.0000,  0.0000],
        [-1.2481, -1.6694,  1.7110,  0.0000,  0.0000,  0.0000],
        [ 0.3248,  0.4986,  0.1686,  0.0000,  0.0000,  0.0000],
        [-0.7805,  0.7324,  2.9352,  0.0000,  0.0000,  0.0000],
        [-0.0415, -1.7464, -2.9655,  0.0000,  0.0000,  0.0000],
        [ 0.1061, -0.2322, -0.0509,  0.0000,  0.0000,  0.0000],
        [-1.8296, -0.5893,  0.8335,  0.0000,  0.0000,  0.0000],
        [ 1.1626, -0.5779, -1.9410,  0.0000,  0.0000,  0.0000],
        [-0.6698, -0.9912, -0.8336,  0.0000,  0.0000,  0.0000],
        [ 0.8899, -2.4159, -2.2494,  0.0000,  0.0000,  0.0000],
        [-1.1055,  0.3995,  1.0598,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  379
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0108, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9500, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9607, grad_fn=<AddBackward0>)
Gradients:
5.498965263366699
Gradient before update: tensor(-4.2420)
Gradient after update: tensor(-4.2420)
current Learning Rate:  0.0001
------------------------------------------------------------------------------------------------------------------
Iteration:  380
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0107, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9492, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9599, grad_fn=<AddBackward0>)
Gradients:
5.697414875030518
Gradient before update: tensor(-5.3254)
Gradient after update: tensor(-5.3254)
current Learning Rate:  0.0001
Total Loss:  tensor(473.9599, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4294,  0.3742, -3.6316,  0.0000,  0.0000,  0.0000],
        [-0.0984,  0.6020,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7512,  0.4578,  2.7570,  0.0000,  0.0000,  0.0000],
        [ 0.8337,  0.2388,  2.7938,  0.0000,  0.0000,  0.0000],
        [-0.0085,  0.0177,  0.7150,  0.0000,  0.0000,  0.0000],
        [ 1.1857,  0.2355, -0.8291,  0.0000,  0.0000,  0.0000],
        [ 0.4702,  0.5242, -0.5648,  0.0000,  0.0000,  0.0000],
        [ 1.2580,  0.3792,  0.7709,  0.0000,  0.0000,  0.0000],
        [-0.5854, -2.2103, -1.3251,  0.0000,  0.0000,  0.0000],
        [ 0.8969, -0.2751,  1.0822,  0.0000,  0.0000,  0.0000],
        [-1.5432, -1.5048, -3.4417,  0.0000,  0.0000,  0.0000],
        [-1.0800, -0.5009,  0.9584,  0.0000,  0.0000,  0.0000],
        [ 0.3762, -0.3792, -2.1636,  0.0000,  0.0000,  0.0000],
        [ 1.2660,  1.0539,  3.2830,  0.0000,  0.0000,  0.0000],
        [-1.1978, -0.8337, -3.2401,  0.0000,  0.0000,  0.0000],
        [-1.2932,  1.0480, -3.4481,  0.0000,  0.0000,  0.0000],
        [ 1.5081,  0.9229,  2.1477,  0.0000,  0.0000,  0.0000],
        [ 0.0694, -0.7575,  2.9161,  0.0000,  0.0000,  0.0000],
        [-0.7862,  0.8506, -1.9942,  0.0000,  0.0000,  0.0000],
        [-0.3377, -1.2222,  0.3731,  0.0000,  0.0000,  0.0000],
        [ 1.4662,  0.8604, -0.3383,  0.0000,  0.0000,  0.0000],
        [-1.2018,  0.9594,  1.6493,  0.0000,  0.0000,  0.0000],
        [ 0.9342,  0.8955, -1.0841,  0.0000,  0.0000,  0.0000],
        [ 0.4315,  0.9766, -1.4864,  0.0000,  0.0000,  0.0000],
        [-1.2607, -0.0858, -1.6202,  0.0000,  0.0000,  0.0000],
        [ 0.6159, -0.6354, -3.5852,  0.0000,  0.0000,  0.0000],
        [-1.8362, -0.1634, -0.5843,  0.0000,  0.0000,  0.0000],
        [-0.5267,  0.0847, -1.4241,  0.0000,  0.0000,  0.0000],
        [ 0.9120, -0.9436,  0.2532,  0.0000,  0.0000,  0.0000],
        [ 0.1715, -0.4489,  1.4393,  0.0000,  0.0000,  0.0000],
        [-0.6802, -0.4446,  2.3335,  0.0000,  0.0000,  0.0000],
        [ 0.4514,  0.6465, -2.8175,  0.0000,  0.0000,  0.0000],
        [ 1.4869, -1.1491, -0.7499,  0.0000,  0.0000,  0.0000],
        [ 1.0583,  0.4987, -2.3336,  0.0000,  0.0000,  0.0000],
        [-1.8372, -1.3042, -0.4958,  0.0000,  0.0000,  0.0000],
        [-1.4256,  0.6398, -2.6278,  0.0000,  0.0000,  0.0000],
        [ 0.7759,  1.0269,  1.3783,  0.0000,  0.0000,  0.0000],
        [ 1.1857, -1.4714,  1.3859,  0.0000,  0.0000,  0.0000],
        [-0.4603, -0.4269, -2.5000,  0.0000,  0.0000,  0.0000],
        [-0.7837, -1.4945,  3.4881,  0.0000,  0.0000,  0.0000],
        [ 0.5050,  0.0194, -1.2501,  0.0000,  0.0000,  0.0000],
        [ 0.1671, -2.2160,  0.2807,  0.0000,  0.0000,  0.0000],
        [-0.3730,  0.7370, -0.0587,  0.0000,  0.0000,  0.0000],
        [ 0.5041, -1.2432,  1.0931,  0.0000,  0.0000,  0.0000],
        [ 0.8128, -1.8551, -1.5902,  0.0000,  0.0000,  0.0000],
        [-1.2481, -1.6696,  1.7109,  0.0000,  0.0000,  0.0000],
        [ 0.3246,  0.4984,  0.1686,  0.0000,  0.0000,  0.0000],
        [-0.7803,  0.7322,  2.9350,  0.0000,  0.0000,  0.0000],
        [-0.0415, -1.7466, -2.9653,  0.0000,  0.0000,  0.0000],
        [ 0.1059, -0.2324, -0.0509,  0.0000,  0.0000,  0.0000],
        [-1.8298, -0.5894,  0.8335,  0.0000,  0.0000,  0.0000],
        [ 1.1628, -0.5778, -1.9408,  0.0000,  0.0000,  0.0000],
        [-0.6696, -0.9913, -0.8335,  0.0000,  0.0000,  0.0000],
        [ 0.8898, -2.4157, -2.2495,  0.0000,  0.0000,  0.0000],
        [-1.1053,  0.3993,  1.0596,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  381
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0107, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9486, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9592, grad_fn=<AddBackward0>)
Gradients:
5.956053256988525
Gradient before update: tensor(-6.2071)
Gradient after update: tensor(-6.2071)
current Learning Rate:  0.0001
------------------------------------------------------------------------------------------------------------------
Iteration:  382
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0106, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9479, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9585, grad_fn=<AddBackward0>)
Gradients:
6.2335920333862305
Gradient before update: tensor(-6.9254)
Gradient after update: tensor(-6.9254)
current Learning Rate:  0.0001
Total Loss:  tensor(473.9585, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4292,  0.3740, -3.6315,  0.0000,  0.0000,  0.0000],
        [-0.0982,  0.6022,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7514,  0.4579,  2.7572,  0.0000,  0.0000,  0.0000],
        [ 0.8337,  0.2386,  2.7938,  0.0000,  0.0000,  0.0000],
        [-0.0087,  0.0179,  0.7148,  0.0000,  0.0000,  0.0000],
        [ 1.1858,  0.2354, -0.8292,  0.0000,  0.0000,  0.0000],
        [ 0.4703,  0.5242, -0.5648,  0.0000,  0.0000,  0.0000],
        [ 1.2582,  0.3790,  0.7711,  0.0000,  0.0000,  0.0000],
        [-0.5856, -2.2105, -1.3249,  0.0000,  0.0000,  0.0000],
        [ 0.8971, -0.2749,  1.0823,  0.0000,  0.0000,  0.0000],
        [-1.5430, -1.5050, -3.4419,  0.0000,  0.0000,  0.0000],
        [-1.0802, -0.5007,  0.9584,  0.0000,  0.0000,  0.0000],
        [ 0.3764, -0.3794, -2.1635,  0.0000,  0.0000,  0.0000],
        [ 1.2661,  1.0540,  3.2831,  0.0000,  0.0000,  0.0000],
        [-1.1980, -0.8339, -3.2401,  0.0000,  0.0000,  0.0000],
        [-1.2932,  1.0478, -3.4483,  0.0000,  0.0000,  0.0000],
        [ 1.5083,  0.9231,  2.1475,  0.0000,  0.0000,  0.0000],
        [ 0.0692, -0.7577,  2.9162,  0.0000,  0.0000,  0.0000],
        [-0.7860,  0.8508, -1.9944,  0.0000,  0.0000,  0.0000],
        [-0.3375, -1.2223,  0.3731,  0.0000,  0.0000,  0.0000],
        [ 1.4664,  0.8602, -0.3381,  0.0000,  0.0000,  0.0000],
        [-1.2016,  0.9596,  1.6491,  0.0000,  0.0000,  0.0000],
        [ 0.9344,  0.8957, -1.0839,  0.0000,  0.0000,  0.0000],
        [ 0.4313,  0.9767, -1.4865,  0.0000,  0.0000,  0.0000],
        [-1.2605, -0.0856, -1.6201,  0.0000,  0.0000,  0.0000],
        [ 0.6157, -0.6356, -3.5850,  0.0000,  0.0000,  0.0000],
        [-1.8364, -0.1632, -0.5842,  0.0000,  0.0000,  0.0000],
        [-0.5269,  0.0846, -1.4243,  0.0000,  0.0000,  0.0000],
        [ 0.9120, -0.9438,  0.2531,  0.0000,  0.0000,  0.0000],
        [ 0.1713, -0.4491,  1.4392,  0.0000,  0.0000,  0.0000],
        [-0.6804, -0.4444,  2.3334,  0.0000,  0.0000,  0.0000],
        [ 0.4512,  0.6467, -2.8174,  0.0000,  0.0000,  0.0000],
        [ 1.4871, -1.1492, -0.7500,  0.0000,  0.0000,  0.0000],
        [ 1.0581,  0.4989, -2.3336,  0.0000,  0.0000,  0.0000],
        [-1.8373, -1.3041, -0.4960,  0.0000,  0.0000,  0.0000],
        [-1.4258,  0.6400, -2.6277,  0.0000,  0.0000,  0.0000],
        [ 0.7761,  1.0270,  1.3781,  0.0000,  0.0000,  0.0000],
        [ 1.1859, -1.4716,  1.3858,  0.0000,  0.0000,  0.0000],
        [-0.4601, -0.4271, -2.5001,  0.0000,  0.0000,  0.0000],
        [-0.7839, -1.4944,  3.4879,  0.0000,  0.0000,  0.0000],
        [ 0.5049,  0.0192, -1.2501,  0.0000,  0.0000,  0.0000],
        [ 0.1671, -2.2160,  0.2809,  0.0000,  0.0000,  0.0000],
        [-0.3729,  0.7371, -0.0586,  0.0000,  0.0000,  0.0000],
        [ 0.5039, -1.2434,  1.0929,  0.0000,  0.0000,  0.0000],
        [ 0.8126, -1.8549, -1.5900,  0.0000,  0.0000,  0.0000],
        [-1.2481, -1.6698,  1.7107,  0.0000,  0.0000,  0.0000],
        [ 0.3244,  0.4982,  0.1685,  0.0000,  0.0000,  0.0000],
        [-0.7801,  0.7320,  2.9348,  0.0000,  0.0000,  0.0000],
        [-0.0416, -1.7468, -2.9651,  0.0000,  0.0000,  0.0000],
        [ 0.1057, -0.2326, -0.0510,  0.0000,  0.0000,  0.0000],
        [-1.8300, -0.5895,  0.8334,  0.0000,  0.0000,  0.0000],
        [ 1.1630, -0.5776, -1.9406,  0.0000,  0.0000,  0.0000],
        [-0.6694, -0.9915, -0.8333,  0.0000,  0.0000,  0.0000],
        [ 0.8897, -2.4156, -2.2495,  0.0000,  0.0000,  0.0000],
        [-1.1051,  0.3991,  1.0594,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  383
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0106, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9473, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9579, grad_fn=<AddBackward0>)
Gradients:
6.510634422302246
Gradient before update: tensor(-7.5582)
Gradient after update: tensor(-7.5582)
current Learning Rate:  0.0001
------------------------------------------------------------------------------------------------------------------
Iteration:  384
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0105, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9467, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9572, grad_fn=<AddBackward0>)
Gradients:
6.779474258422852
Gradient before update: tensor(-8.1354)
Gradient after update: tensor(-8.1354)
current Learning Rate:  0.0001
Total Loss:  tensor(473.9572, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4290,  0.3738, -3.6313,  0.0000,  0.0000,  0.0000],
        [-0.0980,  0.6024,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7516,  0.4581,  2.7574,  0.0000,  0.0000,  0.0000],
        [ 0.8338,  0.2384,  2.7937,  0.0000,  0.0000,  0.0000],
        [-0.0089,  0.0181,  0.7147,  0.0000,  0.0000,  0.0000],
        [ 1.1860,  0.2352, -0.8293,  0.0000,  0.0000,  0.0000],
        [ 0.4701,  0.5243, -0.5649,  0.0000,  0.0000,  0.0000],
        [ 1.2583,  0.3789,  0.7712,  0.0000,  0.0000,  0.0000],
        [-0.5857, -2.2107, -1.3247,  0.0000,  0.0000,  0.0000],
        [ 0.8973, -0.2747,  1.0825,  0.0000,  0.0000,  0.0000],
        [-1.5428, -1.5052, -3.4421,  0.0000,  0.0000,  0.0000],
        [-1.0804, -0.5005,  0.9584,  0.0000,  0.0000,  0.0000],
        [ 0.3766, -0.3796, -2.1634,  0.0000,  0.0000,  0.0000],
        [ 1.2663,  1.0542,  3.2833,  0.0000,  0.0000,  0.0000],
        [-1.1981, -0.8340, -3.2400,  0.0000,  0.0000,  0.0000],
        [-1.2932,  1.0476, -3.4485,  0.0000,  0.0000,  0.0000],
        [ 1.5085,  0.9233,  2.1473,  0.0000,  0.0000,  0.0000],
        [ 0.0690, -0.7579,  2.9163,  0.0000,  0.0000,  0.0000],
        [-0.7858,  0.8510, -1.9946,  0.0000,  0.0000,  0.0000],
        [-0.3373, -1.2225,  0.3730,  0.0000,  0.0000,  0.0000],
        [ 1.4665,  0.8601, -0.3380,  0.0000,  0.0000,  0.0000],
        [-1.2014,  0.9598,  1.6489,  0.0000,  0.0000,  0.0000],
        [ 0.9346,  0.8959, -1.0837,  0.0000,  0.0000,  0.0000],
        [ 0.4312,  0.9769, -1.4867,  0.0000,  0.0000,  0.0000],
        [-1.2603, -0.0854, -1.6200,  0.0000,  0.0000,  0.0000],
        [ 0.6155, -0.6358, -3.5848,  0.0000,  0.0000,  0.0000],
        [-1.8366, -0.1630, -0.5840,  0.0000,  0.0000,  0.0000],
        [-0.5271,  0.0846, -1.4245,  0.0000,  0.0000,  0.0000],
        [ 0.9120, -0.9440,  0.2530,  0.0000,  0.0000,  0.0000],
        [ 0.1711, -0.4493,  1.4391,  0.0000,  0.0000,  0.0000],
        [-0.6806, -0.4442,  2.3333,  0.0000,  0.0000,  0.0000],
        [ 0.4511,  0.6469, -2.8173,  0.0000,  0.0000,  0.0000],
        [ 1.4872, -1.1494, -0.7500,  0.0000,  0.0000,  0.0000],
        [ 1.0579,  0.4990, -2.3336,  0.0000,  0.0000,  0.0000],
        [-1.8374, -1.3040, -0.4962,  0.0000,  0.0000,  0.0000],
        [-1.4260,  0.6402, -2.6276,  0.0000,  0.0000,  0.0000],
        [ 0.7763,  1.0272,  1.3779,  0.0000,  0.0000,  0.0000],
        [ 1.1860, -1.4717,  1.3856,  0.0000,  0.0000,  0.0000],
        [-0.4599, -0.4273, -2.5001,  0.0000,  0.0000,  0.0000],
        [-0.7840, -1.4942,  3.4877,  0.0000,  0.0000,  0.0000],
        [ 0.5048,  0.0191, -1.2501,  0.0000,  0.0000,  0.0000],
        [ 0.1670, -2.2159,  0.2811,  0.0000,  0.0000,  0.0000],
        [-0.3727,  0.7373, -0.0584,  0.0000,  0.0000,  0.0000],
        [ 0.5037, -1.2436,  1.0927,  0.0000,  0.0000,  0.0000],
        [ 0.8124, -1.8547, -1.5898,  0.0000,  0.0000,  0.0000],
        [-1.2480, -1.6700,  1.7106,  0.0000,  0.0000,  0.0000],
        [ 0.3242,  0.4980,  0.1685,  0.0000,  0.0000,  0.0000],
        [-0.7799,  0.7318,  2.9346,  0.0000,  0.0000,  0.0000],
        [-0.0417, -1.7470, -2.9649,  0.0000,  0.0000,  0.0000],
        [ 0.1055, -0.2327, -0.0511,  0.0000,  0.0000,  0.0000],
        [-1.8302, -0.5895,  0.8333,  0.0000,  0.0000,  0.0000],
        [ 1.1632, -0.5774, -1.9405,  0.0000,  0.0000,  0.0000],
        [-0.6692, -0.9915, -0.8332,  0.0000,  0.0000,  0.0000],
        [ 0.8897, -2.4154, -2.2496,  0.0000,  0.0000,  0.0000],
        [-1.1049,  0.3989,  1.0592,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  385
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0105, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9460, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9565, grad_fn=<AddBackward0>)
Gradients:
7.037365913391113
Gradient before update: tensor(-8.6403)
Gradient after update: tensor(-8.6403)
current Learning Rate:  0.0001
------------------------------------------------------------------------------------------------------------------
Iteration:  386
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0104, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9453, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9557, grad_fn=<AddBackward0>)
Gradients:
7.282471179962158
Gradient before update: tensor(-9.1176)
Gradient after update: tensor(-9.1176)
current Learning Rate:  0.0001
Total Loss:  tensor(473.9557, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4288,  0.3736, -3.6311,  0.0000,  0.0000,  0.0000],
        [-0.0979,  0.6025,  1.7916,  0.0000,  0.0000,  0.0000],
        [-1.7518,  0.4583,  2.7576,  0.0000,  0.0000,  0.0000],
        [ 0.8339,  0.2383,  2.7937,  0.0000,  0.0000,  0.0000],
        [-0.0091,  0.0183,  0.7145,  0.0000,  0.0000,  0.0000],
        [ 1.1862,  0.2350, -0.8294,  0.0000,  0.0000,  0.0000],
        [ 0.4700,  0.5244, -0.5651,  0.0000,  0.0000,  0.0000],
        [ 1.2585,  0.3787,  0.7714,  0.0000,  0.0000,  0.0000],
        [-0.5858, -2.2108, -1.3245,  0.0000,  0.0000,  0.0000],
        [ 0.8975, -0.2745,  1.0827,  0.0000,  0.0000,  0.0000],
        [-1.5426, -1.5054, -3.4423,  0.0000,  0.0000,  0.0000],
        [-1.0806, -0.5003,  0.9583,  0.0000,  0.0000,  0.0000],
        [ 0.3768, -0.3798, -2.1632,  0.0000,  0.0000,  0.0000],
        [ 1.2665,  1.0544,  3.2834,  0.0000,  0.0000,  0.0000],
        [-1.1983, -0.8342, -3.2399,  0.0000,  0.0000,  0.0000],
        [-1.2932,  1.0475, -3.4487,  0.0000,  0.0000,  0.0000],
        [ 1.5087,  0.9235,  2.1471,  0.0000,  0.0000,  0.0000],
        [ 0.0688, -0.7581,  2.9164,  0.0000,  0.0000,  0.0000],
        [-0.7856,  0.8512, -1.9947,  0.0000,  0.0000,  0.0000],
        [-0.3371, -1.2226,  0.3729,  0.0000,  0.0000,  0.0000],
        [ 1.4666,  0.8600, -0.3379,  0.0000,  0.0000,  0.0000],
        [-1.2012,  0.9600,  1.6487,  0.0000,  0.0000,  0.0000],
        [ 0.9348,  0.8961, -1.0835,  0.0000,  0.0000,  0.0000],
        [ 0.4310,  0.9770, -1.4869,  0.0000,  0.0000,  0.0000],
        [-1.2601, -0.0852, -1.6199,  0.0000,  0.0000,  0.0000],
        [ 0.6153, -0.6360, -3.5846,  0.0000,  0.0000,  0.0000],
        [-1.8368, -0.1629, -0.5838,  0.0000,  0.0000,  0.0000],
        [-0.5273,  0.0846, -1.4247,  0.0000,  0.0000,  0.0000],
        [ 0.9120, -0.9442,  0.2529,  0.0000,  0.0000,  0.0000],
        [ 0.1709, -0.4495,  1.4390,  0.0000,  0.0000,  0.0000],
        [-0.6808, -0.4440,  2.3333,  0.0000,  0.0000,  0.0000],
        [ 0.4509,  0.6471, -2.8172,  0.0000,  0.0000,  0.0000],
        [ 1.4874, -1.1496, -0.7500,  0.0000,  0.0000,  0.0000],
        [ 1.0577,  0.4992, -2.3336,  0.0000,  0.0000,  0.0000],
        [-1.8374, -1.3040, -0.4963,  0.0000,  0.0000,  0.0000],
        [-1.4262,  0.6404, -2.6275,  0.0000,  0.0000,  0.0000],
        [ 0.7764,  1.0273,  1.3778,  0.0000,  0.0000,  0.0000],
        [ 1.1862, -1.4719,  1.3854,  0.0000,  0.0000,  0.0000],
        [-0.4597, -0.4275, -2.5002,  0.0000,  0.0000,  0.0000],
        [-0.7842, -1.4940,  3.4875,  0.0000,  0.0000,  0.0000],
        [ 0.5047,  0.0189, -1.2501,  0.0000,  0.0000,  0.0000],
        [ 0.1669, -2.2159,  0.2813,  0.0000,  0.0000,  0.0000],
        [-0.3725,  0.7375, -0.0582,  0.0000,  0.0000,  0.0000],
        [ 0.5035, -1.2438,  1.0926,  0.0000,  0.0000,  0.0000],
        [ 0.8123, -1.8546, -1.5897,  0.0000,  0.0000,  0.0000],
        [-1.2479, -1.6702,  1.7104,  0.0000,  0.0000,  0.0000],
        [ 0.3240,  0.4978,  0.1685,  0.0000,  0.0000,  0.0000],
        [-0.7797,  0.7316,  2.9345,  0.0000,  0.0000,  0.0000],
        [-0.0417, -1.7471, -2.9647,  0.0000,  0.0000,  0.0000],
        [ 0.1053, -0.2329, -0.0511,  0.0000,  0.0000,  0.0000],
        [-1.8304, -0.5895,  0.8333,  0.0000,  0.0000,  0.0000],
        [ 1.1634, -0.5773, -1.9403,  0.0000,  0.0000,  0.0000],
        [-0.6690, -0.9916, -0.8331,  0.0000,  0.0000,  0.0000],
        [ 0.8897, -2.4152, -2.2496,  0.0000,  0.0000,  0.0000],
        [-1.1047,  0.3987,  1.0591,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  387
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0104, grad_fn=<DivBackward0>)
Projection Loss:  tensor(474.1158, grad_fn=<AddBackward0>)
Total Loss:  tensor(474.1261, grad_fn=<AddBackward0>)
Gradients:
2844.091064453125
Gradient before update: tensor(1144.2289)
Gradient after update: tensor(1144.2289)
current Learning Rate:  0.0001
------------------------------------------------------------------------------------------------------------------
Iteration:  388
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0104, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9446, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9550, grad_fn=<AddBackward0>)
Gradients:
525.54150390625
Gradient before update: tensor(203.2211)
Gradient after update: tensor(203.2211)
current Learning Rate:  0.0001
Total Loss:  tensor(473.9550, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4286,  0.3734, -3.6309,  0.0000,  0.0000,  0.0000],
        [-0.0977,  0.6027,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7519,  0.4584,  2.7578,  0.0000,  0.0000,  0.0000],
        [ 0.8340,  0.2381,  2.7937,  0.0000,  0.0000,  0.0000],
        [-0.0093,  0.0185,  0.7144,  0.0000,  0.0000,  0.0000],
        [ 1.1864,  0.2349, -0.8295,  0.0000,  0.0000,  0.0000],
        [ 0.4700,  0.5245, -0.5651,  0.0000,  0.0000,  0.0000],
        [ 1.2587,  0.3785,  0.7716,  0.0000,  0.0000,  0.0000],
        [-0.5859, -2.2110, -1.3243,  0.0000,  0.0000,  0.0000],
        [ 0.8977, -0.2743,  1.0828,  0.0000,  0.0000,  0.0000],
        [-1.5424, -1.5056, -3.4425,  0.0000,  0.0000,  0.0000],
        [-1.0808, -0.5001,  0.9583,  0.0000,  0.0000,  0.0000],
        [ 0.3770, -0.3800, -2.1631,  0.0000,  0.0000,  0.0000],
        [ 1.2666,  1.0545,  3.2836,  0.0000,  0.0000,  0.0000],
        [-1.1985, -0.8344, -3.2398,  0.0000,  0.0000,  0.0000],
        [-1.2933,  1.0473, -3.4489,  0.0000,  0.0000,  0.0000],
        [ 1.5089,  0.9237,  2.1469,  0.0000,  0.0000,  0.0000],
        [ 0.0687, -0.7583,  2.9165,  0.0000,  0.0000,  0.0000],
        [-0.7854,  0.8514, -1.9949,  0.0000,  0.0000,  0.0000],
        [-0.3369, -1.2228,  0.3728,  0.0000,  0.0000,  0.0000],
        [ 1.4668,  0.8598, -0.3378,  0.0000,  0.0000,  0.0000],
        [-1.2010,  0.9602,  1.6485,  0.0000,  0.0000,  0.0000],
        [ 0.9350,  0.8963, -1.0833,  0.0000,  0.0000,  0.0000],
        [ 0.4311,  0.9769, -1.4868,  0.0000,  0.0000,  0.0000],
        [-1.2599, -0.0850, -1.6198,  0.0000,  0.0000,  0.0000],
        [ 0.6151, -0.6362, -3.5844,  0.0000,  0.0000,  0.0000],
        [-1.8370, -0.1627, -0.5837,  0.0000,  0.0000,  0.0000],
        [-0.5275,  0.0846, -1.4248,  0.0000,  0.0000,  0.0000],
        [ 0.9121, -0.9444,  0.2528,  0.0000,  0.0000,  0.0000],
        [ 0.1707, -0.4497,  1.4389,  0.0000,  0.0000,  0.0000],
        [-0.6810, -0.4438,  2.3332,  0.0000,  0.0000,  0.0000],
        [ 0.4507,  0.6472, -2.8171,  0.0000,  0.0000,  0.0000],
        [ 1.4876, -1.1497, -0.7500,  0.0000,  0.0000,  0.0000],
        [ 1.0575,  0.4994, -2.3336,  0.0000,  0.0000,  0.0000],
        [-1.8375, -1.3040, -0.4965,  0.0000,  0.0000,  0.0000],
        [-1.4264,  0.6406, -2.6274,  0.0000,  0.0000,  0.0000],
        [ 0.7766,  1.0275,  1.3777,  0.0000,  0.0000,  0.0000],
        [ 1.1864, -1.4721,  1.3853,  0.0000,  0.0000,  0.0000],
        [-0.4595, -0.4277, -2.5002,  0.0000,  0.0000,  0.0000],
        [-0.7844, -1.4939,  3.4874,  0.0000,  0.0000,  0.0000],
        [ 0.5047,  0.0187, -1.2500,  0.0000,  0.0000,  0.0000],
        [ 0.1669, -2.2158,  0.2815,  0.0000,  0.0000,  0.0000],
        [-0.3724,  0.7376, -0.0581,  0.0000,  0.0000,  0.0000],
        [ 0.5033, -1.2439,  1.0924,  0.0000,  0.0000,  0.0000],
        [ 0.8121, -1.8545, -1.5896,  0.0000,  0.0000,  0.0000],
        [-1.2478, -1.6704,  1.7103,  0.0000,  0.0000,  0.0000],
        [ 0.3238,  0.4977,  0.1685,  0.0000,  0.0000,  0.0000],
        [-0.7795,  0.7314,  2.9344,  0.0000,  0.0000,  0.0000],
        [-0.0417, -1.7473, -2.9645,  0.0000,  0.0000,  0.0000],
        [ 0.1051, -0.2331, -0.0512,  0.0000,  0.0000,  0.0000],
        [-1.8306, -0.5895,  0.8332,  0.0000,  0.0000,  0.0000],
        [ 1.1636, -0.5771, -1.9402,  0.0000,  0.0000,  0.0000],
        [-0.6688, -0.9916, -0.8331,  0.0000,  0.0000,  0.0000],
        [ 0.8896, -2.4150, -2.2496,  0.0000,  0.0000,  0.0000],
        [-1.1046,  0.3985,  1.0589,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  389
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0103, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9431, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9535, grad_fn=<AddBackward0>)
Gradients:
7.949160099029541
Gradient before update: tensor(-10.2885)
Gradient after update: tensor(-10.2885)
current Learning Rate:  0.0001
------------------------------------------------------------------------------------------------------------------
Iteration:  390
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0103, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9424, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9527, grad_fn=<AddBackward0>)
Gradients:
8.144721984863281
Gradient before update: tensor(-10.5809)
Gradient after update: tensor(-10.5809)
current Learning Rate:  0.0001
Total Loss:  tensor(473.9527, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4284,  0.3732, -3.6307,  0.0000,  0.0000,  0.0000],
        [-0.0975,  0.6029,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7521,  0.4586,  2.7580,  0.0000,  0.0000,  0.0000],
        [ 0.8340,  0.2379,  2.7937,  0.0000,  0.0000,  0.0000],
        [-0.0095,  0.0187,  0.7142,  0.0000,  0.0000,  0.0000],
        [ 1.1865,  0.2347, -0.8295,  0.0000,  0.0000,  0.0000],
        [ 0.4699,  0.5246, -0.5652,  0.0000,  0.0000,  0.0000],
        [ 1.2589,  0.3783,  0.7717,  0.0000,  0.0000,  0.0000],
        [-0.5859, -2.2112, -1.3242,  0.0000,  0.0000,  0.0000],
        [ 0.8979, -0.2741,  1.0829,  0.0000,  0.0000,  0.0000],
        [-1.5422, -1.5057, -3.4427,  0.0000,  0.0000,  0.0000],
        [-1.0810, -0.4999,  0.9583,  0.0000,  0.0000,  0.0000],
        [ 0.3772, -0.3802, -2.1630,  0.0000,  0.0000,  0.0000],
        [ 1.2667,  1.0547,  3.2837,  0.0000,  0.0000,  0.0000],
        [-1.1986, -0.8345, -3.2397,  0.0000,  0.0000,  0.0000],
        [-1.2933,  1.0471, -3.4491,  0.0000,  0.0000,  0.0000],
        [ 1.5091,  0.9239,  2.1468,  0.0000,  0.0000,  0.0000],
        [ 0.0685, -0.7585,  2.9166,  0.0000,  0.0000,  0.0000],
        [-0.7853,  0.8515, -1.9951,  0.0000,  0.0000,  0.0000],
        [-0.3367, -1.2230,  0.3727,  0.0000,  0.0000,  0.0000],
        [ 1.4669,  0.8597, -0.3377,  0.0000,  0.0000,  0.0000],
        [-1.2008,  0.9604,  1.6483,  0.0000,  0.0000,  0.0000],
        [ 0.9352,  0.8965, -1.0831,  0.0000,  0.0000,  0.0000],
        [ 0.4312,  0.9768, -1.4867,  0.0000,  0.0000,  0.0000],
        [-1.2597, -0.0848, -1.6197,  0.0000,  0.0000,  0.0000],
        [ 0.6149, -0.6364, -3.5842,  0.0000,  0.0000,  0.0000],
        [-1.8372, -0.1625, -0.5836,  0.0000,  0.0000,  0.0000],
        [-0.5277,  0.0847, -1.4249,  0.0000,  0.0000,  0.0000],
        [ 0.9122, -0.9446,  0.2527,  0.0000,  0.0000,  0.0000],
        [ 0.1706, -0.4499,  1.4388,  0.0000,  0.0000,  0.0000],
        [-0.6812, -0.4436,  2.3332,  0.0000,  0.0000,  0.0000],
        [ 0.4505,  0.6474, -2.8170,  0.0000,  0.0000,  0.0000],
        [ 1.4877, -1.1499, -0.7500,  0.0000,  0.0000,  0.0000],
        [ 1.0573,  0.4996, -2.3335,  0.0000,  0.0000,  0.0000],
        [-1.8375, -1.3040, -0.4966,  0.0000,  0.0000,  0.0000],
        [-1.4266,  0.6407, -2.6272,  0.0000,  0.0000,  0.0000],
        [ 0.7767,  1.0276,  1.3776,  0.0000,  0.0000,  0.0000],
        [ 1.1865, -1.4722,  1.3851,  0.0000,  0.0000,  0.0000],
        [-0.4593, -0.4279, -2.5002,  0.0000,  0.0000,  0.0000],
        [-0.7845, -1.4937,  3.4872,  0.0000,  0.0000,  0.0000],
        [ 0.5046,  0.0185, -1.2500,  0.0000,  0.0000,  0.0000],
        [ 0.1668, -2.2158,  0.2817,  0.0000,  0.0000,  0.0000],
        [-0.3722,  0.7378, -0.0579,  0.0000,  0.0000,  0.0000],
        [ 0.5032, -1.2441,  1.0922,  0.0000,  0.0000,  0.0000],
        [ 0.8120, -1.8543, -1.5894,  0.0000,  0.0000,  0.0000],
        [-1.2477, -1.6706,  1.7101,  0.0000,  0.0000,  0.0000],
        [ 0.3236,  0.4975,  0.1685,  0.0000,  0.0000,  0.0000],
        [-0.7793,  0.7312,  2.9344,  0.0000,  0.0000,  0.0000],
        [-0.0417, -1.7475, -2.9643,  0.0000,  0.0000,  0.0000],
        [ 0.1049, -0.2333, -0.0512,  0.0000,  0.0000,  0.0000],
        [-1.8307, -0.5895,  0.8332,  0.0000,  0.0000,  0.0000],
        [ 1.1638, -0.5770, -1.9400,  0.0000,  0.0000,  0.0000],
        [-0.6685, -0.9916, -0.8331,  0.0000,  0.0000,  0.0000],
        [ 0.8896, -2.4148, -2.2496,  0.0000,  0.0000,  0.0000],
        [-1.1044,  0.3984,  1.0587,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  391
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0103, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.9416, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.9519, grad_fn=<AddBackward0>)
Gradients:
8.32420825958252
Gradient before update: tensor(-10.8267)
Gradient after update: tensor(-10.8267)
current Learning Rate:  0.0001
------------------------------------------------------------------------------------------------------------------
Iteration:  392
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0103, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.3369, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.3472, grad_fn=<AddBackward0>)
Gradients:
4985.92724609375
Gradient before update: tensor(-5355.6030)
Gradient after update: tensor(-5355.6030)
current Learning Rate:  0.0001
Total Loss:  tensor(473.3472, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4283,  0.3731, -3.6305,  0.0000,  0.0000,  0.0000],
        [-0.0974,  0.6030,  1.7916,  0.0000,  0.0000,  0.0000],
        [-1.7523,  0.4587,  2.7582,  0.0000,  0.0000,  0.0000],
        [ 0.8341,  0.2377,  2.7937,  0.0000,  0.0000,  0.0000],
        [-0.0097,  0.0189,  0.7141,  0.0000,  0.0000,  0.0000],
        [ 1.1867,  0.2345, -0.8294,  0.0000,  0.0000,  0.0000],
        [ 0.4698,  0.5246, -0.5653,  0.0000,  0.0000,  0.0000],
        [ 1.2590,  0.3782,  0.7719,  0.0000,  0.0000,  0.0000],
        [-0.5860, -2.2114, -1.3240,  0.0000,  0.0000,  0.0000],
        [ 0.8981, -0.2740,  1.0831,  0.0000,  0.0000,  0.0000],
        [-1.5420, -1.5059, -3.4428,  0.0000,  0.0000,  0.0000],
        [-1.0812, -0.4997,  0.9583,  0.0000,  0.0000,  0.0000],
        [ 0.3774, -0.3804, -2.1629,  0.0000,  0.0000,  0.0000],
        [ 1.2669,  1.0548,  3.2839,  0.0000,  0.0000,  0.0000],
        [-1.1988, -0.8346, -3.2395,  0.0000,  0.0000,  0.0000],
        [-1.2933,  1.0470, -3.4493,  0.0000,  0.0000,  0.0000],
        [ 1.5093,  0.9240,  2.1466,  0.0000,  0.0000,  0.0000],
        [ 0.0683, -0.7587,  2.9167,  0.0000,  0.0000,  0.0000],
        [-0.7851,  0.8517, -1.9952,  0.0000,  0.0000,  0.0000],
        [-0.3365, -1.2232,  0.3726,  0.0000,  0.0000,  0.0000],
        [ 1.4670,  0.8596, -0.3376,  0.0000,  0.0000,  0.0000],
        [-1.2006,  0.9606,  1.6482,  0.0000,  0.0000,  0.0000],
        [ 0.9354,  0.8967, -1.0829,  0.0000,  0.0000,  0.0000],
        [ 0.4313,  0.9767, -1.4866,  0.0000,  0.0000,  0.0000],
        [-1.2596, -0.0846, -1.6196,  0.0000,  0.0000,  0.0000],
        [ 0.6147, -0.6366, -3.5840,  0.0000,  0.0000,  0.0000],
        [-1.8374, -0.1623, -0.5834,  0.0000,  0.0000,  0.0000],
        [-0.5279,  0.0849, -1.4250,  0.0000,  0.0000,  0.0000],
        [ 0.9123, -0.9448,  0.2526,  0.0000,  0.0000,  0.0000],
        [ 0.1704, -0.4501,  1.4387,  0.0000,  0.0000,  0.0000],
        [-0.6814, -0.4434,  2.3331,  0.0000,  0.0000,  0.0000],
        [ 0.4503,  0.6476, -2.8169,  0.0000,  0.0000,  0.0000],
        [ 1.4879, -1.1500, -0.7500,  0.0000,  0.0000,  0.0000],
        [ 1.0571,  0.4998, -2.3335,  0.0000,  0.0000,  0.0000],
        [-1.8375, -1.3040, -0.4968,  0.0000,  0.0000,  0.0000],
        [-1.4267,  0.6409, -2.6271,  0.0000,  0.0000,  0.0000],
        [ 0.7768,  1.0278,  1.3774,  0.0000,  0.0000,  0.0000],
        [ 1.1867, -1.4724,  1.3850,  0.0000,  0.0000,  0.0000],
        [-0.4591, -0.4281, -2.5002,  0.0000,  0.0000,  0.0000],
        [-0.7846, -1.4936,  3.4870,  0.0000,  0.0000,  0.0000],
        [ 0.5045,  0.0184, -1.2500,  0.0000,  0.0000,  0.0000],
        [ 0.1668, -2.2157,  0.2818,  0.0000,  0.0000,  0.0000],
        [-0.3721,  0.7379, -0.0578,  0.0000,  0.0000,  0.0000],
        [ 0.5030, -1.2443,  1.0920,  0.0000,  0.0000,  0.0000],
        [ 0.8119, -1.8542, -1.5893,  0.0000,  0.0000,  0.0000],
        [-1.2477, -1.6708,  1.7099,  0.0000,  0.0000,  0.0000],
        [ 0.3234,  0.4973,  0.1685,  0.0000,  0.0000,  0.0000],
        [-0.7791,  0.7310,  2.9345,  0.0000,  0.0000,  0.0000],
        [-0.0416, -1.7476, -2.9641,  0.0000,  0.0000,  0.0000],
        [ 0.1047, -0.2335, -0.0513,  0.0000,  0.0000,  0.0000],
        [-1.8309, -0.5895,  0.8333,  0.0000,  0.0000,  0.0000],
        [ 1.1640, -0.5768, -1.9399,  0.0000,  0.0000,  0.0000],
        [-0.6683, -0.9916, -0.8331,  0.0000,  0.0000,  0.0000],
        [ 0.8896, -2.4146, -2.2497,  0.0000,  0.0000,  0.0000],
        [-1.1042,  0.3982,  1.0585,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  393
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0103, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.1551, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.1653, grad_fn=<AddBackward0>)
Gradients:
1996.4041748046875
Gradient before update: tensor(-2151.1321)
Gradient after update: tensor(-2151.1321)
current Learning Rate:  0.0001
------------------------------------------------------------------------------------------------------------------
Iteration:  394
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0103, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.0623, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.0725, grad_fn=<AddBackward0>)
Gradients:
865.7913818359375
Gradient before update: tensor(-939.1821)
Gradient after update: tensor(-939.1821)
current Learning Rate:  0.0001
Total Loss:  tensor(473.0725, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4281,  0.3729, -3.6303,  0.0000,  0.0000,  0.0000],
        [-0.0972,  0.6032,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7525,  0.4588,  2.7584,  0.0000,  0.0000,  0.0000],
        [ 0.8341,  0.2375,  2.7937,  0.0000,  0.0000,  0.0000],
        [-0.0099,  0.0191,  0.7141,  0.0000,  0.0000,  0.0000],
        [ 1.1868,  0.2344, -0.8293,  0.0000,  0.0000,  0.0000],
        [ 0.4698,  0.5247, -0.5653,  0.0000,  0.0000,  0.0000],
        [ 1.2592,  0.3780,  0.7721,  0.0000,  0.0000,  0.0000],
        [-0.5860, -2.2115, -1.3238,  0.0000,  0.0000,  0.0000],
        [ 0.8982, -0.2738,  1.0832,  0.0000,  0.0000,  0.0000],
        [-1.5418, -1.5061, -3.4430,  0.0000,  0.0000,  0.0000],
        [-1.0814, -0.4995,  0.9583,  0.0000,  0.0000,  0.0000],
        [ 0.3776, -0.3806, -2.1628,  0.0000,  0.0000,  0.0000],
        [ 1.2670,  1.0549,  3.2840,  0.0000,  0.0000,  0.0000],
        [-1.1989, -0.8347, -3.2393,  0.0000,  0.0000,  0.0000],
        [-1.2933,  1.0468, -3.4495,  0.0000,  0.0000,  0.0000],
        [ 1.5094,  0.9242,  2.1464,  0.0000,  0.0000,  0.0000],
        [ 0.0681, -0.7589,  2.9167,  0.0000,  0.0000,  0.0000],
        [-0.7850,  0.8518, -1.9954,  0.0000,  0.0000,  0.0000],
        [-0.3363, -1.2234,  0.3725,  0.0000,  0.0000,  0.0000],
        [ 1.4671,  0.8595, -0.3375,  0.0000,  0.0000,  0.0000],
        [-1.2004,  0.9608,  1.6480,  0.0000,  0.0000,  0.0000],
        [ 0.9356,  0.8969, -1.0827,  0.0000,  0.0000,  0.0000],
        [ 0.4314,  0.9766, -1.4866,  0.0000,  0.0000,  0.0000],
        [-1.2595, -0.0846, -1.6196,  0.0000,  0.0000,  0.0000],
        [ 0.6145, -0.6368, -3.5838,  0.0000,  0.0000,  0.0000],
        [-1.8376, -0.1622, -0.5833,  0.0000,  0.0000,  0.0000],
        [-0.5281,  0.0850, -1.4251,  0.0000,  0.0000,  0.0000],
        [ 0.9124, -0.9450,  0.2525,  0.0000,  0.0000,  0.0000],
        [ 0.1702, -0.4503,  1.4386,  0.0000,  0.0000,  0.0000],
        [-0.6816, -0.4432,  2.3330,  0.0000,  0.0000,  0.0000],
        [ 0.4501,  0.6478, -2.8168,  0.0000,  0.0000,  0.0000],
        [ 1.4880, -1.1502, -0.7500,  0.0000,  0.0000,  0.0000],
        [ 1.0569,  0.5000, -2.3335,  0.0000,  0.0000,  0.0000],
        [-1.8375, -1.3041, -0.4969,  0.0000,  0.0000,  0.0000],
        [-1.4269,  0.6411, -2.6270,  0.0000,  0.0000,  0.0000],
        [ 0.7769,  1.0279,  1.3773,  0.0000,  0.0000,  0.0000],
        [ 1.1868, -1.4725,  1.3848,  0.0000,  0.0000,  0.0000],
        [-0.4589, -0.4283, -2.5002,  0.0000,  0.0000,  0.0000],
        [-0.7848, -1.4935,  3.4868,  0.0000,  0.0000,  0.0000],
        [ 0.5044,  0.0182, -1.2500,  0.0000,  0.0000,  0.0000],
        [ 0.1668, -2.2157,  0.2820,  0.0000,  0.0000,  0.0000],
        [-0.3719,  0.7381, -0.0577,  0.0000,  0.0000,  0.0000],
        [ 0.5028, -1.2445,  1.0919,  0.0000,  0.0000,  0.0000],
        [ 0.8118, -1.8541, -1.5892,  0.0000,  0.0000,  0.0000],
        [-1.2477, -1.6709,  1.7097,  0.0000,  0.0000,  0.0000],
        [ 0.3232,  0.4971,  0.1685,  0.0000,  0.0000,  0.0000],
        [-0.7789,  0.7308,  2.9346,  0.0000,  0.0000,  0.0000],
        [-0.0416, -1.7478, -2.9640,  0.0000,  0.0000,  0.0000],
        [ 0.1045, -0.2336, -0.0513,  0.0000,  0.0000,  0.0000],
        [-1.8311, -0.5895,  0.8333,  0.0000,  0.0000,  0.0000],
        [ 1.1642, -0.5767, -1.9398,  0.0000,  0.0000,  0.0000],
        [-0.6681, -0.9916, -0.8331,  0.0000,  0.0000,  0.0000],
        [ 0.8897, -2.4144, -2.2497,  0.0000,  0.0000,  0.0000],
        [-1.1040,  0.3980,  1.0584,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  395
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0102, grad_fn=<DivBackward0>)
Projection Loss:  tensor(473.0167, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.0270, grad_fn=<AddBackward0>)
Gradients:
442.2517395019531
Gradient before update: tensor(-485.0624)
Gradient after update: tensor(-485.0624)
current Learning Rate:  0.0001
------------------------------------------------------------------------------------------------------------------
Iteration:  396
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0102, grad_fn=<DivBackward0>)
Projection Loss:  tensor(472.9921, grad_fn=<AddBackward0>)
Total Loss:  tensor(473.0023, grad_fn=<AddBackward0>)
Gradients:
259.005615234375
Gradient before update: tensor(-288.3921)
Gradient after update: tensor(-288.3921)
current Learning Rate:  0.0001
Total Loss:  tensor(473.0023, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4279,  0.3727, -3.6301,  0.0000,  0.0000,  0.0000],
        [-0.0970,  0.6034,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7526,  0.4589,  2.7586,  0.0000,  0.0000,  0.0000],
        [ 0.8341,  0.2373,  2.7937,  0.0000,  0.0000,  0.0000],
        [-0.0101,  0.0193,  0.7140,  0.0000,  0.0000,  0.0000],
        [ 1.1870,  0.2342, -0.8291,  0.0000,  0.0000,  0.0000],
        [ 0.4697,  0.5247, -0.5653,  0.0000,  0.0000,  0.0000],
        [ 1.2593,  0.3779,  0.7722,  0.0000,  0.0000,  0.0000],
        [-0.5861, -2.2116, -1.3237,  0.0000,  0.0000,  0.0000],
        [ 0.8984, -0.2736,  1.0833,  0.0000,  0.0000,  0.0000],
        [-1.5416, -1.5063, -3.4432,  0.0000,  0.0000,  0.0000],
        [-1.0816, -0.4993,  0.9583,  0.0000,  0.0000,  0.0000],
        [ 0.3778, -0.3808, -2.1627,  0.0000,  0.0000,  0.0000],
        [ 1.2671,  1.0550,  3.2841,  0.0000,  0.0000,  0.0000],
        [-1.1990, -0.8349, -3.2391,  0.0000,  0.0000,  0.0000],
        [-1.2933,  1.0467, -3.4497,  0.0000,  0.0000,  0.0000],
        [ 1.5096,  0.9244,  2.1462,  0.0000,  0.0000,  0.0000],
        [ 0.0680, -0.7591,  2.9168,  0.0000,  0.0000,  0.0000],
        [-0.7849,  0.8519, -1.9955,  0.0000,  0.0000,  0.0000],
        [-0.3361, -1.2236,  0.3724,  0.0000,  0.0000,  0.0000],
        [ 1.4672,  0.8594, -0.3374,  0.0000,  0.0000,  0.0000],
        [-1.2002,  0.9610,  1.6478,  0.0000,  0.0000,  0.0000],
        [ 0.9358,  0.8971, -1.0825,  0.0000,  0.0000,  0.0000],
        [ 0.4314,  0.9766, -1.4865,  0.0000,  0.0000,  0.0000],
        [-1.2596, -0.0847, -1.6197,  0.0000,  0.0000,  0.0000],
        [ 0.6143, -0.6370, -3.5836,  0.0000,  0.0000,  0.0000],
        [-1.8377, -0.1620, -0.5833,  0.0000,  0.0000,  0.0000],
        [-0.5283,  0.0852, -1.4251,  0.0000,  0.0000,  0.0000],
        [ 0.9125, -0.9452,  0.2524,  0.0000,  0.0000,  0.0000],
        [ 0.1700, -0.4504,  1.4385,  0.0000,  0.0000,  0.0000],
        [-0.6818, -0.4430,  2.3330,  0.0000,  0.0000,  0.0000],
        [ 0.4499,  0.6480, -2.8167,  0.0000,  0.0000,  0.0000],
        [ 1.4882, -1.1503, -0.7500,  0.0000,  0.0000,  0.0000],
        [ 1.0568,  0.5002, -2.3335,  0.0000,  0.0000,  0.0000],
        [-1.8375, -1.3041, -0.4970,  0.0000,  0.0000,  0.0000],
        [-1.4271,  0.6413, -2.6269,  0.0000,  0.0000,  0.0000],
        [ 0.7771,  1.0280,  1.3772,  0.0000,  0.0000,  0.0000],
        [ 1.1870, -1.4727,  1.3847,  0.0000,  0.0000,  0.0000],
        [-0.4587, -0.4284, -2.5003,  0.0000,  0.0000,  0.0000],
        [-0.7849, -1.4933,  3.4867,  0.0000,  0.0000,  0.0000],
        [ 0.5043,  0.0180, -1.2500,  0.0000,  0.0000,  0.0000],
        [ 0.1669, -2.2158,  0.2822,  0.0000,  0.0000,  0.0000],
        [-0.3718,  0.7382, -0.0576,  0.0000,  0.0000,  0.0000],
        [ 0.5026, -1.2447,  1.0917,  0.0000,  0.0000,  0.0000],
        [ 0.8117, -1.8540, -1.5891,  0.0000,  0.0000,  0.0000],
        [-1.2477, -1.6711,  1.7095,  0.0000,  0.0000,  0.0000],
        [ 0.3230,  0.4969,  0.1685,  0.0000,  0.0000,  0.0000],
        [-0.7787,  0.7306,  2.9347,  0.0000,  0.0000,  0.0000],
        [-0.0416, -1.7479, -2.9638,  0.0000,  0.0000,  0.0000],
        [ 0.1043, -0.2338, -0.0513,  0.0000,  0.0000,  0.0000],
        [-1.8313, -0.5895,  0.8334,  0.0000,  0.0000,  0.0000],
        [ 1.1644, -0.5767, -1.9396,  0.0000,  0.0000,  0.0000],
        [-0.6679, -0.9916, -0.8331,  0.0000,  0.0000,  0.0000],
        [ 0.8897, -2.4141, -2.2497,  0.0000,  0.0000,  0.0000],
        [-1.1038,  0.3978,  1.0582,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  397
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0102, grad_fn=<DivBackward0>)
Projection Loss:  tensor(472.9773, grad_fn=<AddBackward0>)
Total Loss:  tensor(472.9875, grad_fn=<AddBackward0>)
Gradients:
168.09213256835938
Gradient before update: tensor(-190.5260)
Gradient after update: tensor(-190.5260)
current Learning Rate:  0.0001
------------------------------------------------------------------------------------------------------------------
Iteration:  398
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0102, grad_fn=<DivBackward0>)
Projection Loss:  tensor(472.9675, grad_fn=<AddBackward0>)
Total Loss:  tensor(472.9777, grad_fn=<AddBackward0>)
Gradients:
117.85486602783203
Gradient before update: tensor(-136.0817)
Gradient after update: tensor(-136.0817)
current Learning Rate:  0.0001
Total Loss:  tensor(472.9777, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4277,  0.3725, -3.6299,  0.0000,  0.0000,  0.0000],
        [-0.0968,  0.6036,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7528,  0.4589,  2.7587,  0.0000,  0.0000,  0.0000],
        [ 0.8341,  0.2371,  2.7937,  0.0000,  0.0000,  0.0000],
        [-0.0103,  0.0195,  0.7140,  0.0000,  0.0000,  0.0000],
        [ 1.1872,  0.2341, -0.8289,  0.0000,  0.0000,  0.0000],
        [ 0.4697,  0.5247, -0.5654,  0.0000,  0.0000,  0.0000],
        [ 1.2595,  0.3777,  0.7723,  0.0000,  0.0000,  0.0000],
        [-0.5861, -2.2117, -1.3235,  0.0000,  0.0000,  0.0000],
        [ 0.8986, -0.2734,  1.0833,  0.0000,  0.0000,  0.0000],
        [-1.5414, -1.5065, -3.4434,  0.0000,  0.0000,  0.0000],
        [-1.0818, -0.4992,  0.9583,  0.0000,  0.0000,  0.0000],
        [ 0.3780, -0.3810, -2.1626,  0.0000,  0.0000,  0.0000],
        [ 1.2672,  1.0552,  3.2842,  0.0000,  0.0000,  0.0000],
        [-1.1992, -0.8350, -3.2388,  0.0000,  0.0000,  0.0000],
        [-1.2934,  1.0466, -3.4499,  0.0000,  0.0000,  0.0000],
        [ 1.5098,  0.9246,  2.1460,  0.0000,  0.0000,  0.0000],
        [ 0.0678, -0.7593,  2.9168,  0.0000,  0.0000,  0.0000],
        [-0.7848,  0.8521, -1.9956,  0.0000,  0.0000,  0.0000],
        [-0.3360, -1.2238,  0.3723,  0.0000,  0.0000,  0.0000],
        [ 1.4673,  0.8593, -0.3373,  0.0000,  0.0000,  0.0000],
        [-1.2000,  0.9612,  1.6476,  0.0000,  0.0000,  0.0000],
        [ 0.9360,  0.8973, -1.0823,  0.0000,  0.0000,  0.0000],
        [ 0.4315,  0.9765, -1.4865,  0.0000,  0.0000,  0.0000],
        [-1.2597, -0.0848, -1.6198,  0.0000,  0.0000,  0.0000],
        [ 0.6141, -0.6372, -3.5834,  0.0000,  0.0000,  0.0000],
        [-1.8379, -0.1618, -0.5832,  0.0000,  0.0000,  0.0000],
        [-0.5285,  0.0854, -1.4251,  0.0000,  0.0000,  0.0000],
        [ 0.9126, -0.9454,  0.2523,  0.0000,  0.0000,  0.0000],
        [ 0.1698, -0.4506,  1.4384,  0.0000,  0.0000,  0.0000],
        [-0.6820, -0.4427,  2.3329,  0.0000,  0.0000,  0.0000],
        [ 0.4497,  0.6482, -2.8166,  0.0000,  0.0000,  0.0000],
        [ 1.4884, -1.1505, -0.7500,  0.0000,  0.0000,  0.0000],
        [ 1.0566,  0.5004, -2.3335,  0.0000,  0.0000,  0.0000],
        [-1.8374, -1.3041, -0.4971,  0.0000,  0.0000,  0.0000],
        [-1.4273,  0.6415, -2.6268,  0.0000,  0.0000,  0.0000],
        [ 0.7772,  1.0281,  1.3771,  0.0000,  0.0000,  0.0000],
        [ 1.1871, -1.4728,  1.3846,  0.0000,  0.0000,  0.0000],
        [-0.4586, -0.4286, -2.5003,  0.0000,  0.0000,  0.0000],
        [-0.7850, -1.4933,  3.4865,  0.0000,  0.0000,  0.0000],
        [ 0.5042,  0.0178, -1.2500,  0.0000,  0.0000,  0.0000],
        [ 0.1669, -2.2158,  0.2824,  0.0000,  0.0000,  0.0000],
        [-0.3717,  0.7383, -0.0574,  0.0000,  0.0000,  0.0000],
        [ 0.5024, -1.2448,  1.0915,  0.0000,  0.0000,  0.0000],
        [ 0.8115, -1.8539, -1.5890,  0.0000,  0.0000,  0.0000],
        [-1.2477, -1.6713,  1.7093,  0.0000,  0.0000,  0.0000],
        [ 0.3228,  0.4967,  0.1685,  0.0000,  0.0000,  0.0000],
        [-0.7785,  0.7304,  2.9348,  0.0000,  0.0000,  0.0000],
        [-0.0416, -1.7481, -2.9636,  0.0000,  0.0000,  0.0000],
        [ 0.1041, -0.2340, -0.0513,  0.0000,  0.0000,  0.0000],
        [-1.8314, -0.5896,  0.8334,  0.0000,  0.0000,  0.0000],
        [ 1.1646, -0.5766, -1.9395,  0.0000,  0.0000,  0.0000],
        [-0.6677, -0.9916, -0.8332,  0.0000,  0.0000,  0.0000],
        [ 0.8897, -2.4139, -2.2497,  0.0000,  0.0000,  0.0000],
        [-1.1037,  0.3976,  1.0581,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  399
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0102, grad_fn=<DivBackward0>)
Projection Loss:  tensor(472.9606, grad_fn=<AddBackward0>)
Total Loss:  tensor(472.9708, grad_fn=<AddBackward0>)
Gradients:
87.72037506103516
Gradient before update: tensor(-103.0010)
Gradient after update: tensor(-103.0010)
current Learning Rate:  0.0001
------------------------------------------------------------------------------------------------------------------
Iteration:  400
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0101, grad_fn=<DivBackward0>)
Projection Loss:  tensor(472.9553, grad_fn=<AddBackward0>)
Total Loss:  tensor(472.9655, grad_fn=<AddBackward0>)
Gradients:
68.45063018798828
Gradient before update: tensor(-81.3511)
Gradient after update: tensor(-81.3511)
current Learning Rate:  0.0001
Total Loss:  tensor(472.9655, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4275,  0.3723, -3.6297,  0.0000,  0.0000,  0.0000],
        [-0.0966,  0.6038,  1.7916,  0.0000,  0.0000,  0.0000],
        [-1.7529,  0.4589,  2.7589,  0.0000,  0.0000,  0.0000],
        [ 0.8341,  0.2369,  2.7937,  0.0000,  0.0000,  0.0000],
        [-0.0105,  0.0197,  0.7139,  0.0000,  0.0000,  0.0000],
        [ 1.1873,  0.2339, -0.8287,  0.0000,  0.0000,  0.0000],
        [ 0.4697,  0.5248, -0.5654,  0.0000,  0.0000,  0.0000],
        [ 1.2596,  0.3776,  0.7725,  0.0000,  0.0000,  0.0000],
        [-0.5862, -2.2118, -1.3234,  0.0000,  0.0000,  0.0000],
        [ 0.8988, -0.2732,  1.0834,  0.0000,  0.0000,  0.0000],
        [-1.5412, -1.5066, -3.4436,  0.0000,  0.0000,  0.0000],
        [-1.0820, -0.4990,  0.9583,  0.0000,  0.0000,  0.0000],
        [ 0.3782, -0.3812, -2.1626,  0.0000,  0.0000,  0.0000],
        [ 1.2674,  1.0553,  3.2843,  0.0000,  0.0000,  0.0000],
        [-1.1993, -0.8350, -3.2386,  0.0000,  0.0000,  0.0000],
        [-1.2934,  1.0465, -3.4501,  0.0000,  0.0000,  0.0000],
        [ 1.5100,  0.9248,  2.1459,  0.0000,  0.0000,  0.0000],
        [ 0.0676, -0.7595,  2.9168,  0.0000,  0.0000,  0.0000],
        [-0.7847,  0.8521, -1.9957,  0.0000,  0.0000,  0.0000],
        [-0.3358, -1.2239,  0.3721,  0.0000,  0.0000,  0.0000],
        [ 1.4674,  0.8592, -0.3373,  0.0000,  0.0000,  0.0000],
        [-1.1998,  0.9614,  1.6474,  0.0000,  0.0000,  0.0000],
        [ 0.9362,  0.8975, -1.0821,  0.0000,  0.0000,  0.0000],
        [ 0.4315,  0.9765, -1.4865,  0.0000,  0.0000,  0.0000],
        [-1.2598, -0.0848, -1.6198,  0.0000,  0.0000,  0.0000],
        [ 0.6139, -0.6374, -3.5832,  0.0000,  0.0000,  0.0000],
        [-1.8381, -0.1617, -0.5831,  0.0000,  0.0000,  0.0000],
        [-0.5287,  0.0857, -1.4251,  0.0000,  0.0000,  0.0000],
        [ 0.9128, -0.9456,  0.2523,  0.0000,  0.0000,  0.0000],
        [ 0.1696, -0.4508,  1.4383,  0.0000,  0.0000,  0.0000],
        [-0.6823, -0.4425,  2.3329,  0.0000,  0.0000,  0.0000],
        [ 0.4495,  0.6484, -2.8165,  0.0000,  0.0000,  0.0000],
        [ 1.4885, -1.1506, -0.7500,  0.0000,  0.0000,  0.0000],
        [ 1.0564,  0.5006, -2.3335,  0.0000,  0.0000,  0.0000],
        [-1.8374, -1.3041, -0.4973,  0.0000,  0.0000,  0.0000],
        [-1.4274,  0.6416, -2.6267,  0.0000,  0.0000,  0.0000],
        [ 0.7773,  1.0282,  1.3771,  0.0000,  0.0000,  0.0000],
        [ 1.1872, -1.4729,  1.3844,  0.0000,  0.0000,  0.0000],
        [-0.4584, -0.4288, -2.5003,  0.0000,  0.0000,  0.0000],
        [-0.7851, -1.4932,  3.4863,  0.0000,  0.0000,  0.0000],
        [ 0.5042,  0.0177, -1.2500,  0.0000,  0.0000,  0.0000],
        [ 0.1669, -2.2159,  0.2825,  0.0000,  0.0000,  0.0000],
        [-0.3716,  0.7384, -0.0573,  0.0000,  0.0000,  0.0000],
        [ 0.5023, -1.2450,  1.0914,  0.0000,  0.0000,  0.0000],
        [ 0.8114, -1.8539, -1.5889,  0.0000,  0.0000,  0.0000],
        [-1.2476, -1.6715,  1.7091,  0.0000,  0.0000,  0.0000],
        [ 0.3226,  0.4965,  0.1684,  0.0000,  0.0000,  0.0000],
        [-0.7783,  0.7302,  2.9350,  0.0000,  0.0000,  0.0000],
        [-0.0416, -1.7482, -2.9634,  0.0000,  0.0000,  0.0000],
        [ 0.1039, -0.2341, -0.0513,  0.0000,  0.0000,  0.0000],
        [-1.8316, -0.5896,  0.8334,  0.0000,  0.0000,  0.0000],
        [ 1.1647, -0.5765, -1.9394,  0.0000,  0.0000,  0.0000],
        [-0.6676, -0.9917, -0.8332,  0.0000,  0.0000,  0.0000],
        [ 0.8897, -2.4137, -2.2497,  0.0000,  0.0000,  0.0000],
        [-1.1035,  0.3975,  1.0579,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  401
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0101, grad_fn=<DivBackward0>)
Projection Loss:  tensor(472.9512, grad_fn=<AddBackward0>)
Total Loss:  tensor(472.9613, grad_fn=<AddBackward0>)
Gradients:
55.50519561767578
Gradient before update: tensor(-66.2579)
Gradient after update: tensor(-66.2579)
current Learning Rate:  0.0001
------------------------------------------------------------------------------------------------------------------
Iteration:  402
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0101, grad_fn=<DivBackward0>)
Projection Loss:  tensor(472.9478, grad_fn=<AddBackward0>)
Total Loss:  tensor(472.9579, grad_fn=<AddBackward0>)
Gradients:
46.49434280395508
Gradient before update: tensor(-55.1709)
Gradient after update: tensor(-55.1709)
current Learning Rate:  0.0001
Total Loss:  tensor(472.9579, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4273,  0.3721, -3.6295,  0.0000,  0.0000,  0.0000],
        [-0.0964,  0.6040,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7531,  0.4589,  2.7591,  0.0000,  0.0000,  0.0000],
        [ 0.8341,  0.2368,  2.7937,  0.0000,  0.0000,  0.0000],
        [-0.0107,  0.0199,  0.7139,  0.0000,  0.0000,  0.0000],
        [ 1.1875,  0.2338, -0.8285,  0.0000,  0.0000,  0.0000],
        [ 0.4697,  0.5248, -0.5654,  0.0000,  0.0000,  0.0000],
        [ 1.2597,  0.3775,  0.7726,  0.0000,  0.0000,  0.0000],
        [-0.5863, -2.2119, -1.3232,  0.0000,  0.0000,  0.0000],
        [ 0.8990, -0.2730,  1.0835,  0.0000,  0.0000,  0.0000],
        [-1.5410, -1.5068, -3.4437,  0.0000,  0.0000,  0.0000],
        [-1.0822, -0.4988,  0.9583,  0.0000,  0.0000,  0.0000],
        [ 0.3784, -0.3814, -2.1625,  0.0000,  0.0000,  0.0000],
        [ 1.2675,  1.0554,  3.2844,  0.0000,  0.0000,  0.0000],
        [-1.1995, -0.8351, -3.2384,  0.0000,  0.0000,  0.0000],
        [-1.2934,  1.0465, -3.4504,  0.0000,  0.0000,  0.0000],
        [ 1.5102,  0.9249,  2.1457,  0.0000,  0.0000,  0.0000],
        [ 0.0675, -0.7597,  2.9168,  0.0000,  0.0000,  0.0000],
        [-0.7846,  0.8522, -1.9958,  0.0000,  0.0000,  0.0000],
        [-0.3356, -1.2241,  0.3720,  0.0000,  0.0000,  0.0000],
        [ 1.4674,  0.8592, -0.3372,  0.0000,  0.0000,  0.0000],
        [-1.1996,  0.9616,  1.6472,  0.0000,  0.0000,  0.0000],
        [ 0.9364,  0.8977, -1.0819,  0.0000,  0.0000,  0.0000],
        [ 0.4315,  0.9765, -1.4864,  0.0000,  0.0000,  0.0000],
        [-1.2598, -0.0849, -1.6199,  0.0000,  0.0000,  0.0000],
        [ 0.6137, -0.6376, -3.5830,  0.0000,  0.0000,  0.0000],
        [-1.8383, -0.1615, -0.5831,  0.0000,  0.0000,  0.0000],
        [-0.5289,  0.0859, -1.4250,  0.0000,  0.0000,  0.0000],
        [ 0.9129, -0.9458,  0.2522,  0.0000,  0.0000,  0.0000],
        [ 0.1694, -0.4510,  1.4382,  0.0000,  0.0000,  0.0000],
        [-0.6825, -0.4423,  2.3329,  0.0000,  0.0000,  0.0000],
        [ 0.4494,  0.6486, -2.8164,  0.0000,  0.0000,  0.0000],
        [ 1.4887, -1.1507, -0.7500,  0.0000,  0.0000,  0.0000],
        [ 1.0562,  0.5008, -2.3335,  0.0000,  0.0000,  0.0000],
        [-1.8373, -1.3041, -0.4974,  0.0000,  0.0000,  0.0000],
        [-1.4276,  0.6418, -2.6266,  0.0000,  0.0000,  0.0000],
        [ 0.7774,  1.0284,  1.3770,  0.0000,  0.0000,  0.0000],
        [ 1.1874, -1.4731,  1.3843,  0.0000,  0.0000,  0.0000],
        [-0.4582, -0.4290, -2.5002,  0.0000,  0.0000,  0.0000],
        [-0.7852, -1.4931,  3.4862,  0.0000,  0.0000,  0.0000],
        [ 0.5041,  0.0175, -1.2500,  0.0000,  0.0000,  0.0000],
        [ 0.1669, -2.2160,  0.2827,  0.0000,  0.0000,  0.0000],
        [-0.3715,  0.7385, -0.0573,  0.0000,  0.0000,  0.0000],
        [ 0.5021, -1.2452,  1.0912,  0.0000,  0.0000,  0.0000],
        [ 0.8114, -1.8538, -1.5889,  0.0000,  0.0000,  0.0000],
        [-1.2475, -1.6717,  1.7089,  0.0000,  0.0000,  0.0000],
        [ 0.3225,  0.4963,  0.1684,  0.0000,  0.0000,  0.0000],
        [-0.7781,  0.7300,  2.9351,  0.0000,  0.0000,  0.0000],
        [-0.0416, -1.7483, -2.9632,  0.0000,  0.0000,  0.0000],
        [ 0.1037, -0.2343, -0.0513,  0.0000,  0.0000,  0.0000],
        [-1.8318, -0.5896,  0.8334,  0.0000,  0.0000,  0.0000],
        [ 1.1649, -0.5765, -1.9393,  0.0000,  0.0000,  0.0000],
        [-0.6674, -0.9918, -0.8333,  0.0000,  0.0000,  0.0000],
        [ 0.8897, -2.4135, -2.2497,  0.0000,  0.0000,  0.0000],
        [-1.1033,  0.3973,  1.0578,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  403
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0101, grad_fn=<DivBackward0>)
Projection Loss:  tensor(472.9448, grad_fn=<AddBackward0>)
Total Loss:  tensor(472.9549, grad_fn=<AddBackward0>)
Gradients:
40.09596252441406
Gradient before update: tensor(-46.7402)
Gradient after update: tensor(-46.7402)
current Learning Rate:  0.0001
------------------------------------------------------------------------------------------------------------------
Iteration:  404
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0100, grad_fn=<DivBackward0>)
Projection Loss:  tensor(472.9422, grad_fn=<AddBackward0>)
Total Loss:  tensor(472.9522, grad_fn=<AddBackward0>)
Gradients:
35.48237609863281
Gradient before update: tensor(-40.2054)
Gradient after update: tensor(-40.2054)
current Learning Rate:  0.0001
Total Loss:  tensor(472.9522, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4272,  0.3719, -3.6293,  0.0000,  0.0000,  0.0000],
        [-0.0962,  0.6042,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7532,  0.4589,  2.7592,  0.0000,  0.0000,  0.0000],
        [ 0.8341,  0.2366,  2.7936,  0.0000,  0.0000,  0.0000],
        [-0.0110,  0.0202,  0.7139,  0.0000,  0.0000,  0.0000],
        [ 1.1876,  0.2337, -0.8282,  0.0000,  0.0000,  0.0000],
        [ 0.4696,  0.5248, -0.5654,  0.0000,  0.0000,  0.0000],
        [ 1.2599,  0.3773,  0.7727,  0.0000,  0.0000,  0.0000],
        [-0.5863, -2.2120, -1.3231,  0.0000,  0.0000,  0.0000],
        [ 0.8991, -0.2729,  1.0835,  0.0000,  0.0000,  0.0000],
        [-1.5408, -1.5070, -3.4439,  0.0000,  0.0000,  0.0000],
        [-1.0823, -0.4986,  0.9583,  0.0000,  0.0000,  0.0000],
        [ 0.3786, -0.3816, -2.1624,  0.0000,  0.0000,  0.0000],
        [ 1.2676,  1.0555,  3.2845,  0.0000,  0.0000,  0.0000],
        [-1.1996, -0.8352, -3.2381,  0.0000,  0.0000,  0.0000],
        [-1.2934,  1.0464, -3.4506,  0.0000,  0.0000,  0.0000],
        [ 1.5104,  0.9251,  2.1455,  0.0000,  0.0000,  0.0000],
        [ 0.0673, -0.7599,  2.9168,  0.0000,  0.0000,  0.0000],
        [-0.7845,  0.8523, -1.9958,  0.0000,  0.0000,  0.0000],
        [-0.3354, -1.2242,  0.3719,  0.0000,  0.0000,  0.0000],
        [ 1.4675,  0.8591, -0.3371,  0.0000,  0.0000,  0.0000],
        [-1.1994,  0.9618,  1.6470,  0.0000,  0.0000,  0.0000],
        [ 0.9366,  0.8979, -1.0817,  0.0000,  0.0000,  0.0000],
        [ 0.4316,  0.9765, -1.4864,  0.0000,  0.0000,  0.0000],
        [-1.2598, -0.0849, -1.6199,  0.0000,  0.0000,  0.0000],
        [ 0.6135, -0.6378, -3.5828,  0.0000,  0.0000,  0.0000],
        [-1.8385, -0.1614, -0.5831,  0.0000,  0.0000,  0.0000],
        [-0.5290,  0.0861, -1.4249,  0.0000,  0.0000,  0.0000],
        [ 0.9130, -0.9460,  0.2522,  0.0000,  0.0000,  0.0000],
        [ 0.1692, -0.4512,  1.4381,  0.0000,  0.0000,  0.0000],
        [-0.6827, -0.4421,  2.3329,  0.0000,  0.0000,  0.0000],
        [ 0.4492,  0.6488, -2.8163,  0.0000,  0.0000,  0.0000],
        [ 1.4888, -1.1509, -0.7500,  0.0000,  0.0000,  0.0000],
        [ 1.0560,  0.5010, -2.3335,  0.0000,  0.0000,  0.0000],
        [-1.8373, -1.3041, -0.4975,  0.0000,  0.0000,  0.0000],
        [-1.4278,  0.6420, -2.6265,  0.0000,  0.0000,  0.0000],
        [ 0.7774,  1.0285,  1.3769,  0.0000,  0.0000,  0.0000],
        [ 1.1875, -1.4732,  1.3842,  0.0000,  0.0000,  0.0000],
        [-0.4580, -0.4292, -2.5002,  0.0000,  0.0000,  0.0000],
        [-0.7853, -1.4930,  3.4860,  0.0000,  0.0000,  0.0000],
        [ 0.5041,  0.0173, -1.2500,  0.0000,  0.0000,  0.0000],
        [ 0.1670, -2.2162,  0.2829,  0.0000,  0.0000,  0.0000],
        [-0.3714,  0.7386, -0.0572,  0.0000,  0.0000,  0.0000],
        [ 0.5019, -1.2453,  1.0911,  0.0000,  0.0000,  0.0000],
        [ 0.8113, -1.8537, -1.5888,  0.0000,  0.0000,  0.0000],
        [-1.2474, -1.6719,  1.7088,  0.0000,  0.0000,  0.0000],
        [ 0.3223,  0.4961,  0.1683,  0.0000,  0.0000,  0.0000],
        [-0.7779,  0.7298,  2.9353,  0.0000,  0.0000,  0.0000],
        [-0.0416, -1.7484, -2.9631,  0.0000,  0.0000,  0.0000],
        [ 0.1035, -0.2345, -0.0513,  0.0000,  0.0000,  0.0000],
        [-1.8319, -0.5897,  0.8334,  0.0000,  0.0000,  0.0000],
        [ 1.1651, -0.5764, -1.9392,  0.0000,  0.0000,  0.0000],
        [-0.6672, -0.9919, -0.8333,  0.0000,  0.0000,  0.0000],
        [ 0.8897, -2.4132, -2.2497,  0.0000,  0.0000,  0.0000],
        [-1.1032,  0.3971,  1.0576,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  405
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0100, grad_fn=<DivBackward0>)
Projection Loss:  tensor(472.9398, grad_fn=<AddBackward0>)
Total Loss:  tensor(472.9498, grad_fn=<AddBackward0>)
Gradients:
32.12820053100586
Gradient before update: tensor(-35.2124)
Gradient after update: tensor(-35.2124)
current Learning Rate:  0.0001
------------------------------------------------------------------------------------------------------------------
Iteration:  406
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0100, grad_fn=<DivBackward0>)
Projection Loss:  tensor(472.9374, grad_fn=<AddBackward0>)
Total Loss:  tensor(472.9474, grad_fn=<AddBackward0>)
Gradients:
29.633142471313477
Gradient before update: tensor(-31.6233)
Gradient after update: tensor(-31.6233)
current Learning Rate:  0.0001
Total Loss:  tensor(472.9474, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4270,  0.3718, -3.6292,  0.0000,  0.0000,  0.0000],
        [-0.0960,  0.6044,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7533,  0.4589,  2.7594,  0.0000,  0.0000,  0.0000],
        [ 0.8341,  0.2364,  2.7936,  0.0000,  0.0000,  0.0000],
        [-0.0112,  0.0204,  0.7138,  0.0000,  0.0000,  0.0000],
        [ 1.1877,  0.2335, -0.8280,  0.0000,  0.0000,  0.0000],
        [ 0.4696,  0.5248, -0.5655,  0.0000,  0.0000,  0.0000],
        [ 1.2600,  0.3772,  0.7728,  0.0000,  0.0000,  0.0000],
        [-0.5864, -2.2120, -1.3229,  0.0000,  0.0000,  0.0000],
        [ 0.8993, -0.2727,  1.0835,  0.0000,  0.0000,  0.0000],
        [-1.5406, -1.5071, -3.4441,  0.0000,  0.0000,  0.0000],
        [-1.0825, -0.4984,  0.9583,  0.0000,  0.0000,  0.0000],
        [ 0.3788, -0.3818, -2.1624,  0.0000,  0.0000,  0.0000],
        [ 1.2676,  1.0556,  3.2846,  0.0000,  0.0000,  0.0000],
        [-1.1997, -0.8353, -3.2379,  0.0000,  0.0000,  0.0000],
        [-1.2934,  1.0464, -3.4508,  0.0000,  0.0000,  0.0000],
        [ 1.5105,  0.9253,  2.1454,  0.0000,  0.0000,  0.0000],
        [ 0.0672, -0.7600,  2.9168,  0.0000,  0.0000,  0.0000],
        [-0.7845,  0.8524, -1.9959,  0.0000,  0.0000,  0.0000],
        [-0.3352, -1.2243,  0.3718,  0.0000,  0.0000,  0.0000],
        [ 1.4676,  0.8590, -0.3371,  0.0000,  0.0000,  0.0000],
        [-1.1993,  0.9620,  1.6469,  0.0000,  0.0000,  0.0000],
        [ 0.9368,  0.8981, -1.0815,  0.0000,  0.0000,  0.0000],
        [ 0.4316,  0.9764, -1.4864,  0.0000,  0.0000,  0.0000],
        [-1.2599, -0.0849, -1.6199,  0.0000,  0.0000,  0.0000],
        [ 0.6133, -0.6380, -3.5826,  0.0000,  0.0000,  0.0000],
        [-1.8387, -0.1613, -0.5831,  0.0000,  0.0000,  0.0000],
        [-0.5292,  0.0864, -1.4249,  0.0000,  0.0000,  0.0000],
        [ 0.9131, -0.9462,  0.2521,  0.0000,  0.0000,  0.0000],
        [ 0.1690, -0.4514,  1.4381,  0.0000,  0.0000,  0.0000],
        [-0.6829, -0.4418,  2.3329,  0.0000,  0.0000,  0.0000],
        [ 0.4490,  0.6490, -2.8162,  0.0000,  0.0000,  0.0000],
        [ 1.4889, -1.1510, -0.7500,  0.0000,  0.0000,  0.0000],
        [ 1.0558,  0.5012, -2.3335,  0.0000,  0.0000,  0.0000],
        [-1.8373, -1.3041, -0.4976,  0.0000,  0.0000,  0.0000],
        [-1.4279,  0.6421, -2.6265,  0.0000,  0.0000,  0.0000],
        [ 0.7775,  1.0285,  1.3768,  0.0000,  0.0000,  0.0000],
        [ 1.1876, -1.4733,  1.3841,  0.0000,  0.0000,  0.0000],
        [-0.4578, -0.4294, -2.5001,  0.0000,  0.0000,  0.0000],
        [-0.7854, -1.4930,  3.4858,  0.0000,  0.0000,  0.0000],
        [ 0.5040,  0.0171, -1.2500,  0.0000,  0.0000,  0.0000],
        [ 0.1671, -2.2163,  0.2831,  0.0000,  0.0000,  0.0000],
        [-0.3713,  0.7387, -0.0571,  0.0000,  0.0000,  0.0000],
        [ 0.5018, -1.2455,  1.0909,  0.0000,  0.0000,  0.0000],
        [ 0.8112, -1.8537, -1.5887,  0.0000,  0.0000,  0.0000],
        [-1.2473, -1.6720,  1.7086,  0.0000,  0.0000,  0.0000],
        [ 0.3221,  0.4959,  0.1683,  0.0000,  0.0000,  0.0000],
        [-0.7777,  0.7296,  2.9354,  0.0000,  0.0000,  0.0000],
        [-0.0417, -1.7485, -2.9629,  0.0000,  0.0000,  0.0000],
        [ 0.1034, -0.2346, -0.0513,  0.0000,  0.0000,  0.0000],
        [-1.8321, -0.5897,  0.8333,  0.0000,  0.0000,  0.0000],
        [ 1.1653, -0.5764, -1.9390,  0.0000,  0.0000,  0.0000],
        [-0.6671, -0.9920, -0.8334,  0.0000,  0.0000,  0.0000],
        [ 0.8897, -2.4130, -2.2497,  0.0000,  0.0000,  0.0000],
        [-1.1030,  0.3970,  1.0575,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  407
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0100, grad_fn=<DivBackward0>)
Projection Loss:  tensor(472.9351, grad_fn=<AddBackward0>)
Total Loss:  tensor(472.9451, grad_fn=<AddBackward0>)
Gradients:
27.686111450195312
Gradient before update: tensor(-29.3712)
Gradient after update: tensor(-29.3712)
current Learning Rate:  0.0001
------------------------------------------------------------------------------------------------------------------
Iteration:  408
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0099, grad_fn=<DivBackward0>)
Projection Loss:  tensor(472.9329, grad_fn=<AddBackward0>)
Total Loss:  tensor(472.9428, grad_fn=<AddBackward0>)
Gradients:
26.084009170532227
Gradient before update: tensor(-28.4254)
Gradient after update: tensor(-28.4254)
current Learning Rate:  0.0001
Total Loss:  tensor(472.9428, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4268,  0.3716, -3.6290,  0.0000,  0.0000,  0.0000],
        [-0.0959,  0.6046,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7535,  0.4589,  2.7595,  0.0000,  0.0000,  0.0000],
        [ 0.8340,  0.2362,  2.7935,  0.0000,  0.0000,  0.0000],
        [-0.0114,  0.0206,  0.7138,  0.0000,  0.0000,  0.0000],
        [ 1.1879,  0.2334, -0.8278,  0.0000,  0.0000,  0.0000],
        [ 0.4696,  0.5248, -0.5655,  0.0000,  0.0000,  0.0000],
        [ 1.2601,  0.3771,  0.7730,  0.0000,  0.0000,  0.0000],
        [-0.5864, -2.2121, -1.3228,  0.0000,  0.0000,  0.0000],
        [ 0.8995, -0.2725,  1.0835,  0.0000,  0.0000,  0.0000],
        [-1.5407, -1.5073, -3.4443,  0.0000,  0.0000,  0.0000],
        [-1.0827, -0.4982,  0.9583,  0.0000,  0.0000,  0.0000],
        [ 0.3790, -0.3820, -2.1624,  0.0000,  0.0000,  0.0000],
        [ 1.2677,  1.0557,  3.2847,  0.0000,  0.0000,  0.0000],
        [-1.1998, -0.8353, -3.2377,  0.0000,  0.0000,  0.0000],
        [-1.2934,  1.0464, -3.4510,  0.0000,  0.0000,  0.0000],
        [ 1.5107,  0.9254,  2.1452,  0.0000,  0.0000,  0.0000],
        [ 0.0670, -0.7602,  2.9167,  0.0000,  0.0000,  0.0000],
        [-0.7844,  0.8524, -1.9959,  0.0000,  0.0000,  0.0000],
        [-0.3350, -1.2243,  0.3717,  0.0000,  0.0000,  0.0000],
        [ 1.4676,  0.8590, -0.3370,  0.0000,  0.0000,  0.0000],
        [-1.1991,  0.9622,  1.6467,  0.0000,  0.0000,  0.0000],
        [ 0.9370,  0.8984, -1.0813,  0.0000,  0.0000,  0.0000],
        [ 0.4316,  0.9764, -1.4864,  0.0000,  0.0000,  0.0000],
        [-1.2599, -0.0850, -1.6200,  0.0000,  0.0000,  0.0000],
        [ 0.6132, -0.6382, -3.5824,  0.0000,  0.0000,  0.0000],
        [-1.8388, -0.1611, -0.5831,  0.0000,  0.0000,  0.0000],
        [-0.5294,  0.0866, -1.4248,  0.0000,  0.0000,  0.0000],
        [ 0.9133, -0.9464,  0.2521,  0.0000,  0.0000,  0.0000],
        [ 0.1689, -0.4516,  1.4380,  0.0000,  0.0000,  0.0000],
        [-0.6832, -0.4416,  2.3329,  0.0000,  0.0000,  0.0000],
        [ 0.4488,  0.6492, -2.8161,  0.0000,  0.0000,  0.0000],
        [ 1.4891, -1.1511, -0.7500,  0.0000,  0.0000,  0.0000],
        [ 1.0556,  0.5014, -2.3335,  0.0000,  0.0000,  0.0000],
        [-1.8372, -1.3041, -0.4977,  0.0000,  0.0000,  0.0000],
        [-1.4281,  0.6423, -2.6264,  0.0000,  0.0000,  0.0000],
        [ 0.7776,  1.0286,  1.3768,  0.0000,  0.0000,  0.0000],
        [ 1.1877, -1.4734,  1.3840,  0.0000,  0.0000,  0.0000],
        [-0.4576, -0.4296, -2.5001,  0.0000,  0.0000,  0.0000],
        [-0.7854, -1.4929,  3.4857,  0.0000,  0.0000,  0.0000],
        [ 0.5040,  0.0169, -1.2500,  0.0000,  0.0000,  0.0000],
        [ 0.1672, -2.2164,  0.2833,  0.0000,  0.0000,  0.0000],
        [-0.3713,  0.7387, -0.0570,  0.0000,  0.0000,  0.0000],
        [ 0.5016, -1.2456,  1.0908,  0.0000,  0.0000,  0.0000],
        [ 0.8111, -1.8536, -1.5886,  0.0000,  0.0000,  0.0000],
        [-1.2473, -1.6722,  1.7085,  0.0000,  0.0000,  0.0000],
        [ 0.3219,  0.4957,  0.1682,  0.0000,  0.0000,  0.0000],
        [-0.7775,  0.7294,  2.9356,  0.0000,  0.0000,  0.0000],
        [-0.0417, -1.7485, -2.9627,  0.0000,  0.0000,  0.0000],
        [ 0.1032, -0.2348, -0.0513,  0.0000,  0.0000,  0.0000],
        [-1.8322, -0.5897,  0.8333,  0.0000,  0.0000,  0.0000],
        [ 1.1655, -0.5764, -1.9389,  0.0000,  0.0000,  0.0000],
        [-0.6669, -0.9922, -0.8334,  0.0000,  0.0000,  0.0000],
        [ 0.8897, -2.4127, -2.2498,  0.0000,  0.0000,  0.0000],
        [-1.1029,  0.3968,  1.0573,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  409
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0099, grad_fn=<DivBackward0>)
Projection Loss:  tensor(472.9306, grad_fn=<AddBackward0>)
Total Loss:  tensor(472.9405, grad_fn=<AddBackward0>)
Gradients:
24.732757568359375
Gradient before update: tensor(-28.6725)
Gradient after update: tensor(-28.6725)
current Learning Rate:  0.0001
------------------------------------------------------------------------------------------------------------------
Iteration:  410
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0099, grad_fn=<DivBackward0>)
Projection Loss:  tensor(472.9283, grad_fn=<AddBackward0>)
Total Loss:  tensor(472.9382, grad_fn=<AddBackward0>)
Gradients:
23.663009643554688
Gradient before update: tensor(-29.9107)
Gradient after update: tensor(-29.9107)
current Learning Rate:  0.0001
Total Loss:  tensor(472.9382, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4266,  0.3714, -3.6288,  0.0000,  0.0000,  0.0000],
        [-0.0957,  0.6047,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7536,  0.4589,  2.7597,  0.0000,  0.0000,  0.0000],
        [ 0.8340,  0.2360,  2.7935,  0.0000,  0.0000,  0.0000],
        [-0.0116,  0.0208,  0.7138,  0.0000,  0.0000,  0.0000],
        [ 1.1880,  0.2333, -0.8276,  0.0000,  0.0000,  0.0000],
        [ 0.4696,  0.5248, -0.5655,  0.0000,  0.0000,  0.0000],
        [ 1.2603,  0.3770,  0.7731,  0.0000,  0.0000,  0.0000],
        [-0.5864, -2.2121, -1.3227,  0.0000,  0.0000,  0.0000],
        [ 0.8997, -0.2723,  1.0836,  0.0000,  0.0000,  0.0000],
        [-1.5408, -1.5076, -3.4445,  0.0000,  0.0000,  0.0000],
        [-1.0829, -0.4981,  0.9583,  0.0000,  0.0000,  0.0000],
        [ 0.3792, -0.3822, -2.1623,  0.0000,  0.0000,  0.0000],
        [ 1.2678,  1.0558,  3.2847,  0.0000,  0.0000,  0.0000],
        [-1.1999, -0.8354, -3.2375,  0.0000,  0.0000,  0.0000],
        [-1.2934,  1.0464, -3.4512,  0.0000,  0.0000,  0.0000],
        [ 1.5109,  0.9256,  2.1451,  0.0000,  0.0000,  0.0000],
        [ 0.0669, -0.7604,  2.9167,  0.0000,  0.0000,  0.0000],
        [-0.7844,  0.8524, -1.9960,  0.0000,  0.0000,  0.0000],
        [-0.3349, -1.2244,  0.3716,  0.0000,  0.0000,  0.0000],
        [ 1.4677,  0.8589, -0.3370,  0.0000,  0.0000,  0.0000],
        [-1.1989,  0.9624,  1.6465,  0.0000,  0.0000,  0.0000],
        [ 0.9372,  0.8985, -1.0811,  0.0000,  0.0000,  0.0000],
        [ 0.4316,  0.9764, -1.4864,  0.0000,  0.0000,  0.0000],
        [-1.2599, -0.0850, -1.6200,  0.0000,  0.0000,  0.0000],
        [ 0.6130, -0.6384, -3.5822,  0.0000,  0.0000,  0.0000],
        [-1.8390, -0.1610, -0.5831,  0.0000,  0.0000,  0.0000],
        [-0.5296,  0.0869, -1.4247,  0.0000,  0.0000,  0.0000],
        [ 0.9133, -0.9466,  0.2522,  0.0000,  0.0000,  0.0000],
        [ 0.1687, -0.4518,  1.4379,  0.0000,  0.0000,  0.0000],
        [-0.6834, -0.4414,  2.3329,  0.0000,  0.0000,  0.0000],
        [ 0.4486,  0.6494, -2.8160,  0.0000,  0.0000,  0.0000],
        [ 1.4892, -1.1512, -0.7500,  0.0000,  0.0000,  0.0000],
        [ 1.0554,  0.5015, -2.3335,  0.0000,  0.0000,  0.0000],
        [-1.8372, -1.3041, -0.4977,  0.0000,  0.0000,  0.0000],
        [-1.4283,  0.6425, -2.6263,  0.0000,  0.0000,  0.0000],
        [ 0.7777,  1.0287,  1.3767,  0.0000,  0.0000,  0.0000],
        [ 1.1878, -1.4735,  1.3839,  0.0000,  0.0000,  0.0000],
        [-0.4574, -0.4297, -2.5000,  0.0000,  0.0000,  0.0000],
        [-0.7855, -1.4929,  3.4855,  0.0000,  0.0000,  0.0000],
        [ 0.5039,  0.0168, -1.2500,  0.0000,  0.0000,  0.0000],
        [ 0.1673, -2.2165,  0.2835,  0.0000,  0.0000,  0.0000],
        [-0.3712,  0.7388, -0.0570,  0.0000,  0.0000,  0.0000],
        [ 0.5015, -1.2458,  1.0906,  0.0000,  0.0000,  0.0000],
        [ 0.8110, -1.8535, -1.5886,  0.0000,  0.0000,  0.0000],
        [-1.2473, -1.6724,  1.7083,  0.0000,  0.0000,  0.0000],
        [ 0.3217,  0.4955,  0.1682,  0.0000,  0.0000,  0.0000],
        [-0.7773,  0.7292,  2.9358,  0.0000,  0.0000,  0.0000],
        [-0.0416, -1.7486, -2.9626,  0.0000,  0.0000,  0.0000],
        [ 0.1030, -0.2349, -0.0513,  0.0000,  0.0000,  0.0000],
        [-1.8324, -0.5897,  0.8333,  0.0000,  0.0000,  0.0000],
        [ 1.1656, -0.5763, -1.9388,  0.0000,  0.0000,  0.0000],
        [-0.6668, -0.9924, -0.8334,  0.0000,  0.0000,  0.0000],
        [ 0.8896, -2.4125, -2.2498,  0.0000,  0.0000,  0.0000],
        [-1.1027,  0.3966,  1.0572,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  411
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0098, grad_fn=<DivBackward0>)
Projection Loss:  tensor(472.9261, grad_fn=<AddBackward0>)
Total Loss:  tensor(472.9359, grad_fn=<AddBackward0>)
Gradients:
22.966468811035156
Gradient before update: tensor(-31.9007)
Gradient after update: tensor(-31.9007)
current Learning Rate:  0.0001
------------------------------------------------------------------------------------------------------------------
Iteration:  412
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0098, grad_fn=<DivBackward0>)
Projection Loss:  tensor(472.9237, grad_fn=<AddBackward0>)
Total Loss:  tensor(472.9336, grad_fn=<AddBackward0>)
Gradients:
22.73358917236328
Gradient before update: tensor(-34.3353)
Gradient after update: tensor(-34.3353)
current Learning Rate:  0.0001
Total Loss:  tensor(472.9336, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4264,  0.3712, -3.6286,  0.0000,  0.0000,  0.0000],
        [-0.0956,  0.6049,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7537,  0.4589,  2.7598,  0.0000,  0.0000,  0.0000],
        [ 0.8339,  0.2358,  2.7934,  0.0000,  0.0000,  0.0000],
        [-0.0118,  0.0210,  0.7138,  0.0000,  0.0000,  0.0000],
        [ 1.1881,  0.2332, -0.8275,  0.0000,  0.0000,  0.0000],
        [ 0.4696,  0.5249, -0.5655,  0.0000,  0.0000,  0.0000],
        [ 1.2604,  0.3768,  0.7731,  0.0000,  0.0000,  0.0000],
        [-0.5864, -2.2121, -1.3226,  0.0000,  0.0000,  0.0000],
        [ 0.8998, -0.2722,  1.0836,  0.0000,  0.0000,  0.0000],
        [-1.5409, -1.5078, -3.4447,  0.0000,  0.0000,  0.0000],
        [-1.0831, -0.4979,  0.9583,  0.0000,  0.0000,  0.0000],
        [ 0.3794, -0.3824, -2.1623,  0.0000,  0.0000,  0.0000],
        [ 1.2679,  1.0559,  3.2848,  0.0000,  0.0000,  0.0000],
        [-1.2000, -0.8355, -3.2373,  0.0000,  0.0000,  0.0000],
        [-1.2934,  1.0464, -3.4514,  0.0000,  0.0000,  0.0000],
        [ 1.5110,  0.9258,  2.1449,  0.0000,  0.0000,  0.0000],
        [ 0.0668, -0.7606,  2.9167,  0.0000,  0.0000,  0.0000],
        [-0.7843,  0.8525, -1.9960,  0.0000,  0.0000,  0.0000],
        [-0.3347, -1.2244,  0.3716,  0.0000,  0.0000,  0.0000],
        [ 1.4677,  0.8589, -0.3369,  0.0000,  0.0000,  0.0000],
        [-1.1987,  0.9626,  1.6463,  0.0000,  0.0000,  0.0000],
        [ 0.9374,  0.8987, -1.0809,  0.0000,  0.0000,  0.0000],
        [ 0.4316,  0.9764, -1.4863,  0.0000,  0.0000,  0.0000],
        [-1.2599, -0.0850, -1.6200,  0.0000,  0.0000,  0.0000],
        [ 0.6128, -0.6386, -3.5820,  0.0000,  0.0000,  0.0000],
        [-1.8392, -0.1609, -0.5831,  0.0000,  0.0000,  0.0000],
        [-0.5298,  0.0871, -1.4246,  0.0000,  0.0000,  0.0000],
        [ 0.9134, -0.9469,  0.2523,  0.0000,  0.0000,  0.0000],
        [ 0.1685, -0.4520,  1.4378,  0.0000,  0.0000,  0.0000],
        [-0.6836, -0.4412,  2.3329,  0.0000,  0.0000,  0.0000],
        [ 0.4484,  0.6495, -2.8159,  0.0000,  0.0000,  0.0000],
        [ 1.4893, -1.1513, -0.7500,  0.0000,  0.0000,  0.0000],
        [ 1.0552,  0.5017, -2.3335,  0.0000,  0.0000,  0.0000],
        [-1.8372, -1.3041, -0.4978,  0.0000,  0.0000,  0.0000],
        [-1.4284,  0.6426, -2.6262,  0.0000,  0.0000,  0.0000],
        [ 0.7778,  1.0288,  1.3767,  0.0000,  0.0000,  0.0000],
        [ 1.1879, -1.4736,  1.3838,  0.0000,  0.0000,  0.0000],
        [-0.4573, -0.4299, -2.5000,  0.0000,  0.0000,  0.0000],
        [-0.7855, -1.4929,  3.4853,  0.0000,  0.0000,  0.0000],
        [ 0.5039,  0.0166, -1.2500,  0.0000,  0.0000,  0.0000],
        [ 0.1673, -2.2166,  0.2836,  0.0000,  0.0000,  0.0000],
        [-0.3711,  0.7389, -0.0569,  0.0000,  0.0000,  0.0000],
        [ 0.5013, -1.2459,  1.0905,  0.0000,  0.0000,  0.0000],
        [ 0.8109, -1.8535, -1.5885,  0.0000,  0.0000,  0.0000],
        [-1.2472, -1.6726,  1.7082,  0.0000,  0.0000,  0.0000],
        [ 0.3215,  0.4953,  0.1682,  0.0000,  0.0000,  0.0000],
        [-0.7771,  0.7290,  2.9359,  0.0000,  0.0000,  0.0000],
        [-0.0416, -1.7487, -2.9624,  0.0000,  0.0000,  0.0000],
        [ 0.1028, -0.2351, -0.0512,  0.0000,  0.0000,  0.0000],
        [-1.8325, -0.5897,  0.8333,  0.0000,  0.0000,  0.0000],
        [ 1.1658, -0.5763, -1.9387,  0.0000,  0.0000,  0.0000],
        [-0.6667, -0.9926, -0.8334,  0.0000,  0.0000,  0.0000],
        [ 0.8896, -2.4122, -2.2498,  0.0000,  0.0000,  0.0000],
        [-1.1026,  0.3965,  1.0571,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  413
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0098, grad_fn=<DivBackward0>)
Projection Loss:  tensor(472.9214, grad_fn=<AddBackward0>)
Total Loss:  tensor(472.9312, grad_fn=<AddBackward0>)
Gradients:
22.9668025970459
Gradient before update: tensor(-36.9048)
Gradient after update: tensor(-36.9048)
current Learning Rate:  0.0001
------------------------------------------------------------------------------------------------------------------
Iteration:  414
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0098, grad_fn=<DivBackward0>)
Projection Loss:  tensor(472.9191, grad_fn=<AddBackward0>)
Total Loss:  tensor(472.9289, grad_fn=<AddBackward0>)
Gradients:
23.51738166809082
Gradient before update: tensor(-39.2504)
Gradient after update: tensor(-39.2504)
current Learning Rate:  0.0001
Total Loss:  tensor(472.9289, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4263,  0.3710, -3.6284,  0.0000,  0.0000,  0.0000],
        [-0.0954,  0.6050,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7538,  0.4589,  2.7599,  0.0000,  0.0000,  0.0000],
        [ 0.8339,  0.2357,  2.7934,  0.0000,  0.0000,  0.0000],
        [-0.0120,  0.0212,  0.7138,  0.0000,  0.0000,  0.0000],
        [ 1.1882,  0.2330, -0.8273,  0.0000,  0.0000,  0.0000],
        [ 0.4696,  0.5249, -0.5655,  0.0000,  0.0000,  0.0000],
        [ 1.2605,  0.3767,  0.7731,  0.0000,  0.0000,  0.0000],
        [-0.5864, -2.2122, -1.3224,  0.0000,  0.0000,  0.0000],
        [ 0.9000, -0.2720,  1.0836,  0.0000,  0.0000,  0.0000],
        [-1.5410, -1.5079, -3.4449,  0.0000,  0.0000,  0.0000],
        [-1.0833, -0.4977,  0.9583,  0.0000,  0.0000,  0.0000],
        [ 0.3796, -0.3826, -2.1623,  0.0000,  0.0000,  0.0000],
        [ 1.2680,  1.0559,  3.2849,  0.0000,  0.0000,  0.0000],
        [-1.2001, -0.8356, -3.2371,  0.0000,  0.0000,  0.0000],
        [-1.2934,  1.0465, -3.4516,  0.0000,  0.0000,  0.0000],
        [ 1.5112,  0.9259,  2.1448,  0.0000,  0.0000,  0.0000],
        [ 0.0666, -0.7608,  2.9167,  0.0000,  0.0000,  0.0000],
        [-0.7843,  0.8525, -1.9960,  0.0000,  0.0000,  0.0000],
        [-0.3345, -1.2244,  0.3715,  0.0000,  0.0000,  0.0000],
        [ 1.4678,  0.8588, -0.3369,  0.0000,  0.0000,  0.0000],
        [-1.1985,  0.9628,  1.6461,  0.0000,  0.0000,  0.0000],
        [ 0.9376,  0.8989, -1.0807,  0.0000,  0.0000,  0.0000],
        [ 0.4316,  0.9764, -1.4863,  0.0000,  0.0000,  0.0000],
        [-1.2600, -0.0850, -1.6200,  0.0000,  0.0000,  0.0000],
        [ 0.6126, -0.6388, -3.5818,  0.0000,  0.0000,  0.0000],
        [-1.8394, -0.1608, -0.5831,  0.0000,  0.0000,  0.0000],
        [-0.5300,  0.0873, -1.4245,  0.0000,  0.0000,  0.0000],
        [ 0.9134, -0.9471,  0.2524,  0.0000,  0.0000,  0.0000],
        [ 0.1683, -0.4522,  1.4377,  0.0000,  0.0000,  0.0000],
        [-0.6838, -0.4409,  2.3329,  0.0000,  0.0000,  0.0000],
        [ 0.4483,  0.6497, -2.8159,  0.0000,  0.0000,  0.0000],
        [ 1.4894, -1.1514, -0.7500,  0.0000,  0.0000,  0.0000],
        [ 1.0550,  0.5019, -2.3335,  0.0000,  0.0000,  0.0000],
        [-1.8372, -1.3041, -0.4979,  0.0000,  0.0000,  0.0000],
        [-1.4286,  0.6428, -2.6261,  0.0000,  0.0000,  0.0000],
        [ 0.7778,  1.0289,  1.3766,  0.0000,  0.0000,  0.0000],
        [ 1.1881, -1.4737,  1.3837,  0.0000,  0.0000,  0.0000],
        [-0.4571, -0.4301, -2.5000,  0.0000,  0.0000,  0.0000],
        [-0.7856, -1.4929,  3.4852,  0.0000,  0.0000,  0.0000],
        [ 0.5038,  0.0164, -1.2500,  0.0000,  0.0000,  0.0000],
        [ 0.1673, -2.2166,  0.2838,  0.0000,  0.0000,  0.0000],
        [-0.3711,  0.7390, -0.0568,  0.0000,  0.0000,  0.0000],
        [ 0.5011, -1.2461,  1.0903,  0.0000,  0.0000,  0.0000],
        [ 0.8109, -1.8535, -1.5885,  0.0000,  0.0000,  0.0000],
        [-1.2472, -1.6727,  1.7082,  0.0000,  0.0000,  0.0000],
        [ 0.3213,  0.4951,  0.1682,  0.0000,  0.0000,  0.0000],
        [-0.7769,  0.7288,  2.9361,  0.0000,  0.0000,  0.0000],
        [-0.0416, -1.7487, -2.9623,  0.0000,  0.0000,  0.0000],
        [ 0.1026, -0.2353, -0.0512,  0.0000,  0.0000,  0.0000],
        [-1.8326, -0.5896,  0.8333,  0.0000,  0.0000,  0.0000],
        [ 1.1660, -0.5763, -1.9386,  0.0000,  0.0000,  0.0000],
        [-0.6665, -0.9927, -0.8334,  0.0000,  0.0000,  0.0000],
        [ 0.8896, -2.4120, -2.2498,  0.0000,  0.0000,  0.0000],
        [-1.1024,  0.3963,  1.0570,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  415
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0097, grad_fn=<DivBackward0>)
Projection Loss:  tensor(472.9166, grad_fn=<AddBackward0>)
Total Loss:  tensor(472.9263, grad_fn=<AddBackward0>)
Gradients:
24.073158264160156
Gradient before update: tensor(-40.8627)
Gradient after update: tensor(-40.8627)
current Learning Rate:  0.0001
------------------------------------------------------------------------------------------------------------------
Iteration:  416
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0097, grad_fn=<DivBackward0>)
Projection Loss:  tensor(472.9140, grad_fn=<AddBackward0>)
Total Loss:  tensor(472.9237, grad_fn=<AddBackward0>)
Gradients:
24.152877807617188
Gradient before update: tensor(-40.9731)
Gradient after update: tensor(-40.9731)
current Learning Rate:  0.0001
Total Loss:  tensor(472.9237, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4261,  0.3708, -3.6282,  0.0000,  0.0000,  0.0000],
        [-0.0953,  0.6052,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7539,  0.4589,  2.7600,  0.0000,  0.0000,  0.0000],
        [ 0.8338,  0.2355,  2.7933,  0.0000,  0.0000,  0.0000],
        [-0.0122,  0.0214,  0.7138,  0.0000,  0.0000,  0.0000],
        [ 1.1883,  0.2329, -0.8272,  0.0000,  0.0000,  0.0000],
        [ 0.4696,  0.5249, -0.5655,  0.0000,  0.0000,  0.0000],
        [ 1.2606,  0.3766,  0.7731,  0.0000,  0.0000,  0.0000],
        [-0.5864, -2.2122, -1.3223,  0.0000,  0.0000,  0.0000],
        [ 0.9002, -0.2719,  1.0835,  0.0000,  0.0000,  0.0000],
        [-1.5410, -1.5081, -3.4451,  0.0000,  0.0000,  0.0000],
        [-1.0835, -0.4975,  0.9583,  0.0000,  0.0000,  0.0000],
        [ 0.3798, -0.3828, -2.1623,  0.0000,  0.0000,  0.0000],
        [ 1.2681,  1.0560,  3.2849,  0.0000,  0.0000,  0.0000],
        [-1.2002, -0.8356, -3.2370,  0.0000,  0.0000,  0.0000],
        [-1.2933,  1.0465, -3.4518,  0.0000,  0.0000,  0.0000],
        [ 1.5114,  0.9261,  2.1446,  0.0000,  0.0000,  0.0000],
        [ 0.0665, -0.7610,  2.9166,  0.0000,  0.0000,  0.0000],
        [-0.7843,  0.8525, -1.9961,  0.0000,  0.0000,  0.0000],
        [-0.3343, -1.2245,  0.3715,  0.0000,  0.0000,  0.0000],
        [ 1.4679,  0.8587, -0.3369,  0.0000,  0.0000,  0.0000],
        [-1.1983,  0.9630,  1.6459,  0.0000,  0.0000,  0.0000],
        [ 0.9378,  0.8991, -1.0805,  0.0000,  0.0000,  0.0000],
        [ 0.4316,  0.9764, -1.4863,  0.0000,  0.0000,  0.0000],
        [-1.2600, -0.0850, -1.6201,  0.0000,  0.0000,  0.0000],
        [ 0.6124, -0.6390, -3.5816,  0.0000,  0.0000,  0.0000],
        [-1.8396, -0.1607, -0.5832,  0.0000,  0.0000,  0.0000],
        [-0.5301,  0.0876, -1.4244,  0.0000,  0.0000,  0.0000],
        [ 0.9134, -0.9473,  0.2526,  0.0000,  0.0000,  0.0000],
        [ 0.1681, -0.4524,  1.4376,  0.0000,  0.0000,  0.0000],
        [-0.6840, -0.4407,  2.3328,  0.0000,  0.0000,  0.0000],
        [ 0.4481,  0.6499, -2.8158,  0.0000,  0.0000,  0.0000],
        [ 1.4895, -1.1515, -0.7500,  0.0000,  0.0000,  0.0000],
        [ 1.0548,  0.5021, -2.3334,  0.0000,  0.0000,  0.0000],
        [-1.8372, -1.3041, -0.4979,  0.0000,  0.0000,  0.0000],
        [-1.4287,  0.6429, -2.6261,  0.0000,  0.0000,  0.0000],
        [ 0.7779,  1.0290,  1.3766,  0.0000,  0.0000,  0.0000],
        [ 1.1882, -1.4738,  1.3836,  0.0000,  0.0000,  0.0000],
        [-0.4569, -0.4303, -2.4999,  0.0000,  0.0000,  0.0000],
        [-0.7856, -1.4929,  3.4850,  0.0000,  0.0000,  0.0000],
        [ 0.5038,  0.0162, -1.2500,  0.0000,  0.0000,  0.0000],
        [ 0.1673, -2.2166,  0.2840,  0.0000,  0.0000,  0.0000],
        [-0.3710,  0.7390, -0.0568,  0.0000,  0.0000,  0.0000],
        [ 0.5010, -1.2462,  1.0902,  0.0000,  0.0000,  0.0000],
        [ 0.8108, -1.8534, -1.5884,  0.0000,  0.0000,  0.0000],
        [-1.2471, -1.6729,  1.7081,  0.0000,  0.0000,  0.0000],
        [ 0.3211,  0.4949,  0.1682,  0.0000,  0.0000,  0.0000],
        [-0.7767,  0.7286,  2.9363,  0.0000,  0.0000,  0.0000],
        [-0.0416, -1.7488, -2.9621,  0.0000,  0.0000,  0.0000],
        [ 0.1024, -0.2354, -0.0512,  0.0000,  0.0000,  0.0000],
        [-1.8328, -0.5896,  0.8333,  0.0000,  0.0000,  0.0000],
        [ 1.1662, -0.5762, -1.9385,  0.0000,  0.0000,  0.0000],
        [-0.6664, -0.9929, -0.8334,  0.0000,  0.0000,  0.0000],
        [ 0.8896, -2.4117, -2.2499,  0.0000,  0.0000,  0.0000],
        [-1.1023,  0.3962,  1.0568,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  417
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0097, grad_fn=<DivBackward0>)
Projection Loss:  tensor(472.9113, grad_fn=<AddBackward0>)
Total Loss:  tensor(472.9210, grad_fn=<AddBackward0>)
Gradients:
23.319305419921875
Gradient before update: tensor(-38.4878)
Gradient after update: tensor(-38.4878)
current Learning Rate:  0.0001
------------------------------------------------------------------------------------------------------------------
Iteration:  418
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0096, grad_fn=<DivBackward0>)
Projection Loss:  tensor(472.9086, grad_fn=<AddBackward0>)
Total Loss:  tensor(472.9182, grad_fn=<AddBackward0>)
Gradients:
21.983612060546875
Gradient before update: tensor(-32.2294)
Gradient after update: tensor(-32.2294)
current Learning Rate:  0.0001
Total Loss:  tensor(472.9182, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4259,  0.3706, -3.6280,  0.0000,  0.0000,  0.0000],
        [-0.0952,  0.6053,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7540,  0.4589,  2.7602,  0.0000,  0.0000,  0.0000],
        [ 0.8337,  0.2353,  2.7933,  0.0000,  0.0000,  0.0000],
        [-0.0124,  0.0216,  0.7137,  0.0000,  0.0000,  0.0000],
        [ 1.1884,  0.2328, -0.8270,  0.0000,  0.0000,  0.0000],
        [ 0.4696,  0.5249, -0.5655,  0.0000,  0.0000,  0.0000],
        [ 1.2608,  0.3765,  0.7731,  0.0000,  0.0000,  0.0000],
        [-0.5864, -2.2122, -1.3222,  0.0000,  0.0000,  0.0000],
        [ 0.9003, -0.2717,  1.0835,  0.0000,  0.0000,  0.0000],
        [-1.5410, -1.5082, -3.4453,  0.0000,  0.0000,  0.0000],
        [-1.0837, -0.4973,  0.9583,  0.0000,  0.0000,  0.0000],
        [ 0.3800, -0.3830, -2.1623,  0.0000,  0.0000,  0.0000],
        [ 1.2681,  1.0561,  3.2850,  0.0000,  0.0000,  0.0000],
        [-1.2003, -0.8357, -3.2368,  0.0000,  0.0000,  0.0000],
        [-1.2933,  1.0465, -3.4520,  0.0000,  0.0000,  0.0000],
        [ 1.5116,  0.9262,  2.1445,  0.0000,  0.0000,  0.0000],
        [ 0.0664, -0.7612,  2.9166,  0.0000,  0.0000,  0.0000],
        [-0.7842,  0.8526, -1.9961,  0.0000,  0.0000,  0.0000],
        [-0.3342, -1.2245,  0.3715,  0.0000,  0.0000,  0.0000],
        [ 1.4679,  0.8587, -0.3368,  0.0000,  0.0000,  0.0000],
        [-1.1981,  0.9632,  1.6457,  0.0000,  0.0000,  0.0000],
        [ 0.9380,  0.8993, -1.0803,  0.0000,  0.0000,  0.0000],
        [ 0.4316,  0.9764, -1.4863,  0.0000,  0.0000,  0.0000],
        [-1.2600, -0.0850, -1.6201,  0.0000,  0.0000,  0.0000],
        [ 0.6122, -0.6391, -3.5815,  0.0000,  0.0000,  0.0000],
        [-1.8397, -0.1606, -0.5832,  0.0000,  0.0000,  0.0000],
        [-0.5303,  0.0878, -1.4243,  0.0000,  0.0000,  0.0000],
        [ 0.9133, -0.9475,  0.2527,  0.0000,  0.0000,  0.0000],
        [ 0.1679, -0.4526,  1.4375,  0.0000,  0.0000,  0.0000],
        [-0.6842, -0.4405,  2.3327,  0.0000,  0.0000,  0.0000],
        [ 0.4479,  0.6501, -2.8157,  0.0000,  0.0000,  0.0000],
        [ 1.4897, -1.1516, -0.7500,  0.0000,  0.0000,  0.0000],
        [ 1.0547,  0.5023, -2.3334,  0.0000,  0.0000,  0.0000],
        [-1.8372, -1.3041, -0.4980,  0.0000,  0.0000,  0.0000],
        [-1.4289,  0.6431, -2.6260,  0.0000,  0.0000,  0.0000],
        [ 0.7779,  1.0291,  1.3765,  0.0000,  0.0000,  0.0000],
        [ 1.1883, -1.4739,  1.3836,  0.0000,  0.0000,  0.0000],
        [-0.4567, -0.4304, -2.4999,  0.0000,  0.0000,  0.0000],
        [-0.7856, -1.4929,  3.4848,  0.0000,  0.0000,  0.0000],
        [ 0.5038,  0.0160, -1.2500,  0.0000,  0.0000,  0.0000],
        [ 0.1673, -2.2166,  0.2842,  0.0000,  0.0000,  0.0000],
        [-0.3709,  0.7391, -0.0567,  0.0000,  0.0000,  0.0000],
        [ 0.5009, -1.2464,  1.0901,  0.0000,  0.0000,  0.0000],
        [ 0.8107, -1.8534, -1.5883,  0.0000,  0.0000,  0.0000],
        [-1.2471, -1.6731,  1.7081,  0.0000,  0.0000,  0.0000],
        [ 0.3209,  0.4947,  0.1682,  0.0000,  0.0000,  0.0000],
        [-0.7766,  0.7284,  2.9365,  0.0000,  0.0000,  0.0000],
        [-0.0416, -1.7488, -2.9620,  0.0000,  0.0000,  0.0000],
        [ 0.1022, -0.2355, -0.0511,  0.0000,  0.0000,  0.0000],
        [-1.8329, -0.5896,  0.8333,  0.0000,  0.0000,  0.0000],
        [ 1.1663, -0.5762, -1.9384,  0.0000,  0.0000,  0.0000],
        [-0.6663, -0.9931, -0.8334,  0.0000,  0.0000,  0.0000],
        [ 0.8896, -2.4114, -2.2499,  0.0000,  0.0000,  0.0000],
        [-1.1022,  0.3960,  1.0567,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
Iteration:  419
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0096, grad_fn=<DivBackward0>)
Projection Loss:  tensor(472.9061, grad_fn=<AddBackward0>)
Total Loss:  tensor(472.9157, grad_fn=<AddBackward0>)
Gradients:
22.45583152770996
Gradient before update: tensor(-22.2204)
Gradient after update: tensor(-22.2204)
current Learning Rate:  0.0001
------------------------------------------------------------------------------------------------------------------
Iteration:  420
inside calulate_loss, stacked_final_signed_distances.requires_grad:  True
Intersection Loss:  tensor(0.0096, grad_fn=<DivBackward0>)
Projection Loss:  tensor(472.9037, grad_fn=<AddBackward0>)
Total Loss:  tensor(472.9133, grad_fn=<AddBackward0>)
Gradients:
24.542240142822266
Gradient before update: tensor(-13.0975)
Gradient after update: tensor(-13.0975)
current Learning Rate:  0.0001
Total Loss:  tensor(472.9133, grad_fn=<AddBackward0>)
Parameter containing:
tensor([[ 0.4257,  0.3704, -3.6278,  0.0000,  0.0000,  0.0000],
        [-0.0951,  0.6054,  1.7917,  0.0000,  0.0000,  0.0000],
        [-1.7541,  0.4589,  2.7603,  0.0000,  0.0000,  0.0000],
        [ 0.8336,  0.2351,  2.7932,  0.0000,  0.0000,  0.0000],
        [-0.0126,  0.0218,  0.7137,  0.0000,  0.0000,  0.0000],
        [ 1.1885,  0.2327, -0.8269,  0.0000,  0.0000,  0.0000],
        [ 0.4696,  0.5249, -0.5655,  0.0000,  0.0000,  0.0000],
        [ 1.2609,  0.3763,  0.7730,  0.0000,  0.0000,  0.0000],
        [-0.5864, -2.2122, -1.3221,  0.0000,  0.0000,  0.0000],
        [ 0.9005, -0.2715,  1.0835,  0.0000,  0.0000,  0.0000],
        [-1.5409, -1.5082, -3.4455,  0.0000,  0.0000,  0.0000],
        [-1.0838, -0.4972,  0.9583,  0.0000,  0.0000,  0.0000],
        [ 0.3802, -0.3832, -2.1623,  0.0000,  0.0000,  0.0000],
        [ 1.2682,  1.0562,  3.2851,  0.0000,  0.0000,  0.0000],
        [-1.2004, -0.8358, -3.2367,  0.0000,  0.0000,  0.0000],
        [-1.2933,  1.0466, -3.4522,  0.0000,  0.0000,  0.0000],
        [ 1.5117,  0.9264,  2.1443,  0.0000,  0.0000,  0.0000],
        [ 0.0662, -0.7614,  2.9166,  0.0000,  0.0000,  0.0000],
        [-0.7842,  0.8526, -1.9961,  0.0000,  0.0000,  0.0000],
        [-0.3340, -1.2245,  0.3715,  0.0000,  0.0000,  0.0000],
        [ 1.4680,  0.8586, -0.3368,  0.0000,  0.0000,  0.0000],
        [-1.1979,  0.9633,  1.6455,  0.0000,  0.0000,  0.0000],
        [ 0.9383,  0.8994, -1.0801,  0.0000,  0.0000,  0.0000],
        [ 0.4317,  0.9764, -1.4863,  0.0000,  0.0000,  0.0000],
        [-1.2600, -0.0851, -1.6201,  0.0000,  0.0000,  0.0000],
        [ 0.6120, -0.6393, -3.5813,  0.0000,  0.0000,  0.0000],
        [-1.8399, -0.1605, -0.5832,  0.0000,  0.0000,  0.0000],
        [-0.5305,  0.0880, -1.4242,  0.0000,  0.0000,  0.0000],
        [ 0.9133, -0.9477,  0.2529,  0.0000,  0.0000,  0.0000],
        [ 0.1677, -0.4528,  1.4374,  0.0000,  0.0000,  0.0000],
        [-0.6845, -0.4403,  2.3325,  0.0000,  0.0000,  0.0000],
        [ 0.4477,  0.6503, -2.8156,  0.0000,  0.0000,  0.0000],
        [ 1.4898, -1.1518, -0.7500,  0.0000,  0.0000,  0.0000],
        [ 1.0545,  0.5025, -2.3334,  0.0000,  0.0000,  0.0000],
        [-1.8372, -1.3041, -0.4980,  0.0000,  0.0000,  0.0000],
        [-1.4290,  0.6432, -2.6259,  0.0000,  0.0000,  0.0000],
        [ 0.7780,  1.0291,  1.3765,  0.0000,  0.0000,  0.0000],
        [ 1.1883, -1.4740,  1.3835,  0.0000,  0.0000,  0.0000],
        [-0.4566, -0.4306, -2.4999,  0.0000,  0.0000,  0.0000],
        [-0.7856, -1.4929,  3.4847,  0.0000,  0.0000,  0.0000],
        [ 0.5037,  0.0158, -1.2501,  0.0000,  0.0000,  0.0000],
        [ 0.1672, -2.2166,  0.2844,  0.0000,  0.0000,  0.0000],
        [-0.3709,  0.7391, -0.0567,  0.0000,  0.0000,  0.0000],
        [ 0.5007, -1.2465,  1.0899,  0.0000,  0.0000,  0.0000],
        [ 0.8107, -1.8533, -1.5883,  0.0000,  0.0000,  0.0000],
        [-1.2470, -1.6732,  1.7080,  0.0000,  0.0000,  0.0000],
        [ 0.3207,  0.4945,  0.1682,  0.0000,  0.0000,  0.0000],
        [-0.7764,  0.7282,  2.9366,  0.0000,  0.0000,  0.0000],
        [-0.0416, -1.7488, -2.9618,  0.0000,  0.0000,  0.0000],
        [ 0.1020, -0.2357, -0.0511,  0.0000,  0.0000,  0.0000],
        [-1.8330, -0.5896,  0.8334,  0.0000,  0.0000,  0.0000],
        [ 1.1665, -0.5761, -1.9383,  0.0000,  0.0000,  0.0000],
        [-0.6662, -0.9933, -0.8334,  0.0000,  0.0000,  0.0000],
        [ 0.8896, -2.4111, -2.2500,  0.0000,  0.0000,  0.0000],
        [-1.1020,  0.3959,  1.0566,  0.0000,  0.0000,  0.0000]],
       requires_grad=True)
------------------------------------------------------------------------------------------------------------------
